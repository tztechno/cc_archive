{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 29550,
          "sourceType": "datasetVersion",
          "datasetId": 23079
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "ASL Alphabet Classification w/TensorFlow.js Export",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tztechno/cc_archive/blob/main/ASL_Alphabet_Classification_w_TensorFlow_js_Export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "grassknoted_asl_alphabet_path = kagglehub.dataset_download('grassknoted/asl-alphabet')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "bw9mH-Env74i"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "STNkpNC8v74k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ASL Alphabet Classification w/TensorFlow.js Export**"
      ],
      "metadata": {
        "id": "M75YaM_3v74k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15.0\n",
        "!pip install protobuf==3.20.3"
      ],
      "metadata": {
        "trusted": true,
        "id": "MkqmOpVCv74k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"Loading data from folders...\")\n",
        "\n",
        "# Set your data path here\n",
        "data_path = '/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
        "\n",
        "# Get all image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Create a mapping from folder names to class indices\n",
        "class_folders = sorted([f for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))])\n",
        "class_to_index = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
        "\n",
        "print(f\"Found classes: {class_folders}\")\n",
        "print(f\"Number of classes: {len(class_folders)}\")\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_folder in class_folders:\n",
        "    class_path = os.path.join(data_path, class_folder)\n",
        "    label = class_to_index[class_folder]\n",
        "\n",
        "    # Get all image files in this class\n",
        "    class_images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    # Sample 2000 images per class (increased from 600)\n",
        "    sampled_images = random.sample(class_images, min(1000, len(class_images)))\n",
        "\n",
        "    for img_file in sampled_images:\n",
        "        image_paths.append(os.path.join(class_path, img_file))\n",
        "        labels.append(label)\n",
        "\n",
        "print(f\"Found {len(image_paths)} images across {len(set(labels))} classes\")\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "    \"\"\"Load image and convert to normalized RGB array\"\"\"\n",
        "    img = keras.preprocessing.image.load_img(\n",
        "        image_path,\n",
        "        color_mode='rgb',\n",
        "        target_size=target_size\n",
        "    )\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
        "    return img_array\n",
        "\n",
        "# Load all images in batches to avoid memory issues\n",
        "print(\"Loading and preprocessing images...\")\n",
        "batch_size = 100\n",
        "X = []\n",
        "for i in range(0, len(image_paths), batch_size):\n",
        "    batch_paths = image_paths[i:i+batch_size]\n",
        "    batch_images = [load_and_preprocess_image(path) for path in batch_paths]\n",
        "    X.extend(batch_images)\n",
        "    print(f\"  Loaded {min(i+batch_size, len(image_paths))}/{len(image_paths)} images...\")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(labels)\n",
        "print(\"All images loaded!\")\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = len(set(labels))\n",
        "y = keras.utils.to_categorical(y, num_classes)\n",
        "\n",
        "print(f\"\\nData shape: {X.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "\n",
        "# Split into training and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training Data: {X_train.shape}\")\n",
        "print(f\"Validation Data: {X_val.shape}\")\n",
        "\n",
        "# Build a simplified and more efficient model\n",
        "print(\"\\nBuilding model...\")\n",
        "model = keras.Sequential([\n",
        "    # Input layer\n",
        "    keras.layers.InputLayer(input_shape=(224, 224, 3)),\n",
        "\n",
        "    # First Convolutional Block\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "\n",
        "    # Fourth Convolutional Block\n",
        "    keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with lower learning rate\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Lower learning rate\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Data augmentation (REMOVED horizontal_flip - critical for sign language!)\n",
        "print(\"\\nConfiguring data augmentation...\")\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=10,           # Reduced from 15\n",
        "    zoom_range=0.1,              # Reduced from 0.15\n",
        "    width_shift_range=0.1,       # Reduced from 0.15\n",
        "    height_shift_range=0.1,      # Reduced from 0.15\n",
        "    brightness_range=[0.9, 1.1], # Narrowed range\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Configure callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,  # Increased patience\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,  # Increased patience\n",
        "        min_lr=0.000001,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'best_asl_model.h5',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nTraining the model...\")\n",
        "print(f\"Steps per epoch: {len(X_train) // 128}\")\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=128),  # Increased batch size\n",
        "    steps_per_epoch=len(X_train) // 128,\n",
        "    epochs=50,  # Increased epochs\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the final model\n",
        "print(\"\\nSaving the model...\")\n",
        "model.save('final_asl_model.h5')\n",
        "print(\"✓ Model saved as 'final_asl_model.h5'\")\n",
        "\n",
        "# Plot training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Accuracy', fontsize=12)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot loss\n",
        "ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Loss', fontsize=12)\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=300)\n",
        "print(\"✓ Training history saved as 'training_history.png'\")\n",
        "\n",
        "# Evaluate on validation set\n",
        "print(\"\\nEvaluating model...\")\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"\\nFinal Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
        "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Display class mapping for reference\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Class Mapping:\")\n",
        "print(\"=\"*60)\n",
        "for class_name, idx in sorted(class_to_index.items(), key=lambda x: x[1]):\n",
        "    print(f\"{idx:2d}: {class_name}\")\n",
        "\n",
        "# Display command for converting to TensorFlow.js format\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Next Step: Convert to TensorFlow.js format\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nRun the following commands:\")\n",
        "print(\"\\n  pip install tensorflowjs\")\n",
        "print(\"\\n  tensorflowjs_converter --input_format=keras \\\\\")\n",
        "print(\"      final_asl_model.h5 \\\\\")\n",
        "print(\"      ./tfjs_model/\")\n",
        "print(\"\\nAfter conversion, place the files in './tfjs_model/' folder\")\n",
        "print(\"into the same directory as your web application.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Summary of improvements made\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KEY IMPROVEMENTS IN THIS VERSION:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. ✓ Removed horizontal_flip (critical for sign language)\")\n",
        "print(\"2. ✓ Lowered learning rate from 0.001 to 0.0001\")\n",
        "print(\"3. ✓ Increased data per class from 600 to 2000 images\")\n",
        "print(\"4. ✓ Simplified model architecture (reduced parameters)\")\n",
        "print(\"5. ✓ Reduced augmentation intensity\")\n",
        "print(\"6. ✓ Increased batch size from 64 to 128\")\n",
        "print(\"7. ✓ Increased patience for callbacks\")\n",
        "print(\"8. ✓ Set random seeds for reproducibility\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1tRZ3QQ4v74k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [**ASL Sign Language Recognition Web App**](https://tztechno.github.io/tz_tensorflowjs/03_ASL_Alphabet/index.html)"
      ],
      "metadata": {
        "id": "GQ7ukk9av74l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F5q3EaFcv74l"
      }
    }
  ]
}