{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 49349,
          "databundleVersionId": 5447706,
          "sourceType": "competition"
        },
        {
          "sourceId": 91498,
          "databundleVersionId": 11655853,
          "sourceType": "competition"
        },
        {
          "sourceId": 289936912,
          "sourceType": "kernelVersion"
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tztechno/cc_archive/blob/main/Gaussian_Splat_w_DINO%2BALIKED_OK_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fountain: Gaussian Splat w/ DINO+ALIKED**"
      ],
      "metadata": {
        "id": "lUpuiNI_IQq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#ã‚µã‚¤ã‚ºã®ç•°ãªã‚‹ç”»åƒã‚’æ‰±ã†\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9kAhlZHTIqC",
        "outputId": "c71dcf21-0bd7-49e3-aa50-31fa24761f91"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "IMAGE_DIR = \"/content/drive/MyDrive/your_folder/fountain2\"\n",
        "WORK_DIR = '/content/gaussian_splatting'\n",
        "OUTPUT_DIR = '/content/output'\n",
        "COLMAP_DIR = '/content/colmap_data'\n",
        "\n",
        "ORIGINAL = IMAGE_DIR\n",
        "RESIZED='/content/resized'"
      ],
      "metadata": {
        "id": "NlvpKXz1IudB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ZIMDLmkV1rj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def run_cmd(cmd, check=True, capture=False):\n",
        "    \"\"\"Run command with better error handling\"\"\"\n",
        "    print(f\"Running: {' '.join(cmd)}\")\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        capture_output=capture,\n",
        "        text=True,\n",
        "        check=False\n",
        "    )\n",
        "    if check and result.returncode != 0:\n",
        "        print(f\"âŒ Command failed with code {result.returncode}\")\n",
        "        if capture:\n",
        "            print(f\"STDOUT: {result.stdout}\")\n",
        "            print(f\"STDERR: {result.stderr}\")\n",
        "    return result\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"\n",
        "    Colab environment setup for Gaussian Splatting + LightGlue + pycolmap\n",
        "    Python 3.12 compatible version (v8)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"ðŸš€ Setting up COLAB environment (v8 - Python 3.12 compatible)\")\n",
        "\n",
        "    WORK_DIR = \"/content/gaussian-splatting\"\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 0: NumPy FIX (Python 3.12 compatible)\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 0: Fix NumPy (Python 3.12 compatible)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Python 3.12 requires numpy >= 1.26\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"numpy\"])\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\"])\n",
        "\n",
        "    # sanity check\n",
        "    run_cmd([sys.executable, \"-c\", \"import numpy; print('NumPy:', numpy.__version__)\"])\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 1: System packages (Colab)\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 1: System packages\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    run_cmd([\"apt-get\", \"update\", \"-qq\"])\n",
        "    run_cmd([\n",
        "        \"apt-get\", \"install\", \"-y\", \"-qq\",\n",
        "        \"colmap\",\n",
        "        \"build-essential\",\n",
        "        \"cmake\",\n",
        "        \"git\",\n",
        "        \"libopenblas-dev\",\n",
        "        \"xvfb\"\n",
        "    ])\n",
        "\n",
        "    # virtual display (COLMAP / OpenCV safety)\n",
        "    os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n",
        "    os.environ[\"DISPLAY\"] = \":99\"\n",
        "    subprocess.Popen(\n",
        "        [\"Xvfb\", \":99\", \"-screen\", \"0\", \"1024x768x24\"],\n",
        "        stdout=subprocess.DEVNULL,\n",
        "        stderr=subprocess.DEVNULL\n",
        "    )\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 2: Clone Gaussian Splatting\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 2: Clone Gaussian Splatting\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if not os.path.exists(WORK_DIR):\n",
        "        run_cmd([\n",
        "            \"git\", \"clone\", \"--recursive\",\n",
        "            \"https://github.com/graphdeco-inria/gaussian-splatting.git\",\n",
        "            WORK_DIR\n",
        "        ])\n",
        "    else:\n",
        "        print(\"âœ“ Repository already exists\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 3: Python packages (FIXED ORDER & VERSIONS)\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 3: Python packages (VERBOSE MODE)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ---- PyTorch (Colab CUDAå¯¾å¿œ) ----\n",
        "    print(\"\\nðŸ“¦ Installing PyTorch...\")\n",
        "    run_cmd([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"torch\", \"torchvision\", \"torchaudio\"\n",
        "    ])\n",
        "\n",
        "    # ---- Core utils ----\n",
        "    print(\"\\nðŸ“¦ Installing core utilities...\")\n",
        "    run_cmd([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"opencv-python\",\n",
        "        \"pillow\",\n",
        "        \"imageio\",\n",
        "        \"imageio-ffmpeg\",\n",
        "        \"plyfile\",\n",
        "        \"tqdm\",\n",
        "        \"tensorboard\"\n",
        "    ])\n",
        "\n",
        "    # ---- transformers (NumPy 1.26 compatible) ----\n",
        "    print(\"\\nðŸ“¦ Installing transformers (NumPy 1.26 compatible)...\")\n",
        "    # Install transformers with proper dependencies\n",
        "    run_cmd([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"transformers==4.40.0\"\n",
        "    ])\n",
        "\n",
        "    # ---- LightGlue stack (GITHUB INSTALL) ----\n",
        "    print(\"\\nðŸ“¦ Installing LightGlue stack...\")\n",
        "\n",
        "    # Install kornia first\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"kornia\"])\n",
        "\n",
        "    # Install h5py (sometimes needed)\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"h5py\"])\n",
        "\n",
        "    # Install matplotlib (LightGlue dependency)\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\"])\n",
        "\n",
        "    # Install LightGlue directly from GitHub (more reliable)\n",
        "    print(\"  Installing LightGlue from GitHub...\")\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "            \"git+https://github.com/cvg/LightGlue.git\"])\n",
        "\n",
        "    # Install pycolmap\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"pycolmap\"])\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 4: Build GS submodules\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 4: Build Gaussian Splatting submodules\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    submodules = {\n",
        "        \"diff-gaussian-rasterization\":\n",
        "            \"https://github.com/graphdeco-inria/diff-gaussian-rasterization.git\",\n",
        "        \"simple-knn\":\n",
        "            \"https://github.com/camenduru/simple-knn.git\"\n",
        "    }\n",
        "\n",
        "    for name, repo in submodules.items():\n",
        "        print(f\"\\nðŸ“¦ Installing {name}...\")\n",
        "        path = os.path.join(WORK_DIR, \"submodules\", name)\n",
        "        if not os.path.exists(path):\n",
        "            run_cmd([\"git\", \"clone\", repo, path])\n",
        "        run_cmd([sys.executable, \"-m\", \"pip\", \"install\", path])\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 5: Detailed Verification\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 5: Detailed Verification\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # NumPy (verify version first)\n",
        "    print(\"\\nðŸ” Testing NumPy...\")\n",
        "    try:\n",
        "        import numpy as np\n",
        "        print(f\"  âœ“ NumPy: {np.__version__}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ NumPy failed: {e}\")\n",
        "\n",
        "    # PyTorch\n",
        "    print(\"\\nðŸ” Testing PyTorch...\")\n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"  âœ“ PyTorch: {torch.__version__}\")\n",
        "        print(f\"  âœ“ CUDA available: {torch.cuda.is_available()}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"  âœ“ CUDA version: {torch.version.cuda}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ PyTorch failed: {e}\")\n",
        "\n",
        "    # transformers\n",
        "    print(\"\\nðŸ” Testing transformers...\")\n",
        "    try:\n",
        "        import transformers\n",
        "        print(f\"  âœ“ transformers version: {transformers.__version__}\")\n",
        "        from transformers import AutoModel\n",
        "        print(f\"  âœ“ AutoModel import: OK\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ transformers failed: {e}\")\n",
        "        print(f\"  Attempting detailed diagnosis...\")\n",
        "        result = run_cmd([\n",
        "            sys.executable, \"-c\",\n",
        "            \"import transformers; print(transformers.__version__)\"\n",
        "        ], capture=True)\n",
        "        print(f\"  Output: {result.stdout}\")\n",
        "        print(f\"  Error: {result.stderr}\")\n",
        "\n",
        "    # LightGlue\n",
        "    print(\"\\nðŸ” Testing LightGlue...\")\n",
        "    try:\n",
        "        from lightglue import LightGlue, ALIKED\n",
        "        print(f\"  âœ“ LightGlue: OK\")\n",
        "        print(f\"  âœ“ ALIKED: OK\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ LightGlue failed: {e}\")\n",
        "        print(f\"  Attempting detailed diagnosis...\")\n",
        "        result = run_cmd([\n",
        "            sys.executable, \"-c\",\n",
        "            \"from lightglue import LightGlue\"\n",
        "        ], capture=True)\n",
        "        print(f\"  Output: {result.stdout}\")\n",
        "        print(f\"  Error: {result.stderr}\")\n",
        "\n",
        "    # pycolmap\n",
        "    print(\"\\nðŸ” Testing pycolmap...\")\n",
        "    try:\n",
        "        import pycolmap\n",
        "        print(f\"  âœ“ pycolmap: OK\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ pycolmap failed: {e}\")\n",
        "\n",
        "    # kornia\n",
        "    print(\"\\nðŸ” Testing kornia...\")\n",
        "    try:\n",
        "        import kornia\n",
        "        print(f\"  âœ“ kornia: {kornia.__version__}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ kornia failed: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"âœ… SETUP COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Working dir: {WORK_DIR}\")\n",
        "\n",
        "    return WORK_DIR\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    setup_environment()"
      ],
      "metadata": {
        "id": "-dxG5w4dZlIz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uuHc-fcmV1Vj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image_sizes(image_dir, output_dir=None, target_size=1200, mode='fit'):\n",
        "    \"\"\"\n",
        "    Resizes all images in a directory while maintaining aspect ratio.\n",
        "\n",
        "    Args:\n",
        "        image_dir: Directory containing input images.\n",
        "        output_dir: Directory to save the processed images. Defaults to image_dir.\n",
        "        target_size: The desired maximum size for the longer side (or minimum size for the shorter side).\n",
        "        mode: Resizing mode - 'fit' (fit within target), 'fill' (fill target), or 'pad' (fit with padding).\n",
        "    \"\"\"\n",
        "    if output_dir is None:\n",
        "        output_dir = image_dir\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Normalizing image sizes (mode: {mode}) while maintaining aspect ratio...\")\n",
        "\n",
        "    size_stats = {}\n",
        "    converted_count = 0\n",
        "\n",
        "    for img_file in sorted(os.listdir(image_dir)):\n",
        "        if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            continue\n",
        "\n",
        "        input_path = os.path.join(image_dir, img_file)\n",
        "        output_path = os.path.join(output_dir, img_file)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(input_path)\n",
        "            original_size = img.size  # (width, height)\n",
        "            original_aspect = original_size[0] / original_size[1]\n",
        "\n",
        "            # Record original size for statistics\n",
        "            size_key = f\"{original_size[0]}x{original_size[1]}\"\n",
        "            if size_key not in size_stats:\n",
        "                size_stats[size_key] = 0\n",
        "            size_stats[size_key] += 1\n",
        "\n",
        "            # Resize while maintaining aspect ratio\n",
        "            if mode == 'fit':\n",
        "                # Fit within target (é•·è¾ºã‚’target_sizeã«åˆã‚ã›ã¦ãƒªã‚µã‚¤ã‚º)\n",
        "                if original_size[0] > original_size[1]:  # æ¨ªé•·\n",
        "                    new_width = target_size\n",
        "                    new_height = int(target_size / original_aspect)\n",
        "                else:  # ç¸¦é•· or æ­£æ–¹å½¢\n",
        "                    new_height = target_size\n",
        "                    new_width = int(target_size * original_aspect)\n",
        "\n",
        "            elif mode == 'fill':\n",
        "                # Fill target (çŸ­è¾ºã‚’target_sizeã«åˆã‚ã›ã¦ãƒªã‚µã‚¤ã‚º)\n",
        "                if original_size[0] > original_size[1]:  # æ¨ªé•·\n",
        "                    new_height = target_size\n",
        "                    new_width = int(target_size * original_aspect)\n",
        "                else:  # ç¸¦é•· or æ­£æ–¹å½¢\n",
        "                    new_width = target_size\n",
        "                    new_height = int(target_size / original_aspect)\n",
        "\n",
        "            elif mode == 'pad':\n",
        "                # Fit with padding (çŸ­è¾ºã‚’target_sizeã«åˆã‚ã›ã¦ã€ä½™ç™½ã‚’è¿½åŠ )\n",
        "                if original_size[0] > original_size[1]:  # æ¨ªé•·\n",
        "                    new_width = target_size\n",
        "                    new_height = int(target_size / original_aspect)\n",
        "                else:  # ç¸¦é•· or æ­£æ–¹å½¢\n",
        "                    new_height = target_size\n",
        "                    new_width = int(target_size * original_aspect)\n",
        "\n",
        "                # ä½™ç™½ã‚’è¿½åŠ ã—ã¦æ­£æ–¹å½¢ã«ã™ã‚‹\n",
        "                img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "                img_square = Image.new('RGB', (target_size, target_size), (255, 255, 255))\n",
        "                offset = ((target_size - new_width) // 2, (target_size - new_height) // 2)\n",
        "                img_square.paste(img_resized, offset)\n",
        "                img = img_square\n",
        "                print(f\"  âœ“ {img_file}: {original_size} â†’ {new_width}x{new_height} (padded to {target_size}x{target_size})\")\n",
        "                img.save(output_path, quality=95)\n",
        "                converted_count += 1\n",
        "                continue\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown mode: {mode}. Use 'fit', 'fill', or 'pad'.\")\n",
        "\n",
        "            # ãƒªã‚µã‚¤ã‚ºå®Ÿè¡Œ\n",
        "            img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "            img_resized.save(output_path, quality=95)\n",
        "            converted_count += 1\n",
        "\n",
        "            print(f\"  âœ“ {img_file}: {original_size} â†’ {new_width}x{new_height} (aspect ratio: {original_aspect:.2f})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  âœ— Error processing {img_file}: {e}\")\n",
        "\n",
        "    print(f\"\\nConversion complete: {converted_count} images\")\n",
        "    print(f\"Original size distribution: {size_stats}\")\n",
        "    return converted_count\n",
        "\n",
        "\n",
        "\n",
        "converted_count=normalize_image_sizes(ORIGINAL, RESIZED, target_size=1000, mode='fit')\n",
        "print(converted_count)\n"
      ],
      "metadata": {
        "id": "IxSbne6AMqVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35daf5d-7e88-4020-b7b1-83ce9863d8bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizing image sizes (mode: fit) while maintaining aspect ratio...\n",
            "  âœ“ image_000.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_001.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_002.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_003.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_004.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_005.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_006.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_007.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_008.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_009.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_010.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_011.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_012.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_013.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_014.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_015.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_016.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_017.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_018.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_019.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_020.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_021.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_022.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_023.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_024.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_025.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_026.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_027.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_028.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_029.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_030.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_031.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_032.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_033.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_034.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_035.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_036.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_037.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_038.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_039.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_040.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_041.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_042.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_043.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_044.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_045.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_046.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_047.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_048.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_049.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_050.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_051.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_052.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_053.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_054.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_055.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_056.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_057.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_058.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_059.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_060.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_061.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_062.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_063.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_064.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_065.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_066.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_067.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_068.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_069.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_070.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_071.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_072.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_073.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_074.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_075.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_076.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_077.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_078.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "  âœ“ image_079.jpeg: (1440, 1920) â†’ 750x1000 (aspect ratio: 0.75)\n",
            "\n",
            "Conversion complete: 80 images\n",
            "Original size distribution: {'1440x1920': 80}\n",
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOjRkVS7PZpA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import glob\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import h5py\n",
        "import sqlite3\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import kornia as K\n",
        "import kornia.feature as KF\n",
        "from lightglue import ALIKED, LightGlue\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "import pycolmap\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CONFIG:\n",
        "    GLOBAL_TOPK = 200\n",
        "    RATIO_THR = 1.2\n",
        "    MATCH_THRESH = 10\n",
        "    N_KEYPOINTS = 2048\n",
        "    exhaustive_if_less = 20\n",
        "    min_matches = 15\n",
        "    max_num_keypoints = 8192\n",
        "    image_size = 1024\n",
        "    colmap_camera_model = 'SIMPLE_RADIAL'"
      ],
      "metadata": {
        "trusted": true,
        "id": "IsqmL7haIQq3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "09f0e741-9a83-461a-965a-b093a02484fe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "tokenizers>=0.19,<0.20 is required for a normal functioning of this module, but found tokenizers==0.22.1.\nTry: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3014031954.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkornia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mKF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightglue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALIKED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightGlue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoImageProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycolmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# not required, check version only if installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"can't find {pkg} in {deps.keys()}, check dependency_versions_table.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;34m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mhint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Try: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwanted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0m_compare_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgot_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwant_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;34mf\"{requirement} is required for a normal functioning of this module, but found {pkg}=={got_ver}.{hint}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         )\n",
            "\u001b[0;31mImportError\u001b[0m: tokenizers>=0.19,<0.20 is required for a normal functioning of this module, but found tokenizers==0.22.1.\nTry: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# COLMAP Database Utilities\n",
        "# =========================================================\n",
        "class COLMAPDatabase:\n",
        "    @staticmethod\n",
        "    def connect(database_path):\n",
        "        return COLMAPDatabase(database_path)\n",
        "\n",
        "    def __init__(self, database_path):\n",
        "        self.connection = sqlite3.connect(database_path)\n",
        "        self.cursor = self.connection.cursor()\n",
        "\n",
        "    def create_tables(self):\n",
        "        self.cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS cameras (\n",
        "                camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "                model INTEGER NOT NULL,\n",
        "                width INTEGER NOT NULL,\n",
        "                height INTEGER NOT NULL,\n",
        "                params BLOB,\n",
        "                prior_focal_length INTEGER NOT NULL\n",
        "            )\n",
        "        \"\"\")\n",
        "        self.cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS images (\n",
        "                image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "                name TEXT NOT NULL UNIQUE,\n",
        "                camera_id INTEGER NOT NULL,\n",
        "                prior_qw REAL,\n",
        "                prior_qx REAL,\n",
        "                prior_qy REAL,\n",
        "                prior_qz REAL,\n",
        "                prior_tx REAL,\n",
        "                prior_ty REAL,\n",
        "                prior_tz REAL,\n",
        "                CONSTRAINT image_id_check CHECK(image_id >= 0 and image_id < 2147483647),\n",
        "                FOREIGN KEY(camera_id) REFERENCES cameras(camera_id)\n",
        "            )\n",
        "        \"\"\")\n",
        "        self.cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS keypoints (\n",
        "                image_id INTEGER PRIMARY KEY NOT NULL,\n",
        "                rows INTEGER NOT NULL,\n",
        "                cols INTEGER NOT NULL,\n",
        "                data BLOB,\n",
        "                FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE\n",
        "            )\n",
        "        \"\"\")\n",
        "        self.cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS matches (\n",
        "                pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "                rows INTEGER NOT NULL,\n",
        "                cols INTEGER NOT NULL,\n",
        "                data BLOB\n",
        "            )\n",
        "        \"\"\")\n",
        "        self.cursor.execute(\"CREATE UNIQUE INDEX IF NOT EXISTS index_name ON images(name)\")\n",
        "\n",
        "    def add_camera(self, model, width, height, params, prior_focal_length=1):\n",
        "        params_blob = np.array(params, dtype=np.float64).tobytes()\n",
        "        self.cursor.execute(\n",
        "            \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "            (None, model, width, height, params_blob, prior_focal_length)\n",
        "        )\n",
        "        return self.cursor.lastrowid\n",
        "\n",
        "    def add_image(self, name, camera_id, prior_q=None, prior_t=None):\n",
        "        if prior_q is None:\n",
        "            prior_q = [1.0, 0.0, 0.0, 0.0]\n",
        "        if prior_t is None:\n",
        "            prior_t = [0.0, 0.0, 0.0]\n",
        "\n",
        "        self.cursor.execute(\n",
        "            \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "            (None, name, camera_id, *prior_q, *prior_t)\n",
        "        )\n",
        "        return self.cursor.lastrowid\n",
        "\n",
        "    def add_keypoints(self, image_id, keypoints):\n",
        "        if keypoints.dtype != np.float32:\n",
        "            keypoints = keypoints.astype(np.float32)\n",
        "\n",
        "        self.cursor.execute(\n",
        "            \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
        "            (image_id, keypoints.shape[0], keypoints.shape[1], keypoints.tobytes())\n",
        "        )\n",
        "\n",
        "    def add_matches(self, image_id1, image_id2, matches):\n",
        "        pair_id = self.image_ids_to_pair_id(image_id1, image_id2)\n",
        "\n",
        "        if matches.dtype != np.uint32:\n",
        "            matches = matches.astype(np.uint32)\n",
        "\n",
        "        self.cursor.execute(\n",
        "            \"INSERT OR REPLACE INTO matches VALUES (?, ?, ?, ?)\",\n",
        "            (pair_id, matches.shape[0], matches.shape[1], matches.tobytes())\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def image_ids_to_pair_id(image_id1, image_id2):\n",
        "        if image_id1 > image_id2:\n",
        "            image_id1, image_id2 = image_id2, image_id1\n",
        "        return image_id1 * 2147483648 + image_id2\n",
        "\n",
        "    def commit(self):\n",
        "        self.connection.commit()\n",
        "\n",
        "    def close(self):\n",
        "        self.connection.close()\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# H5 to Database Import\n",
        "# =========================================================\n",
        "CAMERA_MODEL_IDS = {\n",
        "    'SIMPLE_PINHOLE': 0,\n",
        "    'PINHOLE': 1,\n",
        "    'SIMPLE_RADIAL': 2,\n",
        "    'RADIAL': 3,\n",
        "    'OPENCV': 4,\n",
        "    'OPENCV_FISHEYE': 5,\n",
        "}\n",
        "\n",
        "def create_camera(db, image_path, camera_model):\n",
        "    \"\"\"Create camera entry\"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    width, height = img.size\n",
        "\n",
        "    # Simple radial model: f, cx, cy, k\n",
        "    focal = max(width, height) * 1.2\n",
        "    params = [focal, width/2, height/2, 0.0]\n",
        "\n",
        "    model_id = CAMERA_MODEL_IDS.get(camera_model.upper(), 2)\n",
        "    camera_id = db.add_camera(model_id, width, height, params)\n",
        "\n",
        "    return camera_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-05T05:48:39.582671Z",
          "iopub.execute_input": "2026-01-05T05:48:39.58323Z",
          "iopub.status.idle": "2026-01-05T05:48:39.596493Z",
          "shell.execute_reply.started": "2026-01-05T05:48:39.58321Z",
          "shell.execute_reply": "2026-01-05T05:48:39.595782Z"
        },
        "id": "vNwfOXztIQq4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def import_into_colmap(image_dir, feature_dir, database_path):\n",
        "    \"\"\"COLMAP Database Import - Multiple Cameras Support\"\"\"\n",
        "    print(\"\\n=== Creating COLMAP Database ===\")\n",
        "\n",
        "    if os.path.exists(database_path):\n",
        "        os.remove(database_path)\n",
        "\n",
        "    # Create empty database structure\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create all tables\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cameras (\n",
        "            camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "            model INTEGER NOT NULL,\n",
        "            width INTEGER NOT NULL,\n",
        "            height INTEGER NOT NULL,\n",
        "            params BLOB,\n",
        "            prior_focal_length INTEGER NOT NULL\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS images (\n",
        "            image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "            name TEXT NOT NULL UNIQUE,\n",
        "            camera_id INTEGER NOT NULL,\n",
        "            prior_qw REAL,\n",
        "            prior_qx REAL,\n",
        "            prior_qy REAL,\n",
        "            prior_qz REAL,\n",
        "            prior_tx REAL,\n",
        "            prior_ty REAL,\n",
        "            prior_tz REAL,\n",
        "            FOREIGN KEY(camera_id) REFERENCES cameras(camera_id)\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS keypoints (\n",
        "            image_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB,\n",
        "            FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS matches (\n",
        "            pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
        "            pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB,\n",
        "            config INTEGER NOT NULL,\n",
        "            F BLOB,\n",
        "            E BLOB,\n",
        "            H BLOB,\n",
        "            qvec BLOB,\n",
        "            tvec BLOB\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    # Load keypoints file\n",
        "    kpts_file = os.path.join(feature_dir, 'keypoints.h5')\n",
        "    matches_file = os.path.join(feature_dir, 'matches.h5')\n",
        "\n",
        "    # Create cameras based on image sizes\n",
        "    size_to_camera = {}  # (width, height) -> camera_id\n",
        "    fname_to_id = {}\n",
        "    image_id = 1\n",
        "\n",
        "    with h5py.File(kpts_file, 'r') as f:\n",
        "        print(f\"Importing {len(f.keys())} images...\")\n",
        "\n",
        "        for filename in tqdm(f.keys(), desc=\"Adding images\"):\n",
        "            # Get image size\n",
        "            image_path = os.path.join(image_dir, filename)\n",
        "            try:\n",
        "                img = Image.open(image_path)\n",
        "                width, height = img.size\n",
        "                img.close()\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Cannot open {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Get or create camera for this size\n",
        "            size_key = (width, height)\n",
        "            if size_key not in size_to_camera:\n",
        "                focal = max(width, height) * 1.2\n",
        "                params = np.array([focal, width/2, height/2, 0.0], dtype=np.float64)\n",
        "\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "                    (None, 2, width, height, params.tobytes(), 1)  # 2 = SIMPLE_RADIAL\n",
        "                )\n",
        "                camera_id = cursor.lastrowid\n",
        "                size_to_camera[size_key] = camera_id\n",
        "            else:\n",
        "                camera_id = size_to_camera[size_key]\n",
        "\n",
        "            # Add image\n",
        "            cursor.execute(\n",
        "                \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "                (image_id, filename, camera_id, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "            )\n",
        "            fname_to_id[filename] = image_id\n",
        "\n",
        "            # Add keypoints\n",
        "            kpts = f[filename][()].astype(np.float32)\n",
        "            if len(kpts.shape) == 1:\n",
        "                kpts = kpts.reshape(-1, 2)\n",
        "\n",
        "            cursor.execute(\n",
        "                \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
        "                (image_id, kpts.shape[0], 2, kpts.tobytes())\n",
        "            )\n",
        "\n",
        "            image_id += 1\n",
        "\n",
        "    print(f\"\\nCreated {len(size_to_camera)} camera(s) for different image sizes:\")\n",
        "    for size, cam_id in sorted(size_to_camera.items()):\n",
        "        print(f\"  Camera {cam_id}: {size[0]}x{size[1]}\")\n",
        "\n",
        "    # Add matches\n",
        "    total_matches = 0\n",
        "    total_match_count = 0\n",
        "    with h5py.File(matches_file, 'r') as f:\n",
        "        print(f\"\\nProcessing matches...\")\n",
        "        for key1 in tqdm(f.keys(), desc=\"Adding matches\"):\n",
        "            if key1 not in fname_to_id:\n",
        "                continue\n",
        "            for key2 in f[key1].keys():\n",
        "                if key2 not in fname_to_id:\n",
        "                    continue\n",
        "\n",
        "                id1, id2 = fname_to_id[key1], fname_to_id[key2]\n",
        "                if id1 >= id2:\n",
        "                    continue\n",
        "\n",
        "                matches = f[key1][key2][()].astype(np.uint32)\n",
        "                if matches.shape[0] == 0:\n",
        "                    continue\n",
        "\n",
        "                pair_id = id1 * 2147483648 + id2\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO matches VALUES (?, ?, ?, ?)\",\n",
        "                    (pair_id, matches.shape[0], 2, matches.tobytes())\n",
        "                )\n",
        "                total_matches += 1\n",
        "                total_match_count += matches.shape[0]\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"\\nâœ“ Database created: {database_path}\")\n",
        "    print(f\"  Cameras: {len(size_to_camera)}\")\n",
        "    print(f\"  Images: {len(fname_to_id)}\")\n",
        "    print(f\"  Match pairs: {total_matches}\")\n",
        "    print(f\"  Total matches: {total_match_count}\")\n",
        "\n",
        "    return fname_to_id"
      ],
      "metadata": {
        "trusted": true,
        "id": "APfi4SJrIQq4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_torch_image(fname, device=torch.device('cuda')):\n",
        "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
        "    return img\n",
        "\n",
        "\n",
        "def extract_dino_embeddings(fnames, device=torch.device('cuda')):\n",
        "    print(\"\\n=== Stage 1: Extracting DINO Global Features ===\")\n",
        "\n",
        "    processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
        "    model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
        "    model = model.eval().to(device)\n",
        "\n",
        "    global_descs = []\n",
        "    for img_path in tqdm(fnames, desc=\"DINO extraction\"):\n",
        "        timg = load_torch_image(img_path, device)\n",
        "        with torch.inference_mode():\n",
        "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
        "            outputs = model(**inputs)\n",
        "            dino_feat = F.normalize(\n",
        "                outputs.last_hidden_state[:,1:].max(dim=1)[0],\n",
        "                dim=1, p=2\n",
        "            )\n",
        "        global_descs.append(dino_feat.detach().cpu())\n",
        "\n",
        "    global_descs = torch.cat(global_descs, dim=0)\n",
        "    print(f\"Extracted global features: {global_descs.shape}\")\n",
        "\n",
        "    del model, processor\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return global_descs\n",
        "\n",
        "\n",
        "def build_topk_pairs(global_feats, device):\n",
        "    print(\"\\n=== Building Top-K Pairs from Global Features ===\")\n",
        "\n",
        "    g = global_feats.to(device)\n",
        "    sim = g @ g.T\n",
        "    sim.fill_diagonal_(-1)\n",
        "\n",
        "    N = sim.size(0)\n",
        "    k = min(CONFIG.GLOBAL_TOPK, N - 1)\n",
        "    k = max(k, 1)\n",
        "\n",
        "    topk_indices = torch.topk(sim, k, dim=1).indices.cpu()\n",
        "\n",
        "    pairs = set()\n",
        "    for i, neighbors in enumerate(topk_indices):\n",
        "        for j in neighbors:\n",
        "            j = j.item()\n",
        "            if i < j:\n",
        "                pairs.add((i, j))\n",
        "\n",
        "    pairs = sorted(list(pairs))\n",
        "    print(f\"Initial pairs from global features: {len(pairs)}\")\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def extract_aliked_features(fnames, device=torch.device('cuda')):\n",
        "    print(\"\\n=== Stage 2: Extracting ALIKED Local Features ===\")\n",
        "\n",
        "    dtype = torch.float32\n",
        "    extractor = ALIKED(\n",
        "        model_name=\"aliked-n16\",\n",
        "        max_num_keypoints=CONFIG.max_num_keypoints,\n",
        "        detection_threshold=0.01,\n",
        "        resize=CONFIG.image_size\n",
        "    ).eval().to(device, dtype)\n",
        "\n",
        "    keypoints_dict = {}\n",
        "    descriptors_dict = {}\n",
        "\n",
        "    for img_path in tqdm(fnames, desc=\"ALIKED extraction\"):\n",
        "        key = os.path.basename(img_path)\n",
        "        image = load_torch_image(img_path, device=device).to(dtype)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            feats = extractor.extract(image)\n",
        "            kpts = feats['keypoints'].reshape(-1, 2).detach().cpu()\n",
        "            descs = feats['descriptors'].reshape(-1, 128).detach().cpu()\n",
        "            descs = F.normalize(descs, dim=1).half()\n",
        "\n",
        "        keypoints_dict[key] = kpts.numpy()\n",
        "        descriptors_dict[key] = descs\n",
        "\n",
        "    print(f\"Extracted features for {len(keypoints_dict)} images\")\n",
        "\n",
        "    del extractor\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return keypoints_dict, descriptors_dict\n",
        "\n",
        "\n",
        "def verify_pairs_with_local_features(pairs, fnames, descriptors_dict, device):\n",
        "    print(\"\\n=== Verifying Pairs with Local Features ===\")\n",
        "\n",
        "    verified_pairs = []\n",
        "\n",
        "    for i, j in tqdm(pairs, desc=\"Local verification\"):\n",
        "        key1 = os.path.basename(fnames[i])\n",
        "        key2 = os.path.basename(fnames[j])\n",
        "\n",
        "        desc1 = descriptors_dict[key1].to(device)\n",
        "        desc2 = descriptors_dict[key2].to(device)\n",
        "\n",
        "        if desc1.size(0) == 0 or desc2.size(0) == 0:\n",
        "            continue\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            sim = desc1 @ desc2.T\n",
        "            nn1 = torch.argmax(sim, dim=1)\n",
        "            nn2 = torch.argmax(sim, dim=0)\n",
        "            mutual = torch.arange(len(nn1), device=device) == nn2[nn1]\n",
        "            n_matches = mutual.sum().item()\n",
        "\n",
        "        if n_matches >= CONFIG.MATCH_THRESH:\n",
        "            verified_pairs.append((i, j))\n",
        "\n",
        "    print(f\"Verified pairs: {len(verified_pairs)}\")\n",
        "    return verified_pairs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-05T05:48:39.620344Z",
          "iopub.execute_input": "2026-01-05T05:48:39.620528Z",
          "iopub.status.idle": "2026-01-05T05:48:39.635341Z",
          "shell.execute_reply.started": "2026-01-05T05:48:39.620512Z",
          "shell.execute_reply": "2026-01-05T05:48:39.634554Z"
        },
        "id": "paYlPoohIQq4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def match_with_lightglue(verified_pairs, fnames, keypoints_dict, descriptors_dict,\n",
        "                         output_dir, device=torch.device('cuda')):\n",
        "    \"\"\"Perform detailed matching using LightGlue - Fully Corrected Version\"\"\"\n",
        "    print(\"\\n=== Stage 3: Matching with LightGlue ===\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    lg_matcher = KF.LightGlueMatcher(\n",
        "        \"aliked\", {\n",
        "            \"width_confidence\": -1,\n",
        "            \"depth_confidence\": -1,\n",
        "            \"mp\": True if 'cuda' in str(device) else False\n",
        "        }\n",
        "    ).eval().to(device).half()\n",
        "\n",
        "    print(\"Loaded LightGlue model\")\n",
        "\n",
        "    # Save keypoints\n",
        "    kpts_h5_path = os.path.join(output_dir, 'keypoints.h5')\n",
        "    with h5py.File(kpts_h5_path, 'w') as f:\n",
        "        for img_path in fnames:\n",
        "            key = os.path.basename(img_path)\n",
        "            f.create_dataset(key, data=keypoints_dict[key])\n",
        "\n",
        "    # Save matches\n",
        "    matches_h5_path = os.path.join(output_dir, 'matches.h5')\n",
        "    matched_pairs = 0\n",
        "    skipped_pairs = 0\n",
        "    total_matches = 0\n",
        "\n",
        "    with h5py.File(matches_h5_path, 'w') as f_match:\n",
        "        for i, j in tqdm(verified_pairs, desc=\"LightGlue matching\"):\n",
        "            key1 = os.path.basename(fnames[i])\n",
        "            key2 = os.path.basename(fnames[j])\n",
        "\n",
        "            kp1 = torch.from_numpy(keypoints_dict[key1]).to(device).half()\n",
        "            kp2 = torch.from_numpy(keypoints_dict[key2]).to(device).half()\n",
        "            desc1 = descriptors_dict[key1].to(device)\n",
        "            desc2 = descriptors_dict[key2].to(device)\n",
        "\n",
        "            if len(kp1) == 0 or len(kp2) == 0:\n",
        "                skipped_pairs += 1\n",
        "                continue\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                try:\n",
        "                    dists, idxs = lg_matcher(\n",
        "                        desc1, desc2,\n",
        "                        KF.laf_from_center_scale_ori(kp1[None]),\n",
        "                        KF.laf_from_center_scale_ori(kp2[None])\n",
        "                    )\n",
        "\n",
        "                    # Check if matches were found\n",
        "                    if idxs.numel() == 0:\n",
        "                        skipped_pairs += 1\n",
        "                        continue\n",
        "\n",
        "                    # â˜…â˜…â˜… Fix: Removed [0] â˜…â˜…â˜…\n",
        "                    matches = idxs.cpu().numpy()  # (num_matches, 2)\n",
        "\n",
        "                    # Check match count\n",
        "                    num_matches = matches.shape[0]\n",
        "\n",
        "                    if num_matches >= CONFIG.min_matches:\n",
        "                        grp = f_match.require_group(key1)\n",
        "                        grp.create_dataset(key2, data=matches)\n",
        "                        matched_pairs += 1\n",
        "                        total_matches += num_matches\n",
        "                    else:\n",
        "                        skipped_pairs += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"\\nError matching {key1}-{key2}: {e}\")\n",
        "                    skipped_pairs += 1\n",
        "                    continue\n",
        "\n",
        "    del lg_matcher\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"\\nMatching complete:\")\n",
        "    print(f\"  Matched pairs: {matched_pairs}\")\n",
        "    print(f\"  Skipped pairs: {skipped_pairs}\")\n",
        "    print(f\"  Total matches: {total_matches}\")\n",
        "    print(f\"  Average matches per pair: {total_matches/matched_pairs:.1f}\" if matched_pairs > 0 else \"\")\n",
        "    print(f\"  Success rate: {matched_pairs/len(verified_pairs)*100:.1f}%\")\n",
        "\n",
        "    print(f\"\\nSaved keypoints to: {kpts_h5_path}\")\n",
        "    print(f\"Saved matches to: {matches_h5_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-05T05:48:39.636081Z",
          "iopub.execute_input": "2026-01-05T05:48:39.636374Z",
          "iopub.status.idle": "2026-01-05T05:48:39.655904Z",
          "shell.execute_reply.started": "2026-01-05T05:48:39.636356Z",
          "shell.execute_reply": "2026-01-05T05:48:39.655232Z"
        },
        "id": "33nQw3f2IQq5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cu8BVjF-SJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_colmap_sequential(database_path, image_dir, output_dir):\n",
        "    \"\"\"Run COLMAP mapper with manual initial pair\"\"\"\n",
        "    print(\"\\n=== Stage 4: Running COLMAP Reconstruction ===\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env['QT_QPA_PLATFORM'] = 'offscreen'\n",
        "\n",
        "    from datetime import datetime, timezone\n",
        "    print(f\"ðŸš€ Starting mapper at {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    print(\"ðŸ’¡ Using manual initial pair: images 11-20 (5859 matches)\")\n",
        "    print()\n",
        "\n",
        "    cmd_mapper = [\n",
        "        'colmap', 'mapper',\n",
        "        '--database_path', database_path,\n",
        "        '--image_path', image_dir,\n",
        "        '--output_path', output_dir,\n",
        "        # æ‰‹å‹•æŒ‡å®šãªã—ï¼ˆè‡ªå‹•ï¼‰\n",
        "        '--Mapper.ba_refine_focal_length', '1',\n",
        "        '--Mapper.ba_refine_principal_point', '1',\n",
        "        '--Mapper.ba_refine_extra_params', '1',\n",
        "        # æ¨™æº–çš„ãªè¨­å®š\n",
        "        '--Mapper.init_min_num_inliers', '50',\n",
        "        '--Mapper.init_max_error', '8',\n",
        "        '--Mapper.init_min_tri_angle', '4',\n",
        "    ]\n",
        "\n",
        "    import subprocess\n",
        "    process = subprocess.Popen(\n",
        "        cmd_mapper,\n",
        "        env=env,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        bufsize=1,\n",
        "        universal_newlines=True\n",
        "    )\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        if line:\n",
        "            print(line.rstrip(), flush=True)\n",
        "\n",
        "    process.stdout.close()\n",
        "    return_code = process.wait(timeout=3600)\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    if return_code == 0:\n",
        "        print(f\"\\nâœ… COLMAP reconstruction saved to: {output_dir}\")\n",
        "        print(f\"ðŸ• Completed at {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    else:\n",
        "        print(f\"\\nâŒ COLMAP mapper failed with return code {return_code}\")\n",
        "        raise subprocess.CalledProcessError(return_code, cmd_mapper)"
      ],
      "metadata": {
        "id": "qKD1nLUR1y-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_into_colmap(image_dir, feature_dir, database_path):\n",
        "    \"\"\"Import with camera grouping\"\"\"\n",
        "    print(\"\\n=== Creating COLMAP Database ===\")\n",
        "\n",
        "    if os.path.exists(database_path):\n",
        "        os.remove(database_path)\n",
        "\n",
        "    import cv2\n",
        "\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create tables\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cameras (\n",
        "            camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "            model INTEGER NOT NULL,\n",
        "            width INTEGER NOT NULL,\n",
        "            height INTEGER NOT NULL,\n",
        "            params BLOB,\n",
        "            prior_focal_length INTEGER NOT NULL\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS images (\n",
        "            image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "            name TEXT NOT NULL UNIQUE,\n",
        "            camera_id INTEGER NOT NULL,\n",
        "            prior_qw REAL,\n",
        "            prior_qx REAL,\n",
        "            prior_qy REAL,\n",
        "            prior_qz REAL,\n",
        "            prior_tx REAL,\n",
        "            prior_ty REAL,\n",
        "            prior_tz REAL,\n",
        "            FOREIGN KEY(camera_id) REFERENCES cameras(camera_id)\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS keypoints (\n",
        "            image_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB,\n",
        "            FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS matches (\n",
        "            pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
        "            pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB,\n",
        "            config INTEGER NOT NULL,\n",
        "            F BLOB,\n",
        "            E BLOB,\n",
        "            H BLOB,\n",
        "            qvec BLOB,\n",
        "            tvec BLOB\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    kpts_file = os.path.join(feature_dir, 'keypoints.h5')\n",
        "    matches_file = os.path.join(feature_dir, 'matches.h5')\n",
        "\n",
        "    # Camera grouping function\n",
        "    def get_camera_group(width, height, tolerance=100):\n",
        "        \"\"\"Group similar resolutions together\"\"\"\n",
        "        w_group = round(width / tolerance) * tolerance\n",
        "        h_group = round(height / tolerance) * tolerance\n",
        "        return (w_group, h_group)\n",
        "\n",
        "    # Add cameras and images\n",
        "    size_to_camera = {}\n",
        "    fname_to_id = {}\n",
        "    image_id = 1\n",
        "\n",
        "    with h5py.File(kpts_file, 'r') as f:\n",
        "        print(f\"Importing {len(f.keys())} images...\")\n",
        "\n",
        "        for filename in tqdm(f.keys(), desc=\"Adding images\"):\n",
        "            image_path = os.path.join(image_dir, filename)\n",
        "            try:\n",
        "                img = Image.open(image_path)\n",
        "                width, height = img.size\n",
        "                img.close()\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            # Get grouped camera key\n",
        "            size_key = get_camera_group(width, height, tolerance=50)\n",
        "\n",
        "            if size_key not in size_to_camera:\n",
        "                # Use group representative values\n",
        "                focal = max(size_key[0], size_key[1])  # 1.2å€ã‚’å‰Šé™¤\n",
        "                params = np.array([focal, size_key[0]/2, size_key[1]/2, 0.0], dtype=np.float64)\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "                    (None, 2, size_key[0], size_key[1], params.tobytes(), 1)\n",
        "                )\n",
        "                size_to_camera[size_key] = cursor.lastrowid\n",
        "                print(f\"  Created camera group: {size_key[0]}x{size_key[1]}, focal={focal:.0f}\")\n",
        "\n",
        "            camera_id = size_to_camera[size_key]\n",
        "            cursor.execute(\n",
        "                \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "                (image_id, filename, camera_id, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "            )\n",
        "            fname_to_id[filename] = image_id\n",
        "\n",
        "            kpts = f[filename][()].astype(np.float32)\n",
        "            if len(kpts.shape) == 1:\n",
        "                kpts = kpts.reshape(-1, 2)\n",
        "            cursor.execute(\n",
        "                \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
        "                (image_id, kpts.shape[0], 2, kpts.tobytes())\n",
        "            )\n",
        "            image_id += 1\n",
        "\n",
        "    print(f\"\\nâœ… Grouped into {len(size_to_camera)} camera(s) (from ~36 individual sizes)\")\n",
        "\n",
        "    # Geometric verification\n",
        "    verified_count = 0\n",
        "\n",
        "    with h5py.File(kpts_file, 'r') as f_kpts:\n",
        "        with h5py.File(matches_file, 'r') as f_matches:\n",
        "            print(f\"\\nðŸ”§ Processing matches with geometric verification...\")\n",
        "\n",
        "            for key1 in tqdm(f_matches.keys(), desc=\"Verifying\"):\n",
        "                if key1 not in fname_to_id:\n",
        "                    continue\n",
        "\n",
        "                for key2 in f_matches[key1].keys():\n",
        "                    if key2 not in fname_to_id:\n",
        "                        continue\n",
        "\n",
        "                    id1, id2 = fname_to_id[key1], fname_to_id[key2]\n",
        "                    if id1 >= id2:\n",
        "                        continue\n",
        "\n",
        "                    matches = f_matches[key1][key2][()].astype(np.uint32)\n",
        "                    if matches.shape[0] < 15:\n",
        "                        continue\n",
        "\n",
        "                    kpts1 = f_kpts[key1][()].astype(np.float64)\n",
        "                    kpts2 = f_kpts[key2][()].astype(np.float64)\n",
        "\n",
        "                    if len(kpts1.shape) == 1:\n",
        "                        kpts1 = kpts1.reshape(-1, 2)\n",
        "                    if len(kpts2.shape) == 1:\n",
        "                        kpts2 = kpts2.reshape(-1, 2)\n",
        "\n",
        "                    pts1 = kpts1[matches[:, 0]]\n",
        "                    pts2 = kpts2[matches[:, 1]]\n",
        "\n",
        "                    try:\n",
        "                        F, mask = cv2.findFundamentalMat(\n",
        "                            pts1, pts2,\n",
        "                            cv2.FM_RANSAC,\n",
        "                            3.0, 0.999\n",
        "                        )\n",
        "\n",
        "                        if F is None or mask is None:\n",
        "                            continue\n",
        "\n",
        "                        inliers = matches[mask.ravel() == 1]\n",
        "\n",
        "                        if len(inliers) < 15:\n",
        "                            continue\n",
        "\n",
        "                        pair_id = id1 * 2147483648 + id2\n",
        "\n",
        "                        cursor.execute(\n",
        "                            \"INSERT INTO matches VALUES (?, ?, ?, ?)\",\n",
        "                            (pair_id, len(inliers), 2, inliers.astype(np.uint32).tobytes())\n",
        "                        )\n",
        "\n",
        "                        cursor.execute(\n",
        "                            \"INSERT INTO two_view_geometries VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "                            (pair_id, len(inliers), 2, inliers.astype(np.uint32).tobytes(),\n",
        "                             2, F.astype(np.float64).tobytes(),\n",
        "                             None, None, None, None)\n",
        "                        )\n",
        "\n",
        "                        verified_count += 1\n",
        "\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"\\nâœ“ Database created: {database_path}\")\n",
        "    print(f\"  Camera groups: {len(size_to_camera)}\")\n",
        "    print(f\"  Images: {len(fname_to_id)}\")\n",
        "    print(f\"  âœ… Geometrically verified pairs: {verified_count}\")\n",
        "\n",
        "    return fname_to_id"
      ],
      "metadata": {
        "id": "7gQdy_QYTtjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_pipeline(image_dir, output_base_dir):\n",
        "    \"\"\"Complete pipeline\"\"\"\n",
        "\n",
        "    from datetime import datetime, timezone\n",
        "\n",
        "    print(f\"\\nðŸš€ Pipeline started at {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Get images\n",
        "    img_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "    fnames = []\n",
        "    for ext in img_extensions:\n",
        "        fnames.extend(glob.glob(os.path.join(image_dir, ext)))\n",
        "    fnames = sorted(fnames)\n",
        "    print(f\"\\nðŸ“¸ Found {len(fnames)} images\")\n",
        "\n",
        "    if len(fnames) == 0:\n",
        "        raise ValueError(\"No images found!\")\n",
        "\n",
        "    # Create directories\n",
        "    feature_dir = os.path.join(output_base_dir, 'features')\n",
        "    colmap_dir = os.path.join(output_base_dir, 'colmap')\n",
        "    sparse_dir = os.path.join(colmap_dir, 'sparse')\n",
        "    os.makedirs(feature_dir, exist_ok=True)\n",
        "    os.makedirs(colmap_dir, exist_ok=True)\n",
        "\n",
        "    # Stages 1-3: Feature extraction and matching\n",
        "    print(f\"\\nâ° Stage 1 started: {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    global_feats = extract_dino_embeddings(fnames, device)\n",
        "\n",
        "    print(f\"\\nâ° Stage 2 started: {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    initial_pairs = build_topk_pairs(global_feats, device)\n",
        "    keypoints_dict, descriptors_dict = extract_aliked_features(fnames, device)\n",
        "\n",
        "    print(f\"\\nâ° Stage 3 started: {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    verified_pairs = verify_pairs_with_local_features(\n",
        "        initial_pairs, fnames, descriptors_dict, device\n",
        "    )\n",
        "    match_with_lightglue(\n",
        "        verified_pairs, fnames, keypoints_dict, descriptors_dict,\n",
        "        feature_dir, device\n",
        "    )\n",
        "\n",
        "    from datetime import datetime, timezone\n",
        "    print()\n",
        "    print(datetime.now(timezone.utc))\n",
        "\n",
        "    print(f\"\\nâ° Stage 4 started: {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    # Stage 4: COLMAP Database + Reconstruction\n",
        "    database_path = os.path.join(colmap_dir, 'database.db')\n",
        "    #import_into_colmap(image_dir, feature_dir, database_path)\n",
        "    import_into_colmap(image_dir, feature_dir, database_path)\n",
        "    run_colmap_sequential(database_path, image_dir, sparse_dir)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"âœ… Pipeline Complete!\")\n",
        "    print(f\"ðŸ• Finished at {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "main_pipeline(RESIZED, OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "-bfvkO7NS-gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_cameras_to_pinhole(input_file, output_file):\n",
        "    \"\"\"Convert camera model to PINHOLE format, typically from OPENCV\"\"\"\n",
        "    print(f\"Reading camera file: {input_file}\")\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    converted_count = 0\n",
        "    with open(output_file, 'w') as f:\n",
        "        for line in lines:\n",
        "            # Write comments and empty lines directly\n",
        "            if line.startswith('#') or line.strip() == '':\n",
        "                f.write(line)\n",
        "            else:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 4:\n",
        "                    cam_id = parts[0]\n",
        "                    model = parts[1]\n",
        "                    width = parts[2]\n",
        "                    height = parts[3]\n",
        "                    params = parts[4:]\n",
        "\n",
        "                    # Convert to PINHOLE format\n",
        "                    if model == \"PINHOLE\":\n",
        "                        f.write(line)\n",
        "                    elif model == \"OPENCV\":\n",
        "                        # OPENCV: fx, fy, cx, cy, k1, k2, p1, p2 (only need first four for PINHOLE)\n",
        "                        fx = params[0]\n",
        "                        fy = params[1]\n",
        "                        cx = params[2]\n",
        "                        cy = params[3]\n",
        "                        # PINHOLE: fx, fy, cx, cy\n",
        "                        f.write(f\"{cam_id} PINHOLE {width} {height} {fx} {fy} {cx} {cy}\\n\")\n",
        "                        converted_count += 1\n",
        "                    else:\n",
        "                        # Convert other models by estimating PINHOLE parameters\n",
        "                        # Set focal length to the max of width/height, and principal point to the center\n",
        "                        fx = fy = max(float(width), float(height))\n",
        "                        cx = float(width) / 2\n",
        "                        cy = float(height) / 2\n",
        "                        f.write(f\"{cam_id} PINHOLE {width} {height} {fx} {fy} {cx} {cy}\\n\")\n",
        "                        converted_count += 1\n",
        "                else:\n",
        "                    # Write lines that don't match the expected format\n",
        "                    f.write(line)\n",
        "\n",
        "    print(f\"Converted {converted_count} cameras to PINHOLE format\")\n",
        "\n",
        "\n",
        "\n",
        "def prepare_gaussian_splatting_data(image_dir, colmap_model_dir):\n",
        "    \"\"\"Prepare data for Gaussian Splatting, structuring it in the expected format\"\"\"\n",
        "    print(\"Preparing data for Gaussian Splatting...\")\n",
        "\n",
        "    # Assumes WORK_DIR is defined globally or passed\n",
        "    data_dir = f\"{WORK_DIR}/data/video\"\n",
        "    os.makedirs(f\"{data_dir}/sparse/0\", exist_ok=True)\n",
        "    os.makedirs(f\"{data_dir}/images\", exist_ok=True)\n",
        "\n",
        "    # Copy images\n",
        "    print(\"Copying images...\")\n",
        "    img_count = 0\n",
        "    for img_file in os.listdir(image_dir):\n",
        "        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            shutil.copy(\n",
        "                os.path.join(image_dir, img_file),\n",
        "                f\"{data_dir}/images/{img_file}\"\n",
        "            )\n",
        "            img_count += 1\n",
        "    print(f\"Copied {img_count} images\")\n",
        "\n",
        "    # Convert and copy camera file to PINHOLE format\n",
        "    print(\"Converting camera model to PINHOLE format...\")\n",
        "    convert_cameras_to_pinhole(\n",
        "        os.path.join(colmap_model_dir, 'cameras.txt'),\n",
        "        f\"{data_dir}/sparse/0/cameras.txt\"\n",
        "    )\n",
        "\n",
        "    # Copy other files\n",
        "    for filename in ['images.txt', 'points3D.txt']:\n",
        "        src = os.path.join(colmap_model_dir, filename)\n",
        "        dst = f\"{data_dir}/sparse/0/{filename}\"\n",
        "        if os.path.exists(src):\n",
        "            shutil.copy(src, dst)\n",
        "            print(f\"Copied {filename}\")\n",
        "        else:\n",
        "            print(f\"Warning: {filename} not found\")\n",
        "\n",
        "    print(f\"Data preparation complete: {data_dir}\")\n",
        "    return data_dir\n",
        "\n",
        "\n",
        "\n",
        "def train_gaussian_splatting(data_dir, iterations=3000):\n",
        "    \"\"\"Train the Gaussian Splatting model\"\"\"\n",
        "    print(f\"Training Gaussian Splatting model for {iterations} iterations...\")\n",
        "\n",
        "    # Assumes WORK_DIR is defined globally or passed\n",
        "    model_path = f\"{WORK_DIR}/output/video\"\n",
        "\n",
        "    cmd = [\n",
        "        sys.executable, 'train.py',\n",
        "        '-s', data_dir,\n",
        "        '-m', model_path,\n",
        "        '--iterations', str(iterations),\n",
        "        '--eval' # Optionally run an evaluation phase\n",
        "    ]\n",
        "\n",
        "    # Execute the training script from the WORK_DIR\n",
        "    subprocess.run(cmd, cwd=WORK_DIR, check=True)\n",
        "\n",
        "    return model_path\n",
        "\n",
        "\n",
        "\n",
        "def render_video(model_path, output_video_path, iteration=3000):\n",
        "    \"\"\"Generate video from the trained model by rendering a sequence of views\"\"\"\n",
        "    print(\"Rendering video...\")\n",
        "\n",
        "    # Execute rendering\n",
        "    cmd = [\n",
        "        sys.executable, 'render.py',\n",
        "        '-m', model_path,\n",
        "        '--iteration', str(iteration)\n",
        "    ]\n",
        "\n",
        "    # Execute the rendering script from the WORK_DIR\n",
        "    subprocess.run(cmd, cwd=WORK_DIR, check=True)\n",
        "\n",
        "    # Find the rendering directory\n",
        "    possible_dirs = [\n",
        "        f\"{model_path}/test/ours_{iteration}/renders\",\n",
        "        f\"{model_path}/train/ours_{iteration}/renders\",\n",
        "    ]\n",
        "\n",
        "    render_dir = None\n",
        "    for test_dir in possible_dirs:\n",
        "        if os.path.exists(test_dir):\n",
        "            render_dir = test_dir\n",
        "            print(f\"Rendering directory found: {render_dir}\")\n",
        "            break\n",
        "\n",
        "    if render_dir and os.path.exists(render_dir):\n",
        "        # Sort rendered PNG images for correct video sequence\n",
        "        render_imgs = sorted([f for f in os.listdir(render_dir) if f.endswith('.png')])\n",
        "\n",
        "        if render_imgs:\n",
        "            print(f\"Found {len(render_imgs)} rendered images\")\n",
        "\n",
        "            # Create video with ffmpeg\n",
        "            # -y: overwrite output file without asking\n",
        "            # -framerate 30: set input framerate to 30 FPS\n",
        "            # -pattern_type glob -i: use glob pattern to specify input images\n",
        "            # -c:v libx264: use h.264 video codec\n",
        "            # -pix_fmt yuv420p: use a pixel format compatible with most players\n",
        "            # -crf 18: Constant Rate Factor (lower is higher quality, 18 is generally high quality)\n",
        "            subprocess.run([\n",
        "                'ffmpeg', '-y',\n",
        "                '-framerate', '30',\n",
        "                '-pattern_type', 'glob',\n",
        "                '-i', f\"{render_dir}/*.png\",\n",
        "                '-c:v', 'libx264',\n",
        "                '-pix_fmt', 'yuv420p',\n",
        "                '-crf', '18',\n",
        "                output_video_path\n",
        "            ], check=True)\n",
        "\n",
        "            print(f\"Video saved: {output_video_path}\")\n",
        "            return True\n",
        "\n",
        "    print(\"Error: Rendering directory not found or no images rendered\")\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "def create_gif(video_path, gif_path):\n",
        "    \"\"\"Create an animated GIF from an MP4 video file\"\"\"\n",
        "    print(\"Creating animated GIF...\")\n",
        "\n",
        "    # ffmpeg command to create a GIF\n",
        "    # -vf: video filter graph\n",
        "    # setpts=8*PTS: slows down the video by a factor of 8 (8x original duration)\n",
        "    # fps=10: set output frame rate to 10 FPS\n",
        "    # scale=720:-1:flags=lanczos: resize to 720px width, auto height, using Lanczos resampling\n",
        "    # -loop 0: loop the GIF indefinitely\n",
        "    subprocess.run([\n",
        "        'ffmpeg', '-y',\n",
        "        '-i', video_path,\n",
        "        '-vf', 'setpts=8*PTS,fps=10,scale=720:-1:flags=lanczos',\n",
        "        '-loop', '0',\n",
        "        gif_path\n",
        "    ], check=True)\n",
        "\n",
        "    if os.path.exists(gif_path):\n",
        "        size_mb = os.path.getsize(gif_path) / (1024 * 1024)\n",
        "        print(f\"GIF creation complete: {gif_path} ({size_mb:.2f} MB)\")\n",
        "        return True\n",
        "\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "myF1NasbGgOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = train_gaussian_splatting(data_dir, iterations=1000)\n",
        "\n",
        "# Step 6: Render Video\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "output_video = f\"{OUTPUT_DIR}/gaussian_splatting_video.mp4\"\n",
        "success = render_video(model_path, output_video, iteration=1000)\n"
      ],
      "metadata": {
        "id": "JKJuclrCgMcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnose_specific_pair(database_path, id1, id2):\n",
        "    \"\"\"Diagnose a specific image pair\"\"\"\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    print(f\"\\nðŸ” Diagnosing pair {id1}-{id2}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get match info\n",
        "    pair_id = id1 * 2147483648 + id2\n",
        "    cursor.execute(\n",
        "        \"SELECT rows, F FROM two_view_geometries WHERE pair_id=?\",\n",
        "        (pair_id,)\n",
        "    )\n",
        "    result = cursor.fetchone()\n",
        "\n",
        "    if result:\n",
        "        rows, F_blob = result\n",
        "        print(f\"  Matches: {rows}\")\n",
        "\n",
        "        if F_blob:\n",
        "            F = np.frombuffer(F_blob, dtype=np.float64).reshape(3, 3)\n",
        "            print(f\"  F matrix exists: {F.shape}\")\n",
        "            print(f\"  F matrix:\\n{F}\")\n",
        "        else:\n",
        "            print(\"  âš ï¸ F matrix is NULL!\")\n",
        "    else:\n",
        "        print(f\"  âš ï¸ Pair not found in two_view_geometries!\")\n",
        "\n",
        "    # Get camera info\n",
        "    cursor.execute(\"SELECT c.* FROM cameras c JOIN images i ON c.camera_id = i.camera_id WHERE i.image_id IN (?, ?)\", (id1, id2))\n",
        "    print(\"\\n  Cameras:\")\n",
        "    for row in cursor.fetchall():\n",
        "        cam_id, model, w, h, params_blob, prior = row\n",
        "        params = np.frombuffer(params_blob, dtype=np.float64)\n",
        "        print(f\"    Camera {cam_id}: {w}x{h}, model={model}, params={params}\")\n",
        "\n",
        "    conn.close()\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "diagnose_specific_pair('/content/output/colmap/database.db', 11, 20)"
      ],
      "metadata": {
        "id": "CtinWBxmWjFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "\n",
        "def diagnose_database(database_path):\n",
        "    \"\"\"Diagnose why COLMAP can't find initial pair\"\"\"\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    print(\"\\nðŸ” Database Diagnosis\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get match statistics\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT pair_id, rows, config\n",
        "        FROM two_view_geometries\n",
        "        ORDER BY rows DESC\n",
        "        LIMIT 10\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nTop 10 matches by count:\")\n",
        "    for pair_id, rows, config in cursor.fetchall():\n",
        "        image_id2 = pair_id % 2147483648\n",
        "        image_id1 = (pair_id - image_id2) // 2147483648\n",
        "        print(f\"  Images {image_id1}-{image_id2}: {rows} matches, config={config}\")\n",
        "\n",
        "    # Get image and camera info\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT i.image_id, i.name, i.camera_id, c.width, c.height\n",
        "        FROM images i\n",
        "        JOIN cameras c ON i.camera_id = c.camera_id\n",
        "        LIMIT 5\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nSample images:\")\n",
        "    for img_id, name, cam_id, w, h in cursor.fetchall():\n",
        "        print(f\"  Image {img_id}: {name}, camera {cam_id} ({w}x{h})\")\n",
        "\n",
        "    conn.close()\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "diagnose_database('/content/output/colmap/database.db')"
      ],
      "metadata": {
        "id": "wUW7ZnT99nOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dq2Hln8-FKNu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
