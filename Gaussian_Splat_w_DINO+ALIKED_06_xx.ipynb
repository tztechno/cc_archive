{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 49349,
          "databundleVersionId": 5447706,
          "sourceType": "competition"
        },
        {
          "sourceId": 91498,
          "databundleVersionId": 11655853,
          "sourceType": "competition"
        },
        {
          "sourceId": 289936912,
          "sourceType": "kernelVersion"
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "123c66944fe74f9193414169d81779b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa946603efee4d92b8f3f08fdc53ffff",
              "IPY_MODEL_a44e1f2691d6420a90693843ddad4233",
              "IPY_MODEL_6f83a1c30af04532a394f00dd3b907c6"
            ],
            "layout": "IPY_MODEL_78c4a040b1e54f00985c402a4665574d"
          }
        },
        "aa946603efee4d92b8f3f08fdc53ffff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ad0dfa1b2d45d788970c8f44509761",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_41a59ba6583844a395d1eebec09b1631",
            "value": "preprocessor_config.json:‚Äá100%"
          }
        },
        "a44e1f2691d6420a90693843ddad4233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd41e5c9b9684463a164fe5b70ecef0d",
            "max": 436,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff5ed1421846457da8550b0472836ac2",
            "value": 436
          }
        },
        "6f83a1c30af04532a394f00dd3b907c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_516c383bac544d1fb22721b7babe1954",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5580aabfd132440c8522c3a18bd4cbfa",
            "value": "‚Äá436/436‚Äá[00:00&lt;00:00,‚Äá44.9kB/s]"
          }
        },
        "78c4a040b1e54f00985c402a4665574d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69ad0dfa1b2d45d788970c8f44509761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a59ba6583844a395d1eebec09b1631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd41e5c9b9684463a164fe5b70ecef0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff5ed1421846457da8550b0472836ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "516c383bac544d1fb22721b7babe1954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5580aabfd132440c8522c3a18bd4cbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c7daadaf49e487e94c1615726fb5d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_568c0e8019c349dbb87a300eec8d62b6",
              "IPY_MODEL_f2c7f978d7d143ba89383b87a1d42f6f",
              "IPY_MODEL_5afb5a05b5ff485e90301a69d817f5f0"
            ],
            "layout": "IPY_MODEL_522576272bbc44e0900c0b0906633e94"
          }
        },
        "568c0e8019c349dbb87a300eec8d62b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_790f8ae73ae64a46b1cdba98b0495c2a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_850bf06142fb4ccfaa1dcd4d162e036c",
            "value": "config.json:‚Äá100%"
          }
        },
        "f2c7f978d7d143ba89383b87a1d42f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8074e8c64e34ad49d884aef5bd923c3",
            "max": 548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03a80f7ca4534490807a8a3614655181",
            "value": 548
          }
        },
        "5afb5a05b5ff485e90301a69d817f5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d27d56da5444929a0ac87552b5fb6ab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f3c03891c9004f5293c2b80022ec43b9",
            "value": "‚Äá548/548‚Äá[00:00&lt;00:00,‚Äá61.3kB/s]"
          }
        },
        "522576272bbc44e0900c0b0906633e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "790f8ae73ae64a46b1cdba98b0495c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850bf06142fb4ccfaa1dcd4d162e036c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8074e8c64e34ad49d884aef5bd923c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a80f7ca4534490807a8a3614655181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d27d56da5444929a0ac87552b5fb6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c03891c9004f5293c2b80022ec43b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77653741899c4b738f52b39b59285f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f6503990a1c4eb598ee16631db52e27",
              "IPY_MODEL_cf2c35c0ee8b43dfb7d965fb5cef5803",
              "IPY_MODEL_ca01ba86a0a7402f90983040288d2b4d"
            ],
            "layout": "IPY_MODEL_576dd5c4417c45e78cb54bed46936e85"
          }
        },
        "8f6503990a1c4eb598ee16631db52e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a90fbe51972488eab664b043b5cbac6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8923556812454e1d8f9f0fbdce9ac090",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "cf2c35c0ee8b43dfb7d965fb5cef5803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95da7e164e8b4fa395257fe8541e7bc6",
            "max": 346345912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c4784a893c449ecafd54a34a5571e0c",
            "value": 346345912
          }
        },
        "ca01ba86a0a7402f90983040288d2b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f92917bb24f241d38058addf3dcb2ad4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2baba335c63340b694f03bb8214e3e9d",
            "value": "‚Äá346M/346M‚Äá[00:02&lt;00:00,‚Äá217MB/s]"
          }
        },
        "576dd5c4417c45e78cb54bed46936e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a90fbe51972488eab664b043b5cbac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8923556812454e1d8f9f0fbdce9ac090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95da7e164e8b4fa395257fe8541e7bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c4784a893c449ecafd54a34a5571e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f92917bb24f241d38058addf3dcb2ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2baba335c63340b694f03bb8214e3e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tztechno/cc_archive/blob/main/Gaussian_Splat_w_DINO%2BALIKED_06_xx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fountain: Gaussian Splat w/ DINO+ALIKED**"
      ],
      "metadata": {
        "id": "lUpuiNI_IQq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#„Çµ„Ç§„Ç∫„ÅÆÁï∞„Å™„ÇãÁîªÂÉè„ÇíÊâ±„ÅÜ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9kAhlZHTIqC",
        "outputId": "29d550ae-4d33-46ae-deaf-9981c7bec407"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "IMAGE_DIR = \"/content/drive/MyDrive/your_folder/fountain2\"\n",
        "WORK_DIR = '/content/gaussian_splatting'\n",
        "OUTPUT_DIR = '/content/output'\n",
        "COLMAP_DIR = '/content/colmap_data'\n",
        "\n",
        "ORIGINAL = IMAGE_DIR\n",
        "RESIZED='/content/resized'"
      ],
      "metadata": {
        "id": "NlvpKXz1IudB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ZIMDLmkV1rj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def run_cmd(cmd, check=True, capture=False):\n",
        "    \"\"\"Run command with better error handling\"\"\"\n",
        "    print(f\"Running: {' '.join(cmd)}\")\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        capture_output=capture,\n",
        "        text=True,\n",
        "        check=False\n",
        "    )\n",
        "    if check and result.returncode != 0:\n",
        "        print(f\"‚ùå Command failed with code {result.returncode}\")\n",
        "        if capture:\n",
        "            print(f\"STDOUT: {result.stdout}\")\n",
        "            print(f\"STDERR: {result.stderr}\")\n",
        "    return result\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"\n",
        "    Colab environment setup for Gaussian Splatting + LightGlue + pycolmap\n",
        "    Python 3.12 compatible version (v8)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üöÄ Setting up COLAB environment (v8 - Python 3.12 compatible)\")\n",
        "\n",
        "    WORK_DIR = \"/content/gaussian-splatting\"\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 0: NumPy FIX (Python 3.12 compatible)\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 0: Fix NumPy (Python 3.12 compatible)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Python 3.12 requires numpy >= 1.26\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"numpy\"])\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\"])\n",
        "\n",
        "    # sanity check\n",
        "    run_cmd([sys.executable, \"-c\", \"import numpy; print('NumPy:', numpy.__version__)\"])\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 1: System packages (Colab)\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 1: System packages\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    run_cmd([\"apt-get\", \"update\", \"-qq\"])\n",
        "    run_cmd([\n",
        "        \"apt-get\", \"install\", \"-y\", \"-qq\",\n",
        "        \"colmap\",\n",
        "        \"build-essential\",\n",
        "        \"cmake\",\n",
        "        \"git\",\n",
        "        \"libopenblas-dev\",\n",
        "        \"xvfb\"\n",
        "    ])\n",
        "\n",
        "    # virtual display (COLMAP / OpenCV safety)\n",
        "    os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n",
        "    os.environ[\"DISPLAY\"] = \":99\"\n",
        "    subprocess.Popen(\n",
        "        [\"Xvfb\", \":99\", \"-screen\", \"0\", \"1024x768x24\"],\n",
        "        stdout=subprocess.DEVNULL,\n",
        "        stderr=subprocess.DEVNULL\n",
        "    )\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 2: Clone Gaussian Splatting\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 2: Clone Gaussian Splatting\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if not os.path.exists(WORK_DIR):\n",
        "        run_cmd([\n",
        "            \"git\", \"clone\", \"--recursive\",\n",
        "            \"https://github.com/graphdeco-inria/gaussian-splatting.git\",\n",
        "            WORK_DIR\n",
        "        ])\n",
        "    else:\n",
        "        print(\"‚úì Repository already exists\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 3: Python packages (FIXED ORDER & VERSIONS)\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 3: Python packages (VERBOSE MODE)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ---- PyTorch (Colab CUDAÂØæÂøú) ----\n",
        "    print(\"\\nüì¶ Installing PyTorch...\")\n",
        "    run_cmd([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"torch\", \"torchvision\", \"torchaudio\"\n",
        "    ])\n",
        "\n",
        "    # ---- Core utils ----\n",
        "    print(\"\\nüì¶ Installing core utilities...\")\n",
        "    run_cmd([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"opencv-python\",\n",
        "        \"pillow\",\n",
        "        \"imageio\",\n",
        "        \"imageio-ffmpeg\",\n",
        "        \"plyfile\",\n",
        "        \"tqdm\",\n",
        "        \"tensorboard\"\n",
        "    ])\n",
        "\n",
        "    # ---- transformers (NumPy 1.26 compatible) ----\n",
        "    print(\"\\nüì¶ Installing transformers (NumPy 1.26 compatible)...\")\n",
        "    # Install transformers with proper dependencies\n",
        "    run_cmd([\n",
        "        sys.executable, \"-m\", \"pip\", \"install\",\n",
        "        \"transformers==4.40.0\"\n",
        "    ])\n",
        "\n",
        "    # ---- LightGlue stack (GITHUB INSTALL) ----\n",
        "    print(\"\\nüì¶ Installing LightGlue stack...\")\n",
        "\n",
        "    # Install kornia first\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"kornia\"])\n",
        "\n",
        "    # Install h5py (sometimes needed)\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"h5py\"])\n",
        "\n",
        "    # Install matplotlib (LightGlue dependency)\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\"])\n",
        "\n",
        "    # Install LightGlue directly from GitHub (more reliable)\n",
        "    print(\"  Installing LightGlue from GitHub...\")\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "            \"git+https://github.com/cvg/LightGlue.git\"])\n",
        "\n",
        "    # Install pycolmap\n",
        "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"pycolmap\"])\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 4: Build GS submodules\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 4: Build Gaussian Splatting submodules\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    submodules = {\n",
        "        \"diff-gaussian-rasterization\":\n",
        "            \"https://github.com/graphdeco-inria/diff-gaussian-rasterization.git\",\n",
        "        \"simple-knn\":\n",
        "            \"https://github.com/camenduru/simple-knn.git\"\n",
        "    }\n",
        "\n",
        "    for name, repo in submodules.items():\n",
        "        print(f\"\\nüì¶ Installing {name}...\")\n",
        "        path = os.path.join(WORK_DIR, \"submodules\", name)\n",
        "        if not os.path.exists(path):\n",
        "            run_cmd([\"git\", \"clone\", repo, path])\n",
        "        run_cmd([sys.executable, \"-m\", \"pip\", \"install\", path])\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 5: Detailed Verification\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 5: Detailed Verification\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # NumPy (verify version first)\n",
        "    print(\"\\nüîç Testing NumPy...\")\n",
        "    try:\n",
        "        import numpy as np\n",
        "        print(f\"  ‚úì NumPy: {np.__version__}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå NumPy failed: {e}\")\n",
        "\n",
        "    # PyTorch\n",
        "    print(\"\\nüîç Testing PyTorch...\")\n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"  ‚úì PyTorch: {torch.__version__}\")\n",
        "        print(f\"  ‚úì CUDA available: {torch.cuda.is_available()}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"  ‚úì CUDA version: {torch.version.cuda}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå PyTorch failed: {e}\")\n",
        "\n",
        "    # transformers\n",
        "    print(\"\\nüîç Testing transformers...\")\n",
        "    try:\n",
        "        import transformers\n",
        "        print(f\"  ‚úì transformers version: {transformers.__version__}\")\n",
        "        from transformers import AutoModel\n",
        "        print(f\"  ‚úì AutoModel import: OK\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå transformers failed: {e}\")\n",
        "        print(f\"  Attempting detailed diagnosis...\")\n",
        "        result = run_cmd([\n",
        "            sys.executable, \"-c\",\n",
        "            \"import transformers; print(transformers.__version__)\"\n",
        "        ], capture=True)\n",
        "        print(f\"  Output: {result.stdout}\")\n",
        "        print(f\"  Error: {result.stderr}\")\n",
        "\n",
        "    # LightGlue\n",
        "    print(\"\\nüîç Testing LightGlue...\")\n",
        "    try:\n",
        "        from lightglue import LightGlue, ALIKED\n",
        "        print(f\"  ‚úì LightGlue: OK\")\n",
        "        print(f\"  ‚úì ALIKED: OK\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå LightGlue failed: {e}\")\n",
        "        print(f\"  Attempting detailed diagnosis...\")\n",
        "        result = run_cmd([\n",
        "            sys.executable, \"-c\",\n",
        "            \"from lightglue import LightGlue\"\n",
        "        ], capture=True)\n",
        "        print(f\"  Output: {result.stdout}\")\n",
        "        print(f\"  Error: {result.stderr}\")\n",
        "\n",
        "    # pycolmap\n",
        "    print(\"\\nüîç Testing pycolmap...\")\n",
        "    try:\n",
        "        import pycolmap\n",
        "        print(f\"  ‚úì pycolmap: OK\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå pycolmap failed: {e}\")\n",
        "\n",
        "    # kornia\n",
        "    print(\"\\nüîç Testing kornia...\")\n",
        "    try:\n",
        "        import kornia\n",
        "        print(f\"  ‚úì kornia: {kornia.__version__}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå kornia failed: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ SETUP COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Working dir: {WORK_DIR}\")\n",
        "\n",
        "    return WORK_DIR\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    setup_environment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dxG5w4dZlIz",
        "outputId": "040f506d-53c1-4395-9278-df30cb51b8d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Setting up COLAB environment (v8 - Python 3.12 compatible)\n",
            "\n",
            "======================================================================\n",
            "STEP 0: Fix NumPy (Python 3.12 compatible)\n",
            "======================================================================\n",
            "Running: /usr/bin/python3 -m pip uninstall -y numpy\n",
            "Running: /usr/bin/python3 -m pip install numpy==1.26.4\n",
            "Running: /usr/bin/python3 -c import numpy; print('NumPy:', numpy.__version__)\n",
            "\n",
            "======================================================================\n",
            "STEP 1: System packages\n",
            "======================================================================\n",
            "Running: apt-get update -qq\n",
            "Running: apt-get install -y -qq colmap build-essential cmake git libopenblas-dev xvfb\n",
            "\n",
            "======================================================================\n",
            "STEP 2: Clone Gaussian Splatting\n",
            "======================================================================\n",
            "Running: git clone --recursive https://github.com/graphdeco-inria/gaussian-splatting.git /content/gaussian-splatting\n",
            "\n",
            "======================================================================\n",
            "STEP 3: Python packages (VERBOSE MODE)\n",
            "======================================================================\n",
            "\n",
            "üì¶ Installing PyTorch...\n",
            "Running: /usr/bin/python3 -m pip install torch torchvision torchaudio\n",
            "\n",
            "üì¶ Installing core utilities...\n",
            "Running: /usr/bin/python3 -m pip install opencv-python pillow imageio imageio-ffmpeg plyfile tqdm tensorboard\n",
            "\n",
            "üì¶ Installing transformers (NumPy 1.26 compatible)...\n",
            "Running: /usr/bin/python3 -m pip install transformers==4.40.0\n",
            "\n",
            "üì¶ Installing LightGlue stack...\n",
            "Running: /usr/bin/python3 -m pip install kornia\n",
            "Running: /usr/bin/python3 -m pip install h5py\n",
            "Running: /usr/bin/python3 -m pip install matplotlib\n",
            "  Installing LightGlue from GitHub...\n",
            "Running: /usr/bin/python3 -m pip install git+https://github.com/cvg/LightGlue.git\n",
            "Running: /usr/bin/python3 -m pip install pycolmap\n",
            "\n",
            "======================================================================\n",
            "STEP 4: Build Gaussian Splatting submodules\n",
            "======================================================================\n",
            "\n",
            "üì¶ Installing diff-gaussian-rasterization...\n",
            "Running: /usr/bin/python3 -m pip install /content/gaussian-splatting/submodules/diff-gaussian-rasterization\n",
            "\n",
            "üì¶ Installing simple-knn...\n",
            "Running: /usr/bin/python3 -m pip install /content/gaussian-splatting/submodules/simple-knn\n",
            "\n",
            "======================================================================\n",
            "STEP 5: Detailed Verification\n",
            "======================================================================\n",
            "\n",
            "üîç Testing NumPy...\n",
            "  ‚úì NumPy: 2.0.2\n",
            "\n",
            "üîç Testing PyTorch...\n",
            "  ‚úì PyTorch: 2.9.0+cu126\n",
            "  ‚úì CUDA available: True\n",
            "  ‚úì CUDA version: 12.6\n",
            "\n",
            "üîç Testing transformers...\n",
            "  ‚úì transformers version: 4.40.0\n",
            "  ‚úì AutoModel import: OK\n",
            "\n",
            "üîç Testing LightGlue...\n",
            "  ‚úì LightGlue: OK\n",
            "  ‚úì ALIKED: OK\n",
            "\n",
            "üîç Testing pycolmap...\n",
            "  ‚úì pycolmap: OK\n",
            "\n",
            "üîç Testing kornia...\n",
            "  ‚úì kornia: 0.8.2\n",
            "\n",
            "======================================================================\n",
            "‚úÖ SETUP COMPLETE\n",
            "======================================================================\n",
            "Working dir: /content/gaussian-splatting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup successful 2026/01/07"
      ],
      "metadata": {
        "id": "uuHc-fcmV1Vj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image_sizes(image_dir, output_dir=None, target_size=1024, mode='fit'):\n",
        "    \"\"\"\n",
        "    Resizes all images in a directory while maintaining aspect ratio.\n",
        "\n",
        "    Args:\n",
        "        image_dir: Directory containing input images.\n",
        "        output_dir: Directory to save the processed images. Defaults to image_dir.\n",
        "        target_size: The desired maximum size for the longer side (or minimum size for the shorter side).\n",
        "        mode: Resizing mode - 'fit' (fit within target), 'fill' (fill target), or 'pad' (fit with padding).\n",
        "    \"\"\"\n",
        "    if output_dir is None:\n",
        "        output_dir = image_dir\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Normalizing image sizes (mode: {mode}) while maintaining aspect ratio...\")\n",
        "\n",
        "    size_stats = {}\n",
        "    converted_count = 0\n",
        "\n",
        "    for img_file in sorted(os.listdir(image_dir)):\n",
        "        if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            continue\n",
        "\n",
        "        input_path = os.path.join(image_dir, img_file)\n",
        "        output_path = os.path.join(output_dir, img_file)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(input_path)\n",
        "            original_size = img.size  # (width, height)\n",
        "            original_aspect = original_size[0] / original_size[1]\n",
        "\n",
        "            # Record original size for statistics\n",
        "            size_key = f\"{original_size[0]}x{original_size[1]}\"\n",
        "            if size_key not in size_stats:\n",
        "                size_stats[size_key] = 0\n",
        "            size_stats[size_key] += 1\n",
        "\n",
        "            # Resize while maintaining aspect ratio\n",
        "            if mode == 'fit':\n",
        "                # Fit within target (Èï∑Ëæ∫„Çítarget_size„Å´Âêà„Çè„Åõ„Å¶„É™„Çµ„Ç§„Ç∫)\n",
        "                if original_size[0] > original_size[1]:  # Ê®™Èï∑\n",
        "                    new_width = target_size\n",
        "                    new_height = int(target_size / original_aspect)\n",
        "                else:  # Á∏¶Èï∑ or Ê≠£ÊñπÂΩ¢\n",
        "                    new_height = target_size\n",
        "                    new_width = int(target_size * original_aspect)\n",
        "\n",
        "            elif mode == 'fill':\n",
        "                # Fill target (Áü≠Ëæ∫„Çítarget_size„Å´Âêà„Çè„Åõ„Å¶„É™„Çµ„Ç§„Ç∫)\n",
        "                if original_size[0] > original_size[1]:  # Ê®™Èï∑\n",
        "                    new_height = target_size\n",
        "                    new_width = int(target_size * original_aspect)\n",
        "                else:  # Á∏¶Èï∑ or Ê≠£ÊñπÂΩ¢\n",
        "                    new_width = target_size\n",
        "                    new_height = int(target_size / original_aspect)\n",
        "\n",
        "            elif mode == 'pad':\n",
        "                # Fit with padding (Áü≠Ëæ∫„Çítarget_size„Å´Âêà„Çè„Åõ„Å¶„ÄÅ‰ΩôÁôΩ„ÇíËøΩÂä†)\n",
        "                if original_size[0] > original_size[1]:  # Ê®™Èï∑\n",
        "                    new_width = target_size\n",
        "                    new_height = int(target_size / original_aspect)\n",
        "                else:  # Á∏¶Èï∑ or Ê≠£ÊñπÂΩ¢\n",
        "                    new_height = target_size\n",
        "                    new_width = int(target_size * original_aspect)\n",
        "\n",
        "                # ‰ΩôÁôΩ„ÇíËøΩÂä†„Åó„Å¶Ê≠£ÊñπÂΩ¢„Å´„Åô„Çã\n",
        "                img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "                img_square = Image.new('RGB', (target_size, target_size), (255, 255, 255))\n",
        "                offset = ((target_size - new_width) // 2, (target_size - new_height) // 2)\n",
        "                img_square.paste(img_resized, offset)\n",
        "                img = img_square\n",
        "                print(f\"  ‚úì {img_file}: {original_size} ‚Üí {new_width}x{new_height} (padded to {target_size}x{target_size})\")\n",
        "                img.save(output_path, quality=95)\n",
        "                converted_count += 1\n",
        "                continue\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown mode: {mode}. Use 'fit', 'fill', or 'pad'.\")\n",
        "\n",
        "            # „É™„Çµ„Ç§„Ç∫ÂÆüË°å\n",
        "            img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "            img_resized.save(output_path, quality=95)\n",
        "            converted_count += 1\n",
        "\n",
        "            print(f\"  ‚úì {img_file}: {original_size} ‚Üí {new_width}x{new_height} (aspect ratio: {original_aspect:.2f})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó Error processing {img_file}: {e}\")\n",
        "\n",
        "    print(f\"\\nConversion complete: {converted_count} images\")\n",
        "    print(f\"Original size distribution: {size_stats}\")\n",
        "    return converted_count\n",
        "\n",
        "\n",
        "\n",
        "converted_count=normalize_image_sizes(ORIGINAL, RESIZED, target_size=1024, mode='fit')\n",
        "print(converted_count)\n"
      ],
      "metadata": {
        "id": "IxSbne6AMqVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2964fe-6a5f-4fb9-d7b9-2e35fb316d9e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizing image sizes (mode: fit) while maintaining aspect ratio...\n",
            "  ‚úì image_000.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_001.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_002.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_003.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_004.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_005.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_006.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_007.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_008.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_009.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_010.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_011.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_012.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_013.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_014.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_015.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_016.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_017.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_018.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_019.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_020.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_021.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_022.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_023.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_024.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_025.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_026.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_027.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_028.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_029.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_030.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_031.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_032.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_033.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_034.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_035.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_036.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_037.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_038.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_039.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_040.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_041.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_042.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_043.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_044.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_045.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_046.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_047.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_048.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_049.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_050.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_051.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_052.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_053.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_054.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_055.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_056.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_057.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_058.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_059.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_060.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_061.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_062.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_063.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_064.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_065.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_066.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_067.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_068.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_069.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_070.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_071.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_072.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_073.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_074.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_075.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_076.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_077.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_078.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "  ‚úì image_079.jpeg: (1440, 1920) ‚Üí 768x1024 (aspect ratio: 0.75)\n",
            "\n",
            "Conversion complete: 80 images\n",
            "Original size distribution: {'1440x1920': 80}\n",
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wOjRkVS7PZpA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import glob\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import h5py\n",
        "import sqlite3\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import kornia as K\n",
        "import kornia.feature as KF\n",
        "from lightglue import ALIKED, LightGlue\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "import pycolmap\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CONFIG:\n",
        "    GLOBAL_TOPK = 200\n",
        "    RATIO_THR = 1.2\n",
        "    MATCH_THRESH = 10\n",
        "    N_KEYPOINTS = 2048\n",
        "    exhaustive_if_less = 20\n",
        "    min_matches = 15\n",
        "    max_num_keypoints = 8192\n",
        "    image_size = 1024\n",
        "    colmap_camera_model = 'SIMPLE_RADIAL'"
      ],
      "metadata": {
        "trusted": true,
        "id": "IsqmL7haIQq3"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "def run_colmap_sequential(database_path, image_dir, output_dir):\n",
        "    \"\"\"Run COLMAP with adaptive focal length calibration and pair selection\"\"\"\n",
        "    print(\"\\n=== Stage 4: Running COLMAP Reconstruction ===\")\n",
        "\n",
        "    import sqlite3\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "    import h5py\n",
        "    import re\n",
        "    import os\n",
        "    import subprocess\n",
        "    from datetime import datetime, timezone\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 1: Calibrate focal length (Êó¢Â≠ò„ÅÆ„Åæ„Åæ)\n",
        "    # =====================================================================\n",
        "    print(\"\\nüîß Calibrating focal length from matches...\")\n",
        "\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"SELECT pair_id, rows FROM matches ORDER BY rows DESC LIMIT 1\")\n",
        "    pair_id, num_matches = cursor.fetchone()\n",
        "\n",
        "    image_id2 = pair_id % 2147483648\n",
        "    image_id1 = (pair_id - image_id2) // 2147483648\n",
        "\n",
        "    cursor.execute(\"SELECT data FROM keypoints WHERE image_id = ?\", (image_id1,))\n",
        "    kpts1 = np.frombuffer(cursor.fetchone()[0], dtype=np.float32).reshape(-1, 2)\n",
        "\n",
        "    cursor.execute(\"SELECT data FROM keypoints WHERE image_id = ?\", (image_id2,))\n",
        "    kpts2 = np.frombuffer(cursor.fetchone()[0], dtype=np.float32).reshape(-1, 2)\n",
        "\n",
        "    cursor.execute(\"SELECT data FROM matches WHERE pair_id = ?\", (pair_id,))\n",
        "    matches = np.frombuffer(cursor.fetchone()[0], dtype=np.uint32).reshape(-1, 2)\n",
        "\n",
        "    points1 = kpts1[matches[:, 0]]\n",
        "    points2 = kpts2[matches[:, 1]]\n",
        "\n",
        "    cursor.execute(\"SELECT width, height FROM cameras LIMIT 1\")\n",
        "    width, height = cursor.fetchone()\n",
        "    cx, cy = width / 2, height / 2\n",
        "\n",
        "    print(f\"   Using pair with {num_matches} matches\")\n",
        "    print(f\"   Image size: {width}x{height}\")\n",
        "\n",
        "    best_focal = None\n",
        "    best_inliers = 0\n",
        "    max_dim = max(width, height)\n",
        "\n",
        "    for f in range(int(max_dim * 0.7), int(max_dim * 1.8), 50):\n",
        "        pts1_norm = (points1 - np.array([cx, cy])) / f\n",
        "        pts2_norm = (points2 - np.array([cx, cy])) / f\n",
        "\n",
        "        E, mask = cv2.findEssentialMat(\n",
        "            pts1_norm, pts2_norm,\n",
        "            focal=1.0, pp=(0.0, 0.0),\n",
        "            method=cv2.RANSAC,\n",
        "            prob=0.9999,\n",
        "            threshold=0.005\n",
        "        )\n",
        "\n",
        "        if mask is not None:\n",
        "            inliers = int(np.sum(mask))\n",
        "            if inliers > best_inliers:\n",
        "                best_inliers = inliers\n",
        "                best_focal = f\n",
        "\n",
        "    if best_focal is None:\n",
        "        best_focal = max_dim * 1.2\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Calibrated focal length: {best_focal:.1f} pixels\")\n",
        "        print(f\"      Inliers: {best_inliers}/{len(matches)} ({best_inliers/len(matches)*100:.1f}%)\")\n",
        "\n",
        "    params = np.array([best_focal, cx, cy, 0.0], dtype=np.float64)\n",
        "    cursor.execute(\"UPDATE cameras SET params = ?\", (params.tobytes(),))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"   ‚úÖ Database updated with focal={best_focal:.1f}\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 2: DATA-DRIVEN ADAPTIVE PAIR SELECTION\n",
        "    # =====================================================================\n",
        "    print(\"\\nüîç Analyzing matches for optimal initial pair...\")\n",
        "\n",
        "    matches_file = \"/content/output/features/matches.h5\"\n",
        "\n",
        "    def get_image_number(filename):\n",
        "        match = re.search(r'(\\d+)', filename)\n",
        "        return int(match.group(1)) if match else 0\n",
        "\n",
        "    # Collect all pair statistics\n",
        "    all_pairs = []\n",
        "    with h5py.File(matches_file, 'r') as f:\n",
        "        for key1 in f.keys():\n",
        "            num1 = get_image_number(key1)\n",
        "            for key2 in f[key1].keys():\n",
        "                num2 = get_image_number(key2)\n",
        "                matches_data = f[key1][key2][()]\n",
        "                match_count = len(matches_data)\n",
        "                distance = abs(num2 - num1)\n",
        "\n",
        "                all_pairs.append({\n",
        "                    'pair': (key1, key2),\n",
        "                    'distance': distance,\n",
        "                    'matches': match_count\n",
        "                })\n",
        "\n",
        "    if not all_pairs:\n",
        "        raise RuntimeError(\"No pairs found in matches file\")\n",
        "\n",
        "    # Analyze dataset characteristics\n",
        "    distances = np.array([p['distance'] for p in all_pairs])\n",
        "    match_counts = np.array([p['matches'] for p in all_pairs])\n",
        "\n",
        "    # Compute statistics\n",
        "    match_median = np.median(match_counts)\n",
        "    match_75th = np.percentile(match_counts, 75)\n",
        "    match_90th = np.percentile(match_counts, 90)\n",
        "\n",
        "    distance_median = np.median(distances)\n",
        "    max_distance = np.max(distances)\n",
        "\n",
        "    print(f\"   Dataset statistics:\")\n",
        "    print(f\"   - Total pairs: {len(all_pairs)}\")\n",
        "    print(f\"   - Match count: median={match_median:.0f}, 75th={match_75th:.0f}, 90th={match_90th:.0f}\")\n",
        "    print(f\"   - Distance: median={distance_median:.0f}, max={max_distance}\")\n",
        "\n",
        "    # Scoring function: balance between matches and distance\n",
        "    # Prefer pairs with:\n",
        "    # 1. High match count (relative to dataset)\n",
        "    # 2. Medium-to-large distance (good baseline for triangulation)\n",
        "    # 3. Avoid too-close pairs (poor geometry) and too-far pairs (may fail)\n",
        "\n",
        "    def compute_score(pair_info):\n",
        "        matches = pair_info['matches']\n",
        "        distance = pair_info['distance']\n",
        "\n",
        "        # Match score: normalize to 0-1 range\n",
        "        match_score = min(matches / match_90th, 1.0)\n",
        "\n",
        "        # Distance score: prefer middle-to-large distances\n",
        "        # Penalize very close (<5% of max) and very far (>80% of max)\n",
        "        min_distance = max(5, max_distance * 0.05)\n",
        "        max_good_distance = max_distance * 0.8\n",
        "\n",
        "        if distance < min_distance:\n",
        "            distance_score = distance / min_distance * 0.5  # Penalty for too close\n",
        "        elif distance > max_good_distance:\n",
        "            distance_score = 0.7  # Slight penalty for very far\n",
        "        else:\n",
        "            # Sweet spot: linear increase from min to median\n",
        "            distance_score = 0.5 + 0.5 * (distance - min_distance) / (distance_median - min_distance)\n",
        "            distance_score = min(distance_score, 1.0)\n",
        "\n",
        "        # Combined score: weighted average\n",
        "        # Prioritize matches more than distance (70/30 split)\n",
        "        return 0.7 * match_score + 0.3 * distance_score\n",
        "\n",
        "    # Score all pairs\n",
        "    for pair in all_pairs:\n",
        "        pair['score'] = compute_score(pair)\n",
        "\n",
        "    # Sort by score\n",
        "    all_pairs.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    # Filter: must have reasonable matches (at least 50th percentile)\n",
        "    match_50th = np.percentile(match_counts, 50)\n",
        "    candidates = [p for p in all_pairs if p['matches'] >= match_50th]\n",
        "\n",
        "    if not candidates:\n",
        "        print(\"   ‚ö†Ô∏è  No pairs meet minimum criteria, using top scored pairs\")\n",
        "        candidates = all_pairs[:20]\n",
        "\n",
        "    # Show top candidates\n",
        "    print(f\"\\nüìä Top 10 candidate pairs:\")\n",
        "    for i, c in enumerate(candidates[:10], 1):\n",
        "        print(f\"   {i}. {c['pair'][0]} - {c['pair'][1]}: \"\n",
        "              f\"{c['matches']} matches, distance={c['distance']}, score={c['score']:.3f}\")\n",
        "\n",
        "    # Select best pair\n",
        "    best = candidates[0]\n",
        "    best_pair = best['pair']\n",
        "\n",
        "    print(f\"\\n‚úÖ Selected pair: {best_pair[0]} - {best_pair[1]}\")\n",
        "    print(f\"   Matches: {best['matches']}\")\n",
        "    print(f\"   Distance: {best['distance']} images apart\")\n",
        "    print(f\"   Score: {best['score']:.3f}\")\n",
        "\n",
        "    # Get image IDs from database\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"SELECT image_id FROM images WHERE name = ?\", (best_pair[0],))\n",
        "    result1 = cursor.fetchone()\n",
        "    cursor.execute(\"SELECT image_id FROM images WHERE name = ?\", (best_pair[1],))\n",
        "    result2 = cursor.fetchone()\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    if not result1 or not result2:\n",
        "        raise RuntimeError(\"Selected images not found in database\")\n",
        "\n",
        "    image_id1, image_id2 = result1[0], result2[0]\n",
        "    print(f\"   Image IDs: {image_id1}, {image_id2}\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 3: Run COLMAP with ULTRA-RELAXED parameters\n",
        "    # =====================================================================\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env['QT_QPA_PLATFORM'] = 'offscreen'\n",
        "\n",
        "    print(f\"\\nüöÄ Starting mapper at {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    print(f\"üí° Using calibrated focal={best_focal:.1f}, ULTRA-RELAXED params\")\n",
        "    print()\n",
        "\n",
        "    cmd_mapper = [\n",
        "        'colmap', 'mapper',\n",
        "        '--database_path', database_path,\n",
        "        '--image_path', image_dir,\n",
        "        '--output_path', output_dir,\n",
        "\n",
        "        '--Mapper.init_image_id1', str(image_id1),\n",
        "        '--Mapper.init_image_id2', str(image_id2),\n",
        "\n",
        "        # ULTRA-RELAXED initialization\n",
        "        '--Mapper.init_min_tri_angle', '1',\n",
        "        '--Mapper.init_min_num_inliers', '30',\n",
        "        '--Mapper.init_max_error', '12',\n",
        "\n",
        "        '--Mapper.abs_pose_min_num_inliers', '15',\n",
        "        '--Mapper.abs_pose_max_error', '15',\n",
        "        '--Mapper.min_num_matches', '10',\n",
        "\n",
        "        '--Mapper.ba_refine_focal_length', '1',\n",
        "        '--Mapper.ba_refine_principal_point', '1',\n",
        "        '--Mapper.ba_refine_extra_params', '1',\n",
        "        '--Mapper.ba_global_max_num_iterations', '100',\n",
        "\n",
        "        '--Mapper.filter_max_reproj_error', '12',\n",
        "        '--Mapper.tri_min_angle', '1.0',\n",
        "\n",
        "        '--Mapper.multiple_models', '0',\n",
        "    ]\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        cmd_mapper,\n",
        "        env=env,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        bufsize=1,\n",
        "        universal_newlines=True\n",
        "    )\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        if line:\n",
        "            print(line.rstrip(), flush=True)\n",
        "\n",
        "    process.stdout.close()\n",
        "    return_code = process.wait(timeout=3600)\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    if return_code == 0:\n",
        "        print(f\"\\n‚úÖ COLMAP reconstruction saved to: {output_dir}\")\n",
        "        print(f\"üïê Completed at {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "\n",
        "        try:\n",
        "            import pycolmap\n",
        "            from pathlib import Path\n",
        "\n",
        "            sparse_dirs = list(Path(output_dir).glob(\"*/\"))\n",
        "            if sparse_dirs:\n",
        "                reconstruction = pycolmap.Reconstruction(str(sparse_dirs[0]))\n",
        "\n",
        "                num_images = len(reconstruction.images)\n",
        "                num_points = len(reconstruction.points3D)\n",
        "\n",
        "                print(\"\\nüìä Reconstruction Statistics:\")\n",
        "                print(f\"   Registered images: {num_images}/{len(all_pairs)}\")\n",
        "                print(f\"   3D points: {num_points:,}\")\n",
        "\n",
        "                if num_points > 0:\n",
        "                    mean_error = reconstruction.compute_mean_reprojection_error()\n",
        "                    print(f\"   Mean reprojection error: {mean_error:.2f} pixels\")\n",
        "\n",
        "                    mean_track_length = sum(\n",
        "                        len(p.track.elements) for p in reconstruction.points3D.values()\n",
        "                    ) / num_points\n",
        "                    print(f\"   Mean track length: {mean_track_length:.1f}\")\n",
        "\n",
        "                for cam_id, camera in reconstruction.cameras.items():\n",
        "                    print(f\"\\nüì∑ Camera {cam_id}:\")\n",
        "                    print(f\"   Focal: {camera.focal_length:.1f} (initial: {best_focal:.1f})\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è  Could not read reconstruction stats: {e}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå COLMAP mapper failed with return code {return_code}\")\n",
        "        raise subprocess.CalledProcessError(return_code, cmd_mapper)"
      ],
      "metadata": {
        "id": "aT7YltkXyKds"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_torch_image(fname, device=torch.device('cuda')):\n",
        "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
        "    return img\n",
        "\n",
        "\n",
        "def extract_dino_embeddings(fnames, device=torch.device('cuda')):\n",
        "    print(\"\\n=== Stage 1: Extracting DINO Global Features ===\")\n",
        "\n",
        "    processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
        "    model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
        "    model = model.eval().to(device)\n",
        "\n",
        "    global_descs = []\n",
        "    for img_path in tqdm(fnames, desc=\"DINO extraction\"):\n",
        "        timg = load_torch_image(img_path, device)\n",
        "        with torch.inference_mode():\n",
        "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
        "            outputs = model(**inputs)\n",
        "            dino_feat = F.normalize(\n",
        "                outputs.last_hidden_state[:,1:].max(dim=1)[0],\n",
        "                dim=1, p=2\n",
        "            )\n",
        "        global_descs.append(dino_feat.detach().cpu())\n",
        "\n",
        "    global_descs = torch.cat(global_descs, dim=0)\n",
        "    print(f\"Extracted global features: {global_descs.shape}\")\n",
        "\n",
        "    del model, processor\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return global_descs\n",
        "\n",
        "\n",
        "def build_topk_pairs(global_feats, device):\n",
        "    print(\"\\n=== Building Top-K Pairs from Global Features ===\")\n",
        "\n",
        "    g = global_feats.to(device)\n",
        "    sim = g @ g.T\n",
        "    sim.fill_diagonal_(-1)\n",
        "\n",
        "    N = sim.size(0)\n",
        "    k = min(CONFIG.GLOBAL_TOPK, N - 1)\n",
        "    k = max(k, 1)\n",
        "\n",
        "    topk_indices = torch.topk(sim, k, dim=1).indices.cpu()\n",
        "\n",
        "    pairs = set()\n",
        "    for i, neighbors in enumerate(topk_indices):\n",
        "        for j in neighbors:\n",
        "            j = j.item()\n",
        "            if i < j:\n",
        "                pairs.add((i, j))\n",
        "\n",
        "    pairs = sorted(list(pairs))\n",
        "    print(f\"Initial pairs from global features: {len(pairs)}\")\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def extract_aliked_features(fnames, device=torch.device('cuda')):\n",
        "    print(\"\\n=== Stage 2: Extracting ALIKED Local Features ===\")\n",
        "\n",
        "    dtype = torch.float32\n",
        "    extractor = ALIKED(\n",
        "        model_name=\"aliked-n16\",\n",
        "        max_num_keypoints=CONFIG.max_num_keypoints,\n",
        "        detection_threshold=0.01,\n",
        "        resize=CONFIG.image_size\n",
        "    ).eval().to(device, dtype)\n",
        "\n",
        "    keypoints_dict = {}\n",
        "    descriptors_dict = {}\n",
        "\n",
        "    for img_path in tqdm(fnames, desc=\"ALIKED extraction\"):\n",
        "        key = os.path.basename(img_path)\n",
        "        image = load_torch_image(img_path, device=device).to(dtype)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            feats = extractor.extract(image)\n",
        "            kpts = feats['keypoints'].reshape(-1, 2).detach().cpu()\n",
        "            descs = feats['descriptors'].reshape(-1, 128).detach().cpu()\n",
        "            descs = F.normalize(descs, dim=1).half()\n",
        "\n",
        "        keypoints_dict[key] = kpts.numpy()\n",
        "        descriptors_dict[key] = descs\n",
        "\n",
        "    print(f\"Extracted features for {len(keypoints_dict)} images\")\n",
        "\n",
        "    del extractor\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return keypoints_dict, descriptors_dict\n",
        "\n",
        "\n",
        "def verify_pairs_with_local_features(pairs, fnames, descriptors_dict, device):\n",
        "    print(\"\\n=== Verifying Pairs with Local Features ===\")\n",
        "\n",
        "    verified_pairs = []\n",
        "\n",
        "    for i, j in tqdm(pairs, desc=\"Local verification\"):\n",
        "        key1 = os.path.basename(fnames[i])\n",
        "        key2 = os.path.basename(fnames[j])\n",
        "\n",
        "        desc1 = descriptors_dict[key1].to(device)\n",
        "        desc2 = descriptors_dict[key2].to(device)\n",
        "\n",
        "        if desc1.size(0) == 0 or desc2.size(0) == 0:\n",
        "            continue\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            sim = desc1 @ desc2.T\n",
        "            nn1 = torch.argmax(sim, dim=1)\n",
        "            nn2 = torch.argmax(sim, dim=0)\n",
        "            mutual = torch.arange(len(nn1), device=device) == nn2[nn1]\n",
        "            n_matches = mutual.sum().item()\n",
        "\n",
        "        if n_matches >= CONFIG.MATCH_THRESH:\n",
        "            verified_pairs.append((i, j))\n",
        "\n",
        "    print(f\"Verified pairs: {len(verified_pairs)}\")\n",
        "    return verified_pairs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-05T05:48:39.620344Z",
          "iopub.execute_input": "2026-01-05T05:48:39.620528Z",
          "iopub.status.idle": "2026-01-05T05:48:39.635341Z",
          "shell.execute_reply.started": "2026-01-05T05:48:39.620512Z",
          "shell.execute_reply": "2026-01-05T05:48:39.634554Z"
        },
        "id": "paYlPoohIQq4"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "def match_with_lightglue(verified_pairs, fnames, keypoints_dict, descriptors_dict,\n",
        "                         output_dir, device=torch.device('cuda')):\n",
        "    \"\"\"Perform detailed matching using LightGlue - Fully Corrected Version\"\"\"\n",
        "    print(\"\\n=== Stage 3: Matching with LightGlue ===\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    lg_matcher = KF.LightGlueMatcher(\n",
        "        \"aliked\", {\n",
        "            \"width_confidence\": -1,\n",
        "            \"depth_confidence\": -1,\n",
        "            \"mp\": True if 'cuda' in str(device) else False\n",
        "        }\n",
        "    ).eval().to(device).half()\n",
        "\n",
        "    print(\"Loaded LightGlue model\")\n",
        "\n",
        "    # Save keypoints\n",
        "    kpts_h5_path = os.path.join(output_dir, 'keypoints.h5')\n",
        "    with h5py.File(kpts_h5_path, 'w') as f:\n",
        "        for img_path in fnames:\n",
        "            key = os.path.basename(img_path)\n",
        "            f.create_dataset(key, data=keypoints_dict[key])\n",
        "\n",
        "    # Save matches\n",
        "    matches_h5_path = os.path.join(output_dir, 'matches.h5')\n",
        "    matched_pairs = 0\n",
        "    skipped_pairs = 0\n",
        "    total_matches = 0\n",
        "\n",
        "    with h5py.File(matches_h5_path, 'w') as f_match:\n",
        "        for i, j in tqdm(verified_pairs, desc=\"LightGlue matching\"):\n",
        "            key1 = os.path.basename(fnames[i])\n",
        "            key2 = os.path.basename(fnames[j])\n",
        "\n",
        "            kp1 = torch.from_numpy(keypoints_dict[key1]).to(device).half()\n",
        "            kp2 = torch.from_numpy(keypoints_dict[key2]).to(device).half()\n",
        "            desc1 = descriptors_dict[key1].to(device)\n",
        "            desc2 = descriptors_dict[key2].to(device)\n",
        "\n",
        "            if len(kp1) == 0 or len(kp2) == 0:\n",
        "                skipped_pairs += 1\n",
        "                continue\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                try:\n",
        "                    dists, idxs = lg_matcher(\n",
        "                        desc1, desc2,\n",
        "                        KF.laf_from_center_scale_ori(kp1[None]),\n",
        "                        KF.laf_from_center_scale_ori(kp2[None])\n",
        "                    )\n",
        "\n",
        "                    # Check if matches were found\n",
        "                    if idxs.numel() == 0:\n",
        "                        skipped_pairs += 1\n",
        "                        continue\n",
        "\n",
        "                    # ‚òÖ‚òÖ‚òÖ Fix: Removed [0] ‚òÖ‚òÖ‚òÖ\n",
        "                    matches = idxs.cpu().numpy()  # (num_matches, 2)\n",
        "\n",
        "                    # Check match count\n",
        "                    num_matches = matches.shape[0]\n",
        "\n",
        "                    if num_matches >= CONFIG.min_matches:\n",
        "                        grp = f_match.require_group(key1)\n",
        "                        grp.create_dataset(key2, data=matches)\n",
        "                        matched_pairs += 1\n",
        "                        total_matches += num_matches\n",
        "                    else:\n",
        "                        skipped_pairs += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"\\nError matching {key1}-{key2}: {e}\")\n",
        "                    skipped_pairs += 1\n",
        "                    continue\n",
        "\n",
        "    del lg_matcher\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"\\nMatching complete:\")\n",
        "    print(f\"  Matched pairs: {matched_pairs}\")\n",
        "    print(f\"  Skipped pairs: {skipped_pairs}\")\n",
        "    print(f\"  Total matches: {total_matches}\")\n",
        "    print(f\"  Average matches per pair: {total_matches/matched_pairs:.1f}\" if matched_pairs > 0 else \"\")\n",
        "    print(f\"  Success rate: {matched_pairs/len(verified_pairs)*100:.1f}%\")\n",
        "\n",
        "    print(f\"\\nSaved keypoints to: {kpts_h5_path}\")\n",
        "    print(f\"Saved matches to: {matches_h5_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-05T05:48:39.636081Z",
          "iopub.execute_input": "2026-01-05T05:48:39.636374Z",
          "iopub.status.idle": "2026-01-05T05:48:39.655904Z",
          "shell.execute_reply.started": "2026-01-05T05:48:39.636356Z",
          "shell.execute_reply": "2026-01-05T05:48:39.655232Z"
        },
        "id": "33nQw3f2IQq5"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "print('run colmap sequential')"
      ],
      "metadata": {
        "id": "_cu8BVjF-SJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d081f9cc-f6de-4a77-f94f-82d04916d4a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run colmap sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqo7ENVtV5Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_colmap_sequential(database_path, image_dir, output_dir):\n",
        "    \"\"\"Run COLMAP with proper camera model and database-driven pair selection\"\"\"\n",
        "    print(\"\\n=== Stage 4: Running COLMAP Reconstruction ===\")\n",
        "\n",
        "    import sqlite3\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "    import re\n",
        "    import os\n",
        "    import subprocess\n",
        "    from datetime import datetime, timezone\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 1: Calibrate focal length\n",
        "    # =====================================================================\n",
        "    print(\"\\nüîß Calibrating focal length from matches...\")\n",
        "\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"SELECT pair_id, rows FROM matches ORDER BY rows DESC LIMIT 1\")\n",
        "    pair_id, num_matches = cursor.fetchone()\n",
        "\n",
        "    image_id2 = pair_id % 2147483648\n",
        "    image_id1 = (pair_id - image_id2) // 2147483648\n",
        "\n",
        "    cursor.execute(\"SELECT data FROM keypoints WHERE image_id = ?\", (image_id1,))\n",
        "    kpts1 = np.frombuffer(cursor.fetchone()[0], dtype=np.float32).reshape(-1, 2)\n",
        "\n",
        "    cursor.execute(\"SELECT data FROM keypoints WHERE image_id = ?\", (image_id2,))\n",
        "    kpts2 = np.frombuffer(cursor.fetchone()[0], dtype=np.float32).reshape(-1, 2)\n",
        "\n",
        "    cursor.execute(\"SELECT data FROM matches WHERE pair_id = ?\", (pair_id,))\n",
        "    matches = np.frombuffer(cursor.fetchone()[0], dtype=np.uint32).reshape(-1, 2)\n",
        "\n",
        "    points1 = kpts1[matches[:, 0]]\n",
        "    points2 = kpts2[matches[:, 1]]\n",
        "\n",
        "    cursor.execute(\"SELECT width, height FROM cameras LIMIT 1\")\n",
        "    width, height = cursor.fetchone()\n",
        "    cx, cy = width / 2, height / 2\n",
        "\n",
        "    print(f\"   Using pair with {num_matches} matches\")\n",
        "    print(f\"   Image size: {width}x{height}\")\n",
        "\n",
        "    best_focal = None\n",
        "    best_inliers = 0\n",
        "    max_dim = max(width, height)\n",
        "\n",
        "    for f in range(int(max_dim * 0.7), int(max_dim * 1.8), 50):\n",
        "        pts1_norm = (points1 - np.array([cx, cy])) / f\n",
        "        pts2_norm = (points2 - np.array([cx, cy])) / f\n",
        "\n",
        "        E, mask = cv2.findEssentialMat(\n",
        "            pts1_norm, pts2_norm,\n",
        "            focal=1.0, pp=(0.0, 0.0),\n",
        "            method=cv2.RANSAC,\n",
        "            prob=0.9999,\n",
        "            threshold=0.005\n",
        "        )\n",
        "\n",
        "        if mask is not None:\n",
        "            inliers = int(np.sum(mask))\n",
        "            if inliers > best_inliers:\n",
        "                best_inliers = inliers\n",
        "                best_focal = f\n",
        "\n",
        "    if best_focal is None:\n",
        "        best_focal = max_dim * 1.2\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Calibrated focal length: {best_focal:.1f} pixels\")\n",
        "        print(f\"      Inliers: {best_inliers}/{len(matches)} ({best_inliers/len(matches)*100:.1f}%)\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 1.5: Force PINHOLE model (fix PANORAMIC issue)\n",
        "    # =====================================================================\n",
        "    print(\"\\nüîß Setting PINHOLE camera model...\")\n",
        "\n",
        "    # PINHOLE model (1) requires: fx, fy, cx, cy\n",
        "    params = np.array([best_focal, best_focal, cx, cy], dtype=np.float64)\n",
        "\n",
        "    cursor.execute(\"UPDATE cameras SET model = ?, params = ?, prior_focal_length = ?\",\n",
        "                   (1, params.tobytes(), 1))\n",
        "\n",
        "    # Reset all geometric verifications to force recalculation\n",
        "    cursor.execute(\"UPDATE two_view_geometries SET config = 0\")\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"   ‚úÖ Camera model: PINHOLE (model=1)\")\n",
        "    print(f\"   ‚úÖ Parameters: fx={best_focal:.1f}, fy={best_focal:.1f}, cx={cx:.1f}, cy={cy:.1f}\")\n",
        "    print(f\"   ‚úÖ Reset geometric verifications\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 2: Select pairs FROM DATABASE (not H5!)\n",
        "    # =====================================================================\n",
        "    print(\"\\nüéØ Selecting initialization pairs FROM DATABASE...\")\n",
        "\n",
        "    def get_image_number(filename):\n",
        "        match = re.search(r'(\\d+)', filename)\n",
        "        return int(match.group(1)) if match else 0\n",
        "\n",
        "    # Get image name mapping\n",
        "    cursor.execute(\"SELECT image_id, name FROM images\")\n",
        "    id_to_name = {row[0]: row[1] for row in cursor.fetchall()}\n",
        "\n",
        "    # Get ALL matches from database\n",
        "    cursor.execute(\"SELECT pair_id, rows FROM matches\")\n",
        "    all_matches = cursor.fetchall()\n",
        "\n",
        "    pairs = []\n",
        "    for pair_id, match_count in all_matches:\n",
        "        image_id2 = pair_id % 2147483648\n",
        "        image_id1 = (pair_id - image_id2) // 2147483648\n",
        "\n",
        "        name1 = id_to_name.get(image_id1)\n",
        "        name2 = id_to_name.get(image_id2)\n",
        "\n",
        "        if name1 and name2:\n",
        "            num1 = get_image_number(name1)\n",
        "            num2 = get_image_number(name2)\n",
        "            distance = abs(num2 - num1)\n",
        "\n",
        "            pairs.append({\n",
        "                'image_id1': image_id1,\n",
        "                'image_id2': image_id2,\n",
        "                'name1': name1,\n",
        "                'name2': name2,\n",
        "                'distance': distance,\n",
        "                'matches': match_count\n",
        "            })\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    # Statistics\n",
        "    match_counts = [p['matches'] for p in pairs]\n",
        "    match_75th = np.percentile(match_counts, 75)\n",
        "\n",
        "    print(f\"\\n   Database statistics:\")\n",
        "    print(f\"   - Total pairs: {len(pairs)}\")\n",
        "    print(f\"   - 75th percentile matches: {match_75th:.0f}\")\n",
        "\n",
        "    # Filter: distance 10-25 with high match count\n",
        "    candidates = [\n",
        "        p for p in pairs\n",
        "        if 10 <= p['distance'] <= 25\n",
        "        and p['matches'] >= match_75th\n",
        "    ]\n",
        "\n",
        "    # Fallback if no candidates\n",
        "    if not candidates:\n",
        "        print(\"   ‚ö†Ô∏è  Relaxing constraints...\")\n",
        "        candidates = [\n",
        "            p for p in pairs\n",
        "            if 8 <= p['distance'] <= 30\n",
        "            and p['matches'] >= match_75th * 0.8\n",
        "        ]\n",
        "\n",
        "    # Sort by match count\n",
        "    candidates.sort(key=lambda x: x['matches'], reverse=True)\n",
        "\n",
        "    print(f\"\\n   Found {len(candidates)} candidates (distance 10-25, high matches)\")\n",
        "\n",
        "    print(\"\\nüìä Top 10 candidates from DATABASE:\")\n",
        "    for i, c in enumerate(candidates[:10], 1):\n",
        "        print(f\"   {i:2d}. {c['name1']:15s} - {c['name2']:15s}: \"\n",
        "              f\"{c['matches']:5d} matches, distance={c['distance']:2d}\")\n",
        "\n",
        "    if not candidates:\n",
        "        raise RuntimeError(\"No suitable initialization pairs found in database\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # STEP 3: Try top candidates\n",
        "    # =====================================================================\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env['QT_QPA_PLATFORM'] = 'offscreen'\n",
        "\n",
        "    max_attempts = min(5, len(candidates))\n",
        "\n",
        "    for attempt in range(max_attempts):\n",
        "        candidate = candidates[attempt]\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"üéØ Attempt {attempt + 1}/{max_attempts}\")\n",
        "        print(f\"   Pair: {candidate['name1']} - {candidate['name2']}\")\n",
        "        print(f\"   Matches: {candidate['matches']}, Distance: {candidate['distance']}\")\n",
        "        print(f\"   Image IDs: {candidate['image_id1']} <-> {candidate['image_id2']}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        print(f\"\\nüöÄ Starting mapper at {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "        print(f\"üí° PINHOLE model, focal={best_focal:.1f}, RELAXED initialization\")\n",
        "\n",
        "        cmd_mapper = [\n",
        "            'colmap', 'mapper',\n",
        "            '--database_path', database_path,\n",
        "            '--image_path', image_dir,\n",
        "            '--output_path', output_dir,\n",
        "\n",
        "            '--Mapper.init_image_id1', str(candidate['image_id1']),\n",
        "            '--Mapper.init_image_id2', str(candidate['image_id2']),\n",
        "\n",
        "            # RELAXED but not extreme\n",
        "            '--Mapper.init_min_tri_angle', '1.0',\n",
        "            '--Mapper.init_min_num_inliers', '50',     # Reasonable threshold\n",
        "            '--Mapper.init_max_error', '8',             # Standard threshold\n",
        "\n",
        "            '--Mapper.abs_pose_min_num_inliers', '20',\n",
        "            '--Mapper.abs_pose_max_error', '12',\n",
        "            '--Mapper.min_num_matches', '15',\n",
        "\n",
        "            '--Mapper.ba_refine_focal_length', '1',\n",
        "            '--Mapper.ba_refine_principal_point', '1',\n",
        "            '--Mapper.ba_refine_extra_params', '1',\n",
        "            '--Mapper.ba_global_max_num_iterations', '100',\n",
        "\n",
        "            '--Mapper.filter_max_reproj_error', '8',\n",
        "            '--Mapper.tri_min_angle', '1.5',\n",
        "\n",
        "            '--Mapper.multiple_models', '0',\n",
        "        ]\n",
        "\n",
        "        process = subprocess.Popen(\n",
        "            cmd_mapper,\n",
        "            env=env,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        print(\"-\" * 70)\n",
        "        output_lines = []\n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            if line:\n",
        "                print(line.rstrip(), flush=True)\n",
        "                output_lines.append(line)\n",
        "\n",
        "        process.stdout.close()\n",
        "        return_code = process.wait(timeout=3600)\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        initialization_failed = any(\"Initialization failed\" in line for line in output_lines)\n",
        "\n",
        "        if return_code == 0:\n",
        "            print(f\"\\n‚úÖ SUCCESS! Reconstruction saved to: {output_dir}\")\n",
        "            print(f\"üïê Completed at {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "            print(f\"üéâ Used pair {attempt + 1}: {candidate['name1']} - {candidate['name2']}\")\n",
        "\n",
        "            try:\n",
        "                import pycolmap\n",
        "                from pathlib import Path\n",
        "\n",
        "                sparse_dirs = list(Path(output_dir).glob(\"*/\"))\n",
        "                if sparse_dirs:\n",
        "                    reconstruction = pycolmap.Reconstruction(str(sparse_dirs[0]))\n",
        "\n",
        "                    num_images = len(reconstruction.images)\n",
        "                    num_points = len(reconstruction.points3D)\n",
        "\n",
        "                    print(\"\\nüìä Reconstruction Statistics:\")\n",
        "                    print(f\"   Registered images: {num_images}\")\n",
        "                    print(f\"   3D points: {num_points:,}\")\n",
        "\n",
        "                    if num_points > 0:\n",
        "                        mean_error = reconstruction.compute_mean_reprojection_error()\n",
        "                        print(f\"   Mean reprojection error: {mean_error:.2f} pixels\")\n",
        "\n",
        "                        mean_track_length = sum(\n",
        "                            len(p.track.elements) for p in reconstruction.points3D.values()\n",
        "                        ) / num_points\n",
        "                        print(f\"   Mean track length: {mean_track_length:.1f}\")\n",
        "\n",
        "                    for cam_id, camera in reconstruction.cameras.items():\n",
        "                        print(f\"\\nüì∑ Camera {cam_id}:\")\n",
        "                        print(f\"   Model: {camera.model.name}\")\n",
        "                        print(f\"   Focal: {camera.focal_length:.1f} (initial: {best_focal:.1f})\")\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è  Could not read reconstruction stats: {e}\")\n",
        "\n",
        "            return  # Success!\n",
        "\n",
        "        elif initialization_failed:\n",
        "            print(f\"\\n‚ö†Ô∏è  Pair {attempt + 1} initialization failed, trying next candidate...\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå Pair {attempt + 1} failed with error code {return_code}\")\n",
        "\n",
        "    # All attempts failed\n",
        "    print(f\"\\n‚ùå All {max_attempts} candidates failed\")\n",
        "    print(\"\\nPossible next steps:\")\n",
        "    print(\"  1. Check if images have sufficient overlap\")\n",
        "    print(\"  2. Try manual pair selection with COLMAP GUI\")\n",
        "    print(\"  3. Verify focal length calibration\")\n",
        "    raise RuntimeError(f\"COLMAP failed after {max_attempts} attempts\")"
      ],
      "metadata": {
        "id": "8TzMNBDlV9dc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jR-0QtjrV9T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_into_colmap(image_dir, feature_dir, database_path):\n",
        "    \"\"\"Import with EXACT camera dimensions - NO GROUPING\"\"\"\n",
        "    print(\"\\n=== Creating COLMAP Database ===\")\n",
        "\n",
        "    if os.path.exists(database_path):\n",
        "        os.remove(database_path)\n",
        "\n",
        "    import cv2\n",
        "\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create tables (same as before)\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cameras (\n",
        "            camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "            model INTEGER NOT NULL,\n",
        "            width INTEGER NOT NULL,\n",
        "            height INTEGER NOT NULL,\n",
        "            params BLOB,\n",
        "            prior_focal_length INTEGER NOT NULL\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS images (\n",
        "            image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "            name TEXT NOT NULL UNIQUE,\n",
        "            camera_id INTEGER NOT NULL,\n",
        "            prior_qw REAL,\n",
        "            prior_qx REAL,\n",
        "            prior_qy REAL,\n",
        "            prior_qz REAL,\n",
        "            prior_tx REAL,\n",
        "            prior_ty REAL,\n",
        "            prior_tz REAL,\n",
        "            FOREIGN KEY(camera_id) REFERENCES cameras(camera_id)\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS keypoints (\n",
        "            image_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB,\n",
        "            FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS matches (\n",
        "            pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
        "            pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "            rows INTEGER NOT NULL,\n",
        "            cols INTEGER NOT NULL,\n",
        "            data BLOB,\n",
        "            config INTEGER NOT NULL,\n",
        "            F BLOB,\n",
        "            E BLOB,\n",
        "            H BLOB,\n",
        "            qvec BLOB,\n",
        "            tvec BLOB\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    kpts_file = os.path.join(feature_dir, 'keypoints.h5')\n",
        "    matches_file = os.path.join(feature_dir, 'matches.h5')\n",
        "\n",
        "    # üî• NO GROUPING - Use EXACT dimensions\n",
        "    size_to_camera = {}\n",
        "    fname_to_id = {}\n",
        "    image_id = 1\n",
        "\n",
        "    with h5py.File(kpts_file, 'r') as f:\n",
        "        print(f\"Importing {len(f.keys())} images...\")\n",
        "\n",
        "        for filename in tqdm(f.keys(), desc=\"Adding images\"):\n",
        "            image_path = os.path.join(image_dir, filename)\n",
        "            try:\n",
        "                img = Image.open(image_path)\n",
        "                width, height = img.size  # ÂÆüÈöõ„ÅÆ„Çµ„Ç§„Ç∫: 768x1024\n",
        "                img.close()\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            # üî• Use EXACT size as key\n",
        "            size_key = (width, height)\n",
        "\n",
        "            if size_key not in size_to_camera:\n",
        "                # ÁÑ¶ÁÇπË∑ùÈõ¢„ÅØÊé®Ê∏¨ÂÄ§ÔºàÂæå„ÅßÊ†°Ê≠£Ôºâ\n",
        "                focal = max(width, height) * 1.2\n",
        "                params = np.array([focal, width/2, height/2, 0.0], dtype=np.float64)\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "                    (None, 2, width, height, params.tobytes(), 1)\n",
        "                )\n",
        "                size_to_camera[size_key] = cursor.lastrowid\n",
        "                print(f\"  Created camera: {width}x{height}, focal={focal:.0f}\")\n",
        "\n",
        "            camera_id = size_to_camera[size_key]\n",
        "            cursor.execute(\n",
        "                \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "                (image_id, filename, camera_id, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "            )\n",
        "            fname_to_id[filename] = image_id\n",
        "\n",
        "            kpts = f[filename][()].astype(np.float32)\n",
        "            if len(kpts.shape) == 1:\n",
        "                kpts = kpts.reshape(-1, 2)\n",
        "            cursor.execute(\n",
        "                \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
        "                (image_id, kpts.shape[0], 2, kpts.tobytes())\n",
        "            )\n",
        "            image_id += 1\n",
        "\n",
        "    print(f\"\\n‚úÖ Created {len(size_to_camera)} camera(s) with EXACT dimensions\")\n",
        "\n",
        "    # Geometric verification (same as before)\n",
        "    verified_count = 0\n",
        "\n",
        "    with h5py.File(kpts_file, 'r') as f_kpts:\n",
        "        with h5py.File(matches_file, 'r') as f_matches:\n",
        "            print(f\"\\nüîß Processing matches with geometric verification...\")\n",
        "\n",
        "            for key1 in tqdm(f_matches.keys(), desc=\"Verifying\"):\n",
        "                if key1 not in fname_to_id:\n",
        "                    continue\n",
        "\n",
        "                for key2 in f_matches[key1].keys():\n",
        "                    if key2 not in fname_to_id:\n",
        "                        continue\n",
        "\n",
        "                    id1, id2 = fname_to_id[key1], fname_to_id[key2]\n",
        "                    if id1 >= id2:\n",
        "                        continue\n",
        "\n",
        "                    matches = f_matches[key1][key2][()].astype(np.uint32)\n",
        "                    if matches.shape[0] < 15:\n",
        "                        continue\n",
        "\n",
        "                    kpts1 = f_kpts[key1][()].astype(np.float64)\n",
        "                    kpts2 = f_kpts[key2][()].astype(np.float64)\n",
        "\n",
        "                    if len(kpts1.shape) == 1:\n",
        "                        kpts1 = kpts1.reshape(-1, 2)\n",
        "                    if len(kpts2.shape) == 1:\n",
        "                        kpts2 = kpts2.reshape(-1, 2)\n",
        "\n",
        "                    pts1 = kpts1[matches[:, 0]]\n",
        "                    pts2 = kpts2[matches[:, 1]]\n",
        "\n",
        "                    try:\n",
        "                        F, mask = cv2.findFundamentalMat(\n",
        "                            pts1, pts2,\n",
        "                            cv2.FM_RANSAC,\n",
        "                            3.0, 0.999\n",
        "                        )\n",
        "\n",
        "                        if F is None or mask is None:\n",
        "                            continue\n",
        "\n",
        "                        inliers = matches[mask.ravel() == 1]\n",
        "\n",
        "                        if len(inliers) < 15:\n",
        "                            continue\n",
        "\n",
        "                        pair_id = id1 * 2147483648 + id2\n",
        "\n",
        "                        cursor.execute(\n",
        "                            \"INSERT INTO matches VALUES (?, ?, ?, ?)\",\n",
        "                            (pair_id, len(inliers), 2, inliers.astype(np.uint32).tobytes())\n",
        "                        )\n",
        "\n",
        "                        cursor.execute(\n",
        "                            \"INSERT INTO two_view_geometries VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "                            (pair_id, len(inliers), 2, inliers.astype(np.uint32).tobytes(),\n",
        "                             2, F.astype(np.float64).tobytes(),\n",
        "                             None, None, None, None)\n",
        "                        )\n",
        "\n",
        "                        verified_count += 1\n",
        "\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"\\n‚úì Database created: {database_path}\")\n",
        "    print(f\"  Cameras: {len(size_to_camera)}\")\n",
        "    print(f\"  Images: {len(fname_to_id)}\")\n",
        "    print(f\"  ‚úÖ Geometrically verified pairs: {verified_count}\")\n",
        "\n",
        "    return fname_to_id"
      ],
      "metadata": {
        "id": "7gQdy_QYTtjp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_pipeline(image_dir, output_base_dir):\n",
        "    \"\"\"Complete pipeline\"\"\"\n",
        "\n",
        "    from datetime import datetime, timezone\n",
        "\n",
        "    print(f\"\\nüöÄ Pipeline started at {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Get images\n",
        "    img_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "    fnames = []\n",
        "    for ext in img_extensions:\n",
        "        fnames.extend(glob.glob(os.path.join(image_dir, ext)))\n",
        "    fnames = sorted(fnames)\n",
        "    print(f\"\\nüì∏ Found {len(fnames)} images\")\n",
        "\n",
        "    if len(fnames) == 0:\n",
        "        raise ValueError(\"No images found!\")\n",
        "\n",
        "    # Create directories\n",
        "    feature_dir = os.path.join(output_base_dir, 'features')\n",
        "    colmap_dir = os.path.join(output_base_dir, 'colmap')\n",
        "    sparse_dir = os.path.join(colmap_dir, 'sparse')\n",
        "    os.makedirs(feature_dir, exist_ok=True)\n",
        "    os.makedirs(colmap_dir, exist_ok=True)\n",
        "\n",
        "    # Stages 1-3: Feature extraction and matching\n",
        "    print(f\"\\n‚è∞ Stage 1 started: {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    global_feats = extract_dino_embeddings(fnames, device)\n",
        "\n",
        "    print(f\"\\n‚è∞ Stage 2 started: {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    initial_pairs = build_topk_pairs(global_feats, device)\n",
        "    keypoints_dict, descriptors_dict = extract_aliked_features(fnames, device)\n",
        "\n",
        "    print(f\"\\n‚è∞ Stage 3 started: {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    verified_pairs = verify_pairs_with_local_features(\n",
        "        initial_pairs, fnames, descriptors_dict, device\n",
        "    )\n",
        "    match_with_lightglue(\n",
        "        verified_pairs, fnames, keypoints_dict, descriptors_dict,\n",
        "        feature_dir, device\n",
        "    )\n",
        "\n",
        "    from datetime import datetime, timezone\n",
        "    print()\n",
        "    print(datetime.now(timezone.utc))\n",
        "\n",
        "    print(f\"\\n‚è∞ Stage 4 started: {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "    # Stage 4: COLMAP Database + Reconstruction\n",
        "    database_path = os.path.join(colmap_dir, 'database.db')\n",
        "    #import_into_colmap(image_dir, feature_dir, database_path)\n",
        "    import_into_colmap(image_dir, feature_dir, database_path)\n",
        "    run_colmap_sequential(database_path, image_dir, sparse_dir)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"‚úÖ Pipeline Complete!\")\n",
        "    print(f\"üïê Finished at {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "main_pipeline(RESIZED, OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "123c66944fe74f9193414169d81779b8",
            "aa946603efee4d92b8f3f08fdc53ffff",
            "a44e1f2691d6420a90693843ddad4233",
            "6f83a1c30af04532a394f00dd3b907c6",
            "78c4a040b1e54f00985c402a4665574d",
            "69ad0dfa1b2d45d788970c8f44509761",
            "41a59ba6583844a395d1eebec09b1631",
            "dd41e5c9b9684463a164fe5b70ecef0d",
            "ff5ed1421846457da8550b0472836ac2",
            "516c383bac544d1fb22721b7babe1954",
            "5580aabfd132440c8522c3a18bd4cbfa",
            "0c7daadaf49e487e94c1615726fb5d1a",
            "568c0e8019c349dbb87a300eec8d62b6",
            "f2c7f978d7d143ba89383b87a1d42f6f",
            "5afb5a05b5ff485e90301a69d817f5f0",
            "522576272bbc44e0900c0b0906633e94",
            "790f8ae73ae64a46b1cdba98b0495c2a",
            "850bf06142fb4ccfaa1dcd4d162e036c",
            "c8074e8c64e34ad49d884aef5bd923c3",
            "03a80f7ca4534490807a8a3614655181",
            "9d27d56da5444929a0ac87552b5fb6ab",
            "f3c03891c9004f5293c2b80022ec43b9",
            "77653741899c4b738f52b39b59285f34",
            "8f6503990a1c4eb598ee16631db52e27",
            "cf2c35c0ee8b43dfb7d965fb5cef5803",
            "ca01ba86a0a7402f90983040288d2b4d",
            "576dd5c4417c45e78cb54bed46936e85",
            "8a90fbe51972488eab664b043b5cbac6",
            "8923556812454e1d8f9f0fbdce9ac090",
            "95da7e164e8b4fa395257fe8541e7bc6",
            "9c4784a893c449ecafd54a34a5571e0c",
            "f92917bb24f241d38058addf3dcb2ad4",
            "2baba335c63340b694f03bb8214e3e9d"
          ]
        },
        "id": "-bfvkO7NS-gx",
        "outputId": "da330d36-1d6c-49d7-e126-413309ae5713"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Pipeline started at 2026-01-07 17:19:38 UTC\n",
            "\n",
            "üì∏ Found 80 images\n",
            "\n",
            "‚è∞ Stage 1 started: 17:19:38 UTC\n",
            "\n",
            "=== Stage 1: Extracting DINO Global Features ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "123c66944fe74f9193414169d81779b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c7daadaf49e487e94c1615726fb5d1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77653741899c4b738f52b39b59285f34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DINO extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:11<00:00,  7.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted global features: torch.Size([80, 768])\n",
            "\n",
            "‚è∞ Stage 2 started: 17:19:55 UTC\n",
            "\n",
            "=== Building Top-K Pairs from Global Features ===\n",
            "Initial pairs from global features: 3160\n",
            "\n",
            "=== Stage 2: Extracting ALIKED Local Features ===\n",
            "Downloading: \"https://github.com/Shiaoming/ALIKED/raw/main/models/aliked-n16.pth\" to /root/.cache/torch/hub/checkpoints/aliked-n16.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.61M/2.61M [00:00<00:00, 62.5MB/s]\n",
            "ALIKED extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:07<00:00, 11.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features for 80 images\n",
            "\n",
            "‚è∞ Stage 3 started: 17:20:03 UTC\n",
            "\n",
            "=== Verifying Pairs with Local Features ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Local verification: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3160/3160 [00:10<00:00, 289.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verified pairs: 3160\n",
            "\n",
            "=== Stage 3: Matching with LightGlue ===\n",
            "Downloading: \"https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/aliked_lightglue.pth\" to /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45.4M/45.4M [00:00<00:00, 65.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded LightGlue model\n",
            "Loaded LightGlue model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LightGlue matching: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3160/3160 [15:52<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matching complete:\n",
            "  Matched pairs: 3017\n",
            "  Skipped pairs: 143\n",
            "  Total matches: 3427313\n",
            "  Average matches per pair: 1136.0\n",
            "  Success rate: 95.5%\n",
            "\n",
            "Saved keypoints to: /content/output/features/keypoints.h5\n",
            "Saved matches to: /content/output/features/matches.h5\n",
            "\n",
            "2026-01-07 17:36:08.983309+00:00\n",
            "\n",
            "‚è∞ Stage 4 started: 17:36:08 UTC\n",
            "\n",
            "=== Creating COLMAP Database ===\n",
            "Importing 80 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adding images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 1774.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Created camera: 768x1024, focal=1229\n",
            "\n",
            "‚úÖ Created 1 camera(s) with EXACT dimensions\n",
            "\n",
            "üîß Processing matches with geometric verification...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verifying: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:33<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úì Database created: /content/output/colmap/database.db\n",
            "  Cameras: 1\n",
            "  Images: 80\n",
            "  ‚úÖ Geometrically verified pairs: 2876\n",
            "\n",
            "=== Stage 4: Running COLMAP Reconstruction ===\n",
            "\n",
            "üîß Calibrating focal length from matches...\n",
            "   Using pair with 6967 matches\n",
            "   Image size: 768x1024\n",
            "   ‚úÖ Calibrated focal length: 716.0 pixels\n",
            "      Inliers: 6967/6967 (100.0%)\n",
            "\n",
            "üîß Setting PINHOLE camera model...\n",
            "   ‚úÖ Camera model: PINHOLE (model=1)\n",
            "   ‚úÖ Parameters: fx=716.0, fy=716.0, cx=384.0, cy=512.0\n",
            "   ‚úÖ Reset geometric verifications\n",
            "\n",
            "üéØ Selecting initialization pairs FROM DATABASE...\n",
            "\n",
            "   Database statistics:\n",
            "   - Total pairs: 2876\n",
            "   - 75th percentile matches: 1975\n",
            "\n",
            "   Found 73 candidates (distance 10-25, high matches)\n",
            "\n",
            "üìä Top 10 candidates from DATABASE:\n",
            "    1. image_037.jpeg  - image_047.jpeg :  2548 matches, distance=10\n",
            "    2. image_035.jpeg  - image_045.jpeg :  2506 matches, distance=10\n",
            "    3. image_038.jpeg  - image_048.jpeg :  2504 matches, distance=10\n",
            "    4. image_039.jpeg  - image_049.jpeg :  2488 matches, distance=10\n",
            "    5. image_036.jpeg  - image_046.jpeg :  2457 matches, distance=10\n",
            "    6. image_060.jpeg  - image_070.jpeg :  2380 matches, distance=10\n",
            "    7. image_034.jpeg  - image_044.jpeg :  2375 matches, distance=10\n",
            "    8. image_037.jpeg  - image_048.jpeg :  2353 matches, distance=11\n",
            "    9. image_026.jpeg  - image_036.jpeg :  2346 matches, distance=10\n",
            "   10. image_059.jpeg  - image_069.jpeg :  2345 matches, distance=10\n",
            "\n",
            "======================================================================\n",
            "üéØ Attempt 1/5\n",
            "   Pair: image_037.jpeg - image_047.jpeg\n",
            "   Matches: 2548, Distance: 10\n",
            "   Image IDs: 38 <-> 48\n",
            "======================================================================\n",
            "\n",
            "üöÄ Starting mapper at 17:36:42 UTC\n",
            "üí° PINHOLE model, focal=716.0, RELAXED initialization\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "==============================================================================\n",
            "Loading database\n",
            "==============================================================================\n",
            "\n",
            "Loading cameras... 1 in 0.000s\n",
            "Loading matches... 2876 in 0.052s\n",
            "Loading images... 80 in 0.027s (connected 80)\n",
            "Building correspondence graph... in 0.267s (ignored 1460)\n",
            "\n",
            "Elapsed time: 0.006 [minutes]\n",
            "\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #38 and #48\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #38 and #48\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #38 and #48\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #38 and #48\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #38 and #48\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "\n",
            "Elapsed time: 0.011 [minutes]\n",
            "ERROR: failed to create sparse model\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Pair 1 initialization failed, trying next candidate...\n",
            "\n",
            "======================================================================\n",
            "üéØ Attempt 2/5\n",
            "   Pair: image_035.jpeg - image_045.jpeg\n",
            "   Matches: 2506, Distance: 10\n",
            "   Image IDs: 36 <-> 46\n",
            "======================================================================\n",
            "\n",
            "üöÄ Starting mapper at 17:36:43 UTC\n",
            "üí° PINHOLE model, focal=716.0, RELAXED initialization\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "==============================================================================\n",
            "Loading database\n",
            "==============================================================================\n",
            "\n",
            "Loading cameras... 1 in 0.001s\n",
            "Loading matches... 2876 in 0.059s\n",
            "Loading images... 80 in 0.028s (connected 80)\n",
            "Building correspondence graph... in 0.269s (ignored 1460)\n",
            "\n",
            "Elapsed time: 0.006 [minutes]\n",
            "\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #36 and #46\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #36 and #46\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #36 and #46\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #36 and #46\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #36 and #46\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "\n",
            "Elapsed time: 0.012 [minutes]\n",
            "ERROR: failed to create sparse model\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Pair 2 initialization failed, trying next candidate...\n",
            "\n",
            "======================================================================\n",
            "üéØ Attempt 3/5\n",
            "   Pair: image_038.jpeg - image_048.jpeg\n",
            "   Matches: 2504, Distance: 10\n",
            "   Image IDs: 39 <-> 49\n",
            "======================================================================\n",
            "\n",
            "üöÄ Starting mapper at 17:36:44 UTC\n",
            "üí° PINHOLE model, focal=716.0, RELAXED initialization\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "==============================================================================\n",
            "Loading database\n",
            "==============================================================================\n",
            "\n",
            "Loading cameras... 1 in 0.000s\n",
            "Loading matches... 2876 in 0.067s\n",
            "Loading images... 80 in 0.047s (connected 80)\n",
            "Building correspondence graph... in 0.274s (ignored 1460)\n",
            "\n",
            "Elapsed time: 0.007 [minutes]\n",
            "\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #39 and #49\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #39 and #49\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #39 and #49\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #39 and #49\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #39 and #49\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "\n",
            "Elapsed time: 0.012 [minutes]\n",
            "ERROR: failed to create sparse model\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Pair 3 initialization failed, trying next candidate...\n",
            "\n",
            "======================================================================\n",
            "üéØ Attempt 4/5\n",
            "   Pair: image_039.jpeg - image_049.jpeg\n",
            "   Matches: 2488, Distance: 10\n",
            "   Image IDs: 40 <-> 50\n",
            "======================================================================\n",
            "\n",
            "üöÄ Starting mapper at 17:36:45 UTC\n",
            "üí° PINHOLE model, focal=716.0, RELAXED initialization\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "==============================================================================\n",
            "Loading database\n",
            "==============================================================================\n",
            "\n",
            "Loading cameras... 1 in 0.000s\n",
            "Loading matches... 2876 in 0.068s\n",
            "Loading images... 80 in 0.038s (connected 80)\n",
            "Building correspondence graph... in 0.413s (ignored 1460)\n",
            "\n",
            "Elapsed time: 0.009 [minutes]\n",
            "\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #40 and #50\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #40 and #50\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #40 and #50\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #40 and #50\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #40 and #50\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "\n",
            "Elapsed time: 0.016 [minutes]\n",
            "ERROR: failed to create sparse model\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Pair 4 initialization failed, trying next candidate...\n",
            "\n",
            "======================================================================\n",
            "üéØ Attempt 5/5\n",
            "   Pair: image_036.jpeg - image_046.jpeg\n",
            "   Matches: 2457, Distance: 10\n",
            "   Image IDs: 37 <-> 47\n",
            "======================================================================\n",
            "\n",
            "üöÄ Starting mapper at 17:36:46 UTC\n",
            "üí° PINHOLE model, focal=716.0, RELAXED initialization\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "==============================================================================\n",
            "Loading database\n",
            "==============================================================================\n",
            "\n",
            "Loading cameras... 1 in 0.000s\n",
            "Loading matches... 2876 in 0.070s\n",
            "Loading images... 80 in 0.044s (connected 80)\n",
            "Building correspondence graph... in 0.436s (ignored 1460)\n",
            "\n",
            "Elapsed time: 0.009 [minutes]\n",
            "\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #37 and #47\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #37 and #47\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #37 and #47\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #37 and #47\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "  => Relaxing the initialization constraints.\n",
            "\n",
            "==============================================================================\n",
            "Initializing with image pair #37 and #47\n",
            "==============================================================================\n",
            "\n",
            "  => Initialization failed - possible solutions:\n",
            "     - try to relax the initialization constraints\n",
            "     - manually select an initial image pair\n",
            "\n",
            "Elapsed time: 0.016 [minutes]\n",
            "ERROR: failed to create sparse model\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚ö†Ô∏è  Pair 5 initialization failed, trying next candidate...\n",
            "\n",
            "‚ùå All 5 candidates failed\n",
            "\n",
            "Possible next steps:\n",
            "  1. Check if images have sufficient overlap\n",
            "  2. Try manual pair selection with COLMAP GUI\n",
            "  3. Verify focal length calibration\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "COLMAP failed after 5 attempts",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1765179838.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mmain_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESIZED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1765179838.py\u001b[0m in \u001b[0;36mmain_pipeline\u001b[0;34m(image_dir, output_base_dir)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m#import_into_colmap(image_dir, feature_dir, database_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mimport_into_colmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mrun_colmap_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-601425890.py\u001b[0m in \u001b[0;36mrun_colmap_sequential\u001b[0;34m(database_path, image_dir, output_dir)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  2. Try manual pair selection with COLMAP GUI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  3. Verify focal length calibration\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"COLMAP failed after {max_attempts} attempts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: COLMAP failed after 5 attempts"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8SiZgkfyeL5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3PnJMY7eLu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ypJ7MvA27mpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('--------------debug--------------')"
      ],
      "metadata": {
        "id": "VcaR1Xc9sa_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syLqYiY2UD0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "\n",
        "def fix_colmap_database(database_path):\n",
        "    \"\"\"Fix COLMAP database to use calibrated camera model instead of PANORAMIC\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üîß FIXING COLMAP DATABASE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # =====================================================================\n",
        "    # 1. Check current camera model\n",
        "    # =====================================================================\n",
        "    print(\"\\n1Ô∏è‚É£ Current camera configuration:\")\n",
        "    cursor.execute(\"SELECT camera_id, model, width, height, params FROM cameras\")\n",
        "    camera = cursor.fetchone()\n",
        "\n",
        "    camera_id, model, width, height, params_blob = camera\n",
        "    params = np.frombuffer(params_blob, dtype=np.float64)\n",
        "\n",
        "    model_names = {\n",
        "        0: \"SIMPLE_PINHOLE\",\n",
        "        1: \"PINHOLE\",\n",
        "        2: \"SIMPLE_RADIAL\",\n",
        "        3: \"RADIAL\",\n",
        "        4: \"OPENCV\",\n",
        "        5: \"OPENCV_FISHEYE\",\n",
        "        6: \"FULL_OPENCV\"\n",
        "    }\n",
        "\n",
        "    print(f\"   Model: {model} ({model_names.get(model, 'UNKNOWN')})\")\n",
        "    print(f\"   Size: {width}x{height}\")\n",
        "    print(f\"   Parameters: {params}\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 2. Force PINHOLE model with correct calibration\n",
        "    # =====================================================================\n",
        "    print(\"\\n2Ô∏è‚É£ Forcing PINHOLE model (model=1)...\")\n",
        "\n",
        "    # PINHOLE model requires: fx, fy, cx, cy\n",
        "    focal = params[0]  # Use calibrated focal length\n",
        "    cx = width / 2\n",
        "    cy = height / 2\n",
        "\n",
        "    new_params = np.array([focal, focal, cx, cy], dtype=np.float64)\n",
        "\n",
        "    # Update to PINHOLE model (1)\n",
        "    cursor.execute(\n",
        "        \"UPDATE cameras SET model = ?, params = ?, prior_focal_length = ? WHERE camera_id = ?\",\n",
        "        (1, new_params.tobytes(), 1, camera_id)\n",
        "    )\n",
        "\n",
        "    print(f\"   ‚úÖ Updated to PINHOLE model\")\n",
        "    print(f\"   Parameters: fx={focal:.1f}, fy={focal:.1f}, cx={cx:.1f}, cy={cy:.1f}\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 3. Re-verify geometric relationships with correct model\n",
        "    # =====================================================================\n",
        "    print(\"\\n3Ô∏è‚É£ Clearing PANORAMIC geometric verifications...\")\n",
        "\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM two_view_geometries WHERE config = 2\")\n",
        "    panoramic_count = cursor.fetchone()[0]\n",
        "\n",
        "    print(f\"   Found {panoramic_count} PANORAMIC pairs\")\n",
        "    print(f\"   Note: These will be re-computed by COLMAP with correct model\")\n",
        "\n",
        "    # Option 1: Delete all geometric verifications (COLMAP will recompute)\n",
        "    # cursor.execute(\"DELETE FROM two_view_geometries\")\n",
        "    # print(f\"   ‚úÖ Deleted all geometric verifications\")\n",
        "\n",
        "    # Option 2: Just change configuration (faster)\n",
        "    # Configuration 0 = uncalibrated, will force proper estimation\n",
        "    cursor.execute(\"UPDATE two_view_geometries SET config = 0\")\n",
        "    print(f\"   ‚úÖ Reset all pairs to UNCALIBRATED (config=0)\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\n‚úÖ Database fixed!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "def select_pairs_from_database(database_path):\n",
        "    \"\"\"Select initialization pairs from DATABASE (not H5)\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üéØ SELECTING PAIRS FROM DATABASE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Get image name mapping\n",
        "    cursor.execute(\"SELECT image_id, name FROM images\")\n",
        "    id_to_name = {row[0]: row[1] for row in cursor.fetchall()}\n",
        "    name_to_id = {row[1]: row[0] for row in cursor.fetchall()}\n",
        "\n",
        "    # Get matches from database (what COLMAP actually sees)\n",
        "    cursor.execute(\"SELECT pair_id, rows FROM matches ORDER BY rows DESC\")\n",
        "    all_matches = cursor.fetchall()\n",
        "\n",
        "    # Parse pairs with distances\n",
        "    import re\n",
        "    def get_image_number(filename):\n",
        "        match = re.search(r'(\\d+)', filename)\n",
        "        return int(match.group(1)) if match else 0\n",
        "\n",
        "    pairs = []\n",
        "    for pair_id, match_count in all_matches:\n",
        "        image_id2 = pair_id % 2147483648\n",
        "        image_id1 = (pair_id - image_id2) // 2147483648\n",
        "\n",
        "        name1 = id_to_name.get(image_id1)\n",
        "        name2 = id_to_name.get(image_id2)\n",
        "\n",
        "        if name1 and name2:\n",
        "            num1 = get_image_number(name1)\n",
        "            num2 = get_image_number(name2)\n",
        "            distance = abs(num2 - num1)\n",
        "\n",
        "            pairs.append({\n",
        "                'image_id1': image_id1,\n",
        "                'image_id2': image_id2,\n",
        "                'name1': name1,\n",
        "                'name2': name2,\n",
        "                'distance': distance,\n",
        "                'matches': match_count\n",
        "            })\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    # =====================================================================\n",
        "    # Filter for good initialization pairs\n",
        "    # =====================================================================\n",
        "    print(f\"\\n   Total pairs in database: {len(pairs)}\")\n",
        "\n",
        "    # Strategy: Find pairs with:\n",
        "    # 1. Good baseline (distance 10-25)\n",
        "    # 2. High match count (top 25%)\n",
        "    match_counts = [p['matches'] for p in pairs]\n",
        "    match_75th = np.percentile(match_counts, 75)\n",
        "\n",
        "    print(f\"   75th percentile matches: {match_75th:.0f}\")\n",
        "\n",
        "    # Filter candidates\n",
        "    candidates = [\n",
        "        p for p in pairs\n",
        "        if 10 <= p['distance'] <= 25  # Good baseline\n",
        "        and p['matches'] >= match_75th  # High quality\n",
        "    ]\n",
        "\n",
        "    # Sort by match count\n",
        "    candidates.sort(key=lambda x: x['matches'], reverse=True)\n",
        "\n",
        "    print(f\"\\n   Candidates (distance 10-25, high matches): {len(candidates)}\")\n",
        "\n",
        "    if not candidates:\n",
        "        print(\"   ‚ö†Ô∏è  No candidates found, relaxing distance constraint...\")\n",
        "        candidates = [\n",
        "            p for p in pairs\n",
        "            if 8 <= p['distance'] <= 30\n",
        "            and p['matches'] >= match_75th * 0.8\n",
        "        ]\n",
        "        candidates.sort(key=lambda x: x['matches'], reverse=True)\n",
        "\n",
        "    print(\"\\nüìä Top 10 candidates from DATABASE:\")\n",
        "    print(\"   \" + \"-\"*70)\n",
        "    for i, c in enumerate(candidates[:10], 1):\n",
        "        print(f\"   {i:2d}. {c['name1']:15s} - {c['name2']:15s}: \"\n",
        "              f\"{c['matches']:5d} matches, distance={c['distance']:2d}\")\n",
        "        print(f\"       Image IDs: {c['image_id1']} <-> {c['image_id2']}\")\n",
        "\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return candidates[:5]  # Return top 5\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# USAGE\n",
        "# =====================================================================\n",
        "database_path = \"/content/output/colmap/database.db\"\n",
        "\n",
        "# Step 1: Fix the database\n",
        "fix_colmap_database(database_path)\n",
        "\n",
        "# Step 2: Get correct pairs\n",
        "candidates = select_pairs_from_database(database_path)\n",
        "\n",
        "print(\"\\nüéØ Use these image IDs for initialization:\")\n",
        "for i, c in enumerate(candidates, 1):\n",
        "    print(f\"{i}. --Mapper.init_image_id1 {c['image_id1']} --Mapper.init_image_id2 {c['image_id2']}\")"
      ],
      "metadata": {
        "id": "X-4edtRMUDtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78f9335-0f3b-4f5b-9a9a-f9a44a4e1a47"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üîß FIXING COLMAP DATABASE\n",
            "======================================================================\n",
            "\n",
            "1Ô∏è‚É£ Current camera configuration:\n",
            "   Model: 1 (PINHOLE)\n",
            "   Size: 768x1024\n",
            "   Parameters: [716. 716. 384. 512.]\n",
            "\n",
            "2Ô∏è‚É£ Forcing PINHOLE model (model=1)...\n",
            "   ‚úÖ Updated to PINHOLE model\n",
            "   Parameters: fx=716.0, fy=716.0, cx=384.0, cy=512.0\n",
            "\n",
            "3Ô∏è‚É£ Clearing PANORAMIC geometric verifications...\n",
            "   Found 0 PANORAMIC pairs\n",
            "   Note: These will be re-computed by COLMAP with correct model\n",
            "   ‚úÖ Reset all pairs to UNCALIBRATED (config=0)\n",
            "\n",
            "‚úÖ Database fixed!\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "üéØ SELECTING PAIRS FROM DATABASE\n",
            "======================================================================\n",
            "\n",
            "   Total pairs in database: 2876\n",
            "   75th percentile matches: 1975\n",
            "\n",
            "   Candidates (distance 10-25, high matches): 73\n",
            "\n",
            "üìä Top 10 candidates from DATABASE:\n",
            "   ----------------------------------------------------------------------\n",
            "    1. image_037.jpeg  - image_047.jpeg :  2548 matches, distance=10\n",
            "       Image IDs: 38 <-> 48\n",
            "    2. image_035.jpeg  - image_045.jpeg :  2506 matches, distance=10\n",
            "       Image IDs: 36 <-> 46\n",
            "    3. image_038.jpeg  - image_048.jpeg :  2504 matches, distance=10\n",
            "       Image IDs: 39 <-> 49\n",
            "    4. image_039.jpeg  - image_049.jpeg :  2488 matches, distance=10\n",
            "       Image IDs: 40 <-> 50\n",
            "    5. image_036.jpeg  - image_046.jpeg :  2457 matches, distance=10\n",
            "       Image IDs: 37 <-> 47\n",
            "    6. image_060.jpeg  - image_070.jpeg :  2380 matches, distance=10\n",
            "       Image IDs: 61 <-> 71\n",
            "    7. image_034.jpeg  - image_044.jpeg :  2375 matches, distance=10\n",
            "       Image IDs: 35 <-> 45\n",
            "    8. image_037.jpeg  - image_048.jpeg :  2353 matches, distance=11\n",
            "       Image IDs: 38 <-> 49\n",
            "    9. image_026.jpeg  - image_036.jpeg :  2346 matches, distance=10\n",
            "       Image IDs: 27 <-> 37\n",
            "   10. image_059.jpeg  - image_069.jpeg :  2345 matches, distance=10\n",
            "       Image IDs: 60 <-> 70\n",
            "======================================================================\n",
            "\n",
            "üéØ Use these image IDs for initialization:\n",
            "1. --Mapper.init_image_id1 38 --Mapper.init_image_id2 48\n",
            "2. --Mapper.init_image_id1 36 --Mapper.init_image_id2 46\n",
            "3. --Mapper.init_image_id1 39 --Mapper.init_image_id2 49\n",
            "4. --Mapper.init_image_id1 40 --Mapper.init_image_id2 50\n",
            "5. --Mapper.init_image_id1 37 --Mapper.init_image_id2 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "\n",
        "def inspect_colmap_database(database_path):\n",
        "    \"\"\"Inspect COLMAP database structure and sample data\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üîç COLMAP DATABASE INSPECTION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # =====================================================================\n",
        "    # 1. CAMERAS TABLE\n",
        "    # =====================================================================\n",
        "    print(\"\\n1Ô∏è‚É£ CAMERAS TABLE\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    cursor.execute(\"SELECT * FROM cameras\")\n",
        "    cameras = cursor.fetchall()\n",
        "\n",
        "    print(f\"Total cameras: {len(cameras)}\")\n",
        "    for cam in cameras:\n",
        "        camera_id, model, width, height, params_blob, prior_focal_length = cam\n",
        "        params = np.frombuffer(params_blob, dtype=np.float64)\n",
        "\n",
        "        print(f\"\\nCamera ID: {camera_id}\")\n",
        "        print(f\"  Model: {model} (0=SIMPLE_PINHOLE, 1=PINHOLE, 2=SIMPLE_RADIAL, 3=RADIAL)\")\n",
        "        print(f\"  Image size: {width} x {height}\")\n",
        "        print(f\"  Parameters (raw binary -> float64 array):\")\n",
        "        print(f\"    {params}\")\n",
        "        print(f\"  Interpretation:\")\n",
        "        if model == 0:  # SIMPLE_PINHOLE\n",
        "            print(f\"    - focal length (f): {params[0]:.2f}\")\n",
        "            print(f\"    - principal point (cx, cy): ({params[1]:.2f}, {params[2]:.2f})\")\n",
        "        elif model == 1:  # PINHOLE\n",
        "            print(f\"    - focal lengths (fx, fy): ({params[0]:.2f}, {params[1]:.2f})\")\n",
        "            print(f\"    - principal point (cx, cy): ({params[2]:.2f}, {params[3]:.2f})\")\n",
        "        print(f\"  Prior focal length: {prior_focal_length}\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 2. IMAGES TABLE\n",
        "    # =====================================================================\n",
        "    print(\"\\n2Ô∏è‚É£ IMAGES TABLE (sample)\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM images\")\n",
        "    total_images = cursor.fetchone()[0]\n",
        "    print(f\"Total images: {total_images}\")\n",
        "\n",
        "    cursor.execute(\"SELECT * FROM images LIMIT 5\")\n",
        "    images = cursor.fetchall()\n",
        "\n",
        "    print(\"\\nFirst 5 images:\")\n",
        "    for img in images:\n",
        "        image_id, name, camera_id, prior_qw, prior_qx, prior_qy, prior_qz, prior_tx, prior_ty, prior_tz = img\n",
        "        print(f\"\\n  Image ID: {image_id}\")\n",
        "        print(f\"    Name: {name}\")\n",
        "        print(f\"    Camera ID: {camera_id}\")\n",
        "        print(f\"    Prior pose (quaternion): [{prior_qw:.3f}, {prior_qx:.3f}, {prior_qy:.3f}, {prior_qz:.3f}]\")\n",
        "        print(f\"    Prior translation: [{prior_tx:.3f}, {prior_ty:.3f}, {prior_tz:.3f}]\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 3. KEYPOINTS TABLE\n",
        "    # =====================================================================\n",
        "    print(\"\\n3Ô∏è‚É£ KEYPOINTS TABLE (sample)\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM keypoints\")\n",
        "    total_kpts = cursor.fetchone()[0]\n",
        "    print(f\"Total keypoint records: {total_kpts}\")\n",
        "\n",
        "    cursor.execute(\"SELECT image_id, data FROM keypoints LIMIT 3\")\n",
        "    keypoints = cursor.fetchall()\n",
        "\n",
        "    print(\"\\nFirst 3 keypoint records:\")\n",
        "    for image_id, kpts_blob in keypoints:\n",
        "        kpts = np.frombuffer(kpts_blob, dtype=np.float32).reshape(-1, 2)\n",
        "        print(f\"\\n  Image ID: {image_id}\")\n",
        "        print(f\"    Total keypoints: {len(kpts)}\")\n",
        "        print(f\"    Data format: float32 array, shape=({len(kpts)}, 2)\")\n",
        "        print(f\"    First 5 keypoints (x, y):\")\n",
        "        for i, kpt in enumerate(kpts[:5]):\n",
        "            print(f\"      [{i}]: ({kpt[0]:.2f}, {kpt[1]:.2f})\")\n",
        "        print(f\"    Statistics:\")\n",
        "        print(f\"      X range: [{kpts[:, 0].min():.1f}, {kpts[:, 0].max():.1f}]\")\n",
        "        print(f\"      Y range: [{kpts[:, 1].min():.1f}, {kpts[:, 1].max():.1f}]\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 4. MATCHES TABLE\n",
        "    # =====================================================================\n",
        "    print(\"\\n4Ô∏è‚É£ MATCHES TABLE (sample)\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM matches\")\n",
        "    total_matches = cursor.fetchone()[0]\n",
        "    print(f\"Total match records: {total_matches}\")\n",
        "\n",
        "    # Get top matches by count\n",
        "    cursor.execute(\"SELECT pair_id, rows, data FROM matches ORDER BY rows DESC LIMIT 5\")\n",
        "    matches = cursor.fetchall()\n",
        "\n",
        "    # Get image names\n",
        "    cursor.execute(\"SELECT image_id, name FROM images\")\n",
        "    id_to_name = {row[0]: row[1] for row in cursor.fetchall()}\n",
        "\n",
        "    print(\"\\nTop 5 matches by count:\")\n",
        "    for pair_id, num_matches, matches_blob in matches:\n",
        "        image_id2 = pair_id % 2147483648\n",
        "        image_id1 = (pair_id - image_id2) // 2147483648\n",
        "\n",
        "        name1 = id_to_name.get(image_id1, f\"ID_{image_id1}\")\n",
        "        name2 = id_to_name.get(image_id2, f\"ID_{image_id2}\")\n",
        "\n",
        "        matches_data = np.frombuffer(matches_blob, dtype=np.uint32).reshape(-1, 2)\n",
        "\n",
        "        print(f\"\\n  Pair: {name1} <-> {name2}\")\n",
        "        print(f\"    Image IDs: {image_id1} <-> {image_id2}\")\n",
        "        print(f\"    Pair ID (encoded): {pair_id}\")\n",
        "        print(f\"    Match count: {num_matches}\")\n",
        "        print(f\"    Data format: uint32 array, shape=({len(matches_data)}, 2)\")\n",
        "        print(f\"    First 5 matches (kpt_idx1, kpt_idx2):\")\n",
        "        for i, match in enumerate(matches_data[:5]):\n",
        "            print(f\"      [{i}]: keypoint {match[0]} <-> keypoint {match[1]}\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 5. TWO_VIEW_GEOMETRIES TABLE (CRITICAL!)\n",
        "    # =====================================================================\n",
        "    print(\"\\n5Ô∏è‚É£ TWO_VIEW_GEOMETRIES TABLE (geometric verification)\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM two_view_geometries\")\n",
        "    total_geom = cursor.fetchone()[0]\n",
        "    print(f\"Total geometry records: {total_geom}\")\n",
        "\n",
        "    cursor.execute(\"SELECT pair_id, rows, data, config, F, E, H FROM two_view_geometries ORDER BY rows DESC LIMIT 5\")\n",
        "    geometries = cursor.fetchall()\n",
        "\n",
        "    print(\"\\nTop 5 verified pairs by inlier count:\")\n",
        "    for pair_id, inlier_count, inliers_blob, config, F_blob, E_blob, H_blob in geometries:\n",
        "        image_id2 = pair_id % 2147483648\n",
        "        image_id1 = (pair_id - image_id2) // 2147483648\n",
        "\n",
        "        name1 = id_to_name.get(image_id1, f\"ID_{image_id1}\")\n",
        "        name2 = id_to_name.get(image_id2, f\"ID_{image_id2}\")\n",
        "\n",
        "        print(f\"\\n  Pair: {name1} <-> {name2}\")\n",
        "        print(f\"    Image IDs: {image_id1} <-> {image_id2}\")\n",
        "        print(f\"    ‚úÖ Inlier count: {inlier_count}\")\n",
        "        print(f\"    Configuration: {config} (1=PLANAR, 2=PANORAMIC, 3=PLANAR_OR_PANORAMIC, 4-7=UNCALIBRATED)\")\n",
        "\n",
        "        # Decode inliers (uint32 array of match indices)\n",
        "        if inliers_blob:\n",
        "            inliers = np.frombuffer(inliers_blob, dtype=np.uint32)\n",
        "            print(f\"    Inlier indices (first 10): {inliers[:10]}\")\n",
        "\n",
        "        # Decode matrices\n",
        "        if F_blob:\n",
        "            F = np.frombuffer(F_blob, dtype=np.float64).reshape(3, 3)\n",
        "            print(f\"    Fundamental matrix F (3x3):\")\n",
        "            print(f\"      {F[0]}\")\n",
        "            print(f\"      {F[1]}\")\n",
        "            print(f\"      {F[2]}\")\n",
        "\n",
        "        if E_blob:\n",
        "            E = np.frombuffer(E_blob, dtype=np.float64).reshape(3, 3)\n",
        "            print(f\"    Essential matrix E available: Yes\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 6. CRITICAL COMPARISON\n",
        "    # =====================================================================\n",
        "    print(\"\\n6Ô∏è‚É£ CRITICAL COMPARISON: Matches vs Verified Inliers\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT m.pair_id, m.rows as match_count, g.rows as inlier_count\n",
        "        FROM matches m\n",
        "        LEFT JOIN two_view_geometries g ON m.pair_id = g.pair_id\n",
        "        ORDER BY m.rows DESC\n",
        "        LIMIT 10\n",
        "    \"\"\")\n",
        "\n",
        "    comparison = cursor.fetchall()\n",
        "\n",
        "    print(\"\\nTop 10 pairs - Match count vs Verified inlier count:\")\n",
        "    print(f\"{'Pair ID':<20} | {'Image 1':<15} | {'Image 2':<15} | {'Matches':<8} | {'Inliers':<8} | {'Loss %'}\")\n",
        "    print(\"-\"*95)\n",
        "\n",
        "    for pair_id, match_count, inlier_count in comparison:\n",
        "        image_id2 = pair_id % 2147483648\n",
        "        image_id1 = (pair_id - image_id2) // 2147483648\n",
        "\n",
        "        name1 = id_to_name.get(image_id1, f\"ID_{image_id1}\")\n",
        "        name2 = id_to_name.get(image_id2, f\"ID_{image_id2}\")\n",
        "\n",
        "        if inlier_count:\n",
        "            loss_pct = (match_count - inlier_count) / match_count * 100\n",
        "            print(f\"{pair_id:<20} | {name1:<15} | {name2:<15} | {match_count:<8} | {inlier_count:<8} | {loss_pct:>6.1f}%\")\n",
        "        else:\n",
        "            print(f\"{pair_id:<20} | {name1:<15} | {name2:<15} | {match_count:<8} | {'N/A':<8} | {'N/A'}\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ Inspection complete!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "# Usage\n",
        "database_path = \"/content/output/colmap/database.db\"\n",
        "inspect_colmap_database(database_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usuYhnmxMxHU",
        "outputId": "27313932-afaa-4dce-d0d6-df3765d42105"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üîç COLMAP DATABASE INSPECTION\n",
            "======================================================================\n",
            "\n",
            "1Ô∏è‚É£ CAMERAS TABLE\n",
            "----------------------------------------------------------------------\n",
            "Total cameras: 1\n",
            "\n",
            "Camera ID: 1\n",
            "  Model: 1 (0=SIMPLE_PINHOLE, 1=PINHOLE, 2=SIMPLE_RADIAL, 3=RADIAL)\n",
            "  Image size: 768 x 1024\n",
            "  Parameters (raw binary -> float64 array):\n",
            "    [716. 716. 384. 512.]\n",
            "  Interpretation:\n",
            "    - focal lengths (fx, fy): (716.00, 716.00)\n",
            "    - principal point (cx, cy): (384.00, 512.00)\n",
            "  Prior focal length: 1\n",
            "\n",
            "2Ô∏è‚É£ IMAGES TABLE (sample)\n",
            "----------------------------------------------------------------------\n",
            "Total images: 80\n",
            "\n",
            "First 5 images:\n",
            "\n",
            "  Image ID: 1\n",
            "    Name: image_000.jpeg\n",
            "    Camera ID: 1\n",
            "    Prior pose (quaternion): [1.000, 0.000, 0.000, 0.000]\n",
            "    Prior translation: [0.000, 0.000, 0.000]\n",
            "\n",
            "  Image ID: 2\n",
            "    Name: image_001.jpeg\n",
            "    Camera ID: 1\n",
            "    Prior pose (quaternion): [1.000, 0.000, 0.000, 0.000]\n",
            "    Prior translation: [0.000, 0.000, 0.000]\n",
            "\n",
            "  Image ID: 3\n",
            "    Name: image_002.jpeg\n",
            "    Camera ID: 1\n",
            "    Prior pose (quaternion): [1.000, 0.000, 0.000, 0.000]\n",
            "    Prior translation: [0.000, 0.000, 0.000]\n",
            "\n",
            "  Image ID: 4\n",
            "    Name: image_003.jpeg\n",
            "    Camera ID: 1\n",
            "    Prior pose (quaternion): [1.000, 0.000, 0.000, 0.000]\n",
            "    Prior translation: [0.000, 0.000, 0.000]\n",
            "\n",
            "  Image ID: 5\n",
            "    Name: image_004.jpeg\n",
            "    Camera ID: 1\n",
            "    Prior pose (quaternion): [1.000, 0.000, 0.000, 0.000]\n",
            "    Prior translation: [0.000, 0.000, 0.000]\n",
            "\n",
            "3Ô∏è‚É£ KEYPOINTS TABLE (sample)\n",
            "----------------------------------------------------------------------\n",
            "Total keypoint records: 80\n",
            "\n",
            "First 3 keypoint records:\n",
            "\n",
            "  Image ID: 1\n",
            "    Total keypoints: 8192\n",
            "    Data format: float32 array, shape=(8192, 2)\n",
            "    First 5 keypoints (x, y):\n",
            "      [0]: (292.28, 522.62)\n",
            "      [1]: (710.86, 696.17)\n",
            "      [2]: (225.30, 641.83)\n",
            "      [3]: (510.51, 659.84)\n",
            "      [4]: (232.14, 369.73)\n",
            "    Statistics:\n",
            "      X range: [3.0, 765.1]\n",
            "      Y range: [1.6, 1021.4]\n",
            "\n",
            "  Image ID: 2\n",
            "    Total keypoints: 8192\n",
            "    Data format: float32 array, shape=(8192, 2)\n",
            "    First 5 keypoints (x, y):\n",
            "      [0]: (717.82, 208.96)\n",
            "      [1]: (711.67, 373.04)\n",
            "      [2]: (549.76, 981.09)\n",
            "      [3]: (579.00, 444.81)\n",
            "      [4]: (125.05, 311.88)\n",
            "    Statistics:\n",
            "      X range: [3.0, 765.4]\n",
            "      Y range: [1.9, 1020.9]\n",
            "\n",
            "  Image ID: 3\n",
            "    Total keypoints: 8192\n",
            "    Data format: float32 array, shape=(8192, 2)\n",
            "    First 5 keypoints (x, y):\n",
            "      [0]: (721.96, 276.73)\n",
            "      [1]: (189.09, 516.74)\n",
            "      [2]: (219.72, 501.01)\n",
            "      [3]: (124.60, 605.68)\n",
            "      [4]: (672.10, 244.66)\n",
            "    Statistics:\n",
            "      X range: [3.0, 765.1]\n",
            "      Y range: [2.0, 1018.0]\n",
            "\n",
            "4Ô∏è‚É£ MATCHES TABLE (sample)\n",
            "----------------------------------------------------------------------\n",
            "Total match records: 2876\n",
            "\n",
            "Top 5 matches by count:\n",
            "\n",
            "  Pair: image_078.jpeg <-> image_079.jpeg\n",
            "    Image IDs: 79 <-> 80\n",
            "    Pair ID (encoded): 169651208272\n",
            "    Match count: 6967\n",
            "    Data format: uint32 array, shape=(6967, 2)\n",
            "    First 5 matches (kpt_idx1, kpt_idx2):\n",
            "      [0]: keypoint 0 <-> keypoint 101\n",
            "      [1]: keypoint 1 <-> keypoint 0\n",
            "      [2]: keypoint 2 <-> keypoint 3\n",
            "      [3]: keypoint 3 <-> keypoint 1\n",
            "      [4]: keypoint 4 <-> keypoint 154\n",
            "\n",
            "  Pair: image_004.jpeg <-> image_005.jpeg\n",
            "    Image IDs: 5 <-> 6\n",
            "    Pair ID (encoded): 10737418246\n",
            "    Match count: 6671\n",
            "    Data format: uint32 array, shape=(6671, 2)\n",
            "    First 5 matches (kpt_idx1, kpt_idx2):\n",
            "      [0]: keypoint 0 <-> keypoint 126\n",
            "      [1]: keypoint 1 <-> keypoint 16\n",
            "      [2]: keypoint 2 <-> keypoint 111\n",
            "      [3]: keypoint 3 <-> keypoint 18\n",
            "      [4]: keypoint 4 <-> keypoint 7086\n",
            "\n",
            "  Pair: image_066.jpeg <-> image_067.jpeg\n",
            "    Image IDs: 67 <-> 68\n",
            "    Pair ID (encoded): 143881404484\n",
            "    Match count: 6645\n",
            "    Data format: uint32 array, shape=(6645, 2)\n",
            "    First 5 matches (kpt_idx1, kpt_idx2):\n",
            "      [0]: keypoint 0 <-> keypoint 0\n",
            "      [1]: keypoint 1 <-> keypoint 3\n",
            "      [2]: keypoint 2 <-> keypoint 21\n",
            "      [3]: keypoint 3 <-> keypoint 27\n",
            "      [4]: keypoint 4 <-> keypoint 90\n",
            "\n",
            "  Pair: image_073.jpeg <-> image_074.jpeg\n",
            "    Image IDs: 74 <-> 75\n",
            "    Pair ID (encoded): 158913790027\n",
            "    Match count: 6624\n",
            "    Data format: uint32 array, shape=(6624, 2)\n",
            "    First 5 matches (kpt_idx1, kpt_idx2):\n",
            "      [0]: keypoint 0 <-> keypoint 0\n",
            "      [1]: keypoint 1 <-> keypoint 9\n",
            "      [2]: keypoint 2 <-> keypoint 502\n",
            "      [3]: keypoint 3 <-> keypoint 32\n",
            "      [4]: keypoint 4 <-> keypoint 151\n",
            "\n",
            "  Pair: image_003.jpeg <-> image_004.jpeg\n",
            "    Image IDs: 4 <-> 5\n",
            "    Pair ID (encoded): 8589934597\n",
            "    Match count: 6583\n",
            "    Data format: uint32 array, shape=(6583, 2)\n",
            "    First 5 matches (kpt_idx1, kpt_idx2):\n",
            "      [0]: keypoint 0 <-> keypoint 10\n",
            "      [1]: keypoint 1 <-> keypoint 12\n",
            "      [2]: keypoint 2 <-> keypoint 47\n",
            "      [3]: keypoint 3 <-> keypoint 5\n",
            "      [4]: keypoint 4 <-> keypoint 48\n",
            "\n",
            "5Ô∏è‚É£ TWO_VIEW_GEOMETRIES TABLE (geometric verification)\n",
            "----------------------------------------------------------------------\n",
            "Total geometry records: 2876\n",
            "\n",
            "Top 5 verified pairs by inlier count:\n",
            "\n",
            "  Pair: image_078.jpeg <-> image_079.jpeg\n",
            "    Image IDs: 79 <-> 80\n",
            "    ‚úÖ Inlier count: 6967\n",
            "    Configuration: 0 (1=PLANAR, 2=PANORAMIC, 3=PLANAR_OR_PANORAMIC, 4-7=UNCALIBRATED)\n",
            "    Inlier indices (first 10): [  0 101   1   0   2   3   3   1   4 154]\n",
            "    Fundamental matrix F (3x3):\n",
            "      [ 1.00159762e-07 -7.24228646e-05  1.91930638e-02]\n",
            "      [7.82079065e-05 2.76008011e-06 1.71633227e-01]\n",
            "      [-0.02055195 -0.17671309  1.        ]\n",
            "\n",
            "  Pair: image_004.jpeg <-> image_005.jpeg\n",
            "    Image IDs: 5 <-> 6\n",
            "    ‚úÖ Inlier count: 6671\n",
            "    Configuration: 0 (1=PLANAR, 2=PANORAMIC, 3=PLANAR_OR_PANORAMIC, 4-7=UNCALIBRATED)\n",
            "    Inlier indices (first 10): [   0  126    1   16    2  111    3   18    4 7086]\n",
            "    Fundamental matrix F (3x3):\n",
            "      [-3.86507973e-07  2.03059313e-05 -9.45841862e-03]\n",
            "      [-1.30469752e-05  1.27494519e-06  1.81777233e-01]\n",
            "      [ 0.00962462 -0.18540776  1.        ]\n",
            "\n",
            "  Pair: image_066.jpeg <-> image_067.jpeg\n",
            "    Image IDs: 67 <-> 68\n",
            "    ‚úÖ Inlier count: 6645\n",
            "    Configuration: 0 (1=PLANAR, 2=PANORAMIC, 3=PLANAR_OR_PANORAMIC, 4-7=UNCALIBRATED)\n",
            "    Inlier indices (first 10): [ 0  0  1  3  2 21  3 27  4 90]\n",
            "    Fundamental matrix F (3x3):\n",
            "      [2.65035701e-06 1.25253317e-05 6.99831207e-02]\n",
            "      [-2.53663900e-05 -2.49838469e-06 -3.43232439e-01]\n",
            "      [-0.07344476  0.35032388  1.        ]\n",
            "\n",
            "  Pair: image_073.jpeg <-> image_074.jpeg\n",
            "    Image IDs: 74 <-> 75\n",
            "    ‚úÖ Inlier count: 6624\n",
            "    Configuration: 0 (1=PLANAR, 2=PANORAMIC, 3=PLANAR_OR_PANORAMIC, 4-7=UNCALIBRATED)\n",
            "    Inlier indices (first 10): [  0   0   1   9   2 502   3  32   4 151]\n",
            "    Fundamental matrix F (3x3):\n",
            "      [ 9.72767176e-07 -5.30960090e-05  3.82827802e-02]\n",
            "      [6.40217207e-05 2.66889168e-06 5.59278138e-01]\n",
            "      [-0.03611003 -0.56605208  1.        ]\n",
            "\n",
            "  Pair: image_003.jpeg <-> image_004.jpeg\n",
            "    Image IDs: 4 <-> 5\n",
            "    ‚úÖ Inlier count: 6583\n",
            "    Configuration: 0 (1=PLANAR, 2=PANORAMIC, 3=PLANAR_OR_PANORAMIC, 4-7=UNCALIBRATED)\n",
            "    Inlier indices (first 10): [ 0 10  1 12  2 47  3  5  4 48]\n",
            "    Fundamental matrix F (3x3):\n",
            "      [-6.31406417e-08  1.94494727e-06 -1.44230870e-03]\n",
            "      [-8.03859304e-07  1.55473921e-06  4.83672455e-02]\n",
            "      [ 0.00218769 -0.05035678  1.        ]\n",
            "\n",
            "6Ô∏è‚É£ CRITICAL COMPARISON: Matches vs Verified Inliers\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Top 10 pairs - Match count vs Verified inlier count:\n",
            "Pair ID              | Image 1         | Image 2         | Matches  | Inliers  | Loss %\n",
            "-----------------------------------------------------------------------------------------------\n",
            "169651208272         | image_078.jpeg  | image_079.jpeg  | 6967     | 6967     |    0.0%\n",
            "10737418246          | image_004.jpeg  | image_005.jpeg  | 6671     | 6671     |    0.0%\n",
            "143881404484         | image_066.jpeg  | image_067.jpeg  | 6645     | 6645     |    0.0%\n",
            "158913790027         | image_073.jpeg  | image_074.jpeg  | 6624     | 6624     |    0.0%\n",
            "8589934597           | image_003.jpeg  | image_004.jpeg  | 6583     | 6583     |    0.0%\n",
            "161061273676         | image_074.jpeg  | image_075.jpeg  | 6571     | 6571     |    0.0%\n",
            "98784247855          | image_045.jpeg  | image_046.jpeg  | 6554     | 6554     |    0.0%\n",
            "17179869193          | image_007.jpeg  | image_008.jpeg  | 6513     | 6513     |    0.0%\n",
            "96636764206          | image_044.jpeg  | image_045.jpeg  | 6502     | 6502     |    0.0%\n",
            "64424509471          | image_029.jpeg  | image_030.jpeg  | 6500     | 6500     |    0.0%\n",
            "\n",
            "======================================================================\n",
            "‚úÖ Inspection complete!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import h5py\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def debug_database_vs_h5(database_path, matches_h5_path):\n",
        "    \"\"\"Compare matches in database.db vs matches.h5\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üîç DEBUGGING: Database vs H5 Match Counts\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    def get_image_number(filename):\n",
        "        match = re.search(r'(\\d+)', filename)\n",
        "        return int(match.group(1)) if match else 0\n",
        "\n",
        "    # Read H5 matches\n",
        "    print(\"\\n1Ô∏è‚É£ Reading matches.h5...\")\n",
        "    h5_pairs = {}\n",
        "    with h5py.File(matches_h5_path, 'r') as f:\n",
        "        for key1 in f.keys():\n",
        "            for key2 in f[key1].keys():\n",
        "                matches = f[key1][key2][()]\n",
        "                pair_key = tuple(sorted([key1, key2]))\n",
        "                h5_pairs[pair_key] = len(matches)\n",
        "\n",
        "    print(f\"   Found {len(h5_pairs)} pairs in H5\")\n",
        "    print(f\"   Total H5 matches: {sum(h5_pairs.values()):,}\")\n",
        "\n",
        "    # Read database matches\n",
        "    print(\"\\n2Ô∏è‚É£ Reading database.db...\")\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Get image name mapping\n",
        "    cursor.execute(\"SELECT image_id, name FROM images\")\n",
        "    id_to_name = {row[0]: row[1] for row in cursor.fetchall()}\n",
        "\n",
        "    # Get matches from database\n",
        "    cursor.execute(\"SELECT pair_id, rows FROM matches\")\n",
        "    db_matches = cursor.fetchall()\n",
        "\n",
        "    db_pairs = {}\n",
        "    for pair_id, num_matches in db_matches:\n",
        "        image_id2 = pair_id % 2147483648\n",
        "        image_id1 = (pair_id - image_id2) // 2147483648\n",
        "\n",
        "        name1 = id_to_name.get(image_id1)\n",
        "        name2 = id_to_name.get(image_id2)\n",
        "\n",
        "        if name1 and name2:\n",
        "            pair_key = tuple(sorted([name1, name2]))\n",
        "            db_pairs[pair_key] = num_matches\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"   Found {len(db_pairs)} pairs in database\")\n",
        "    print(f\"   Total DB matches: {sum(db_pairs.values()):,}\")\n",
        "\n",
        "    # Compare\n",
        "    print(\"\\n3Ô∏è‚É£ Comparing differences...\")\n",
        "\n",
        "    # Find pairs only in H5\n",
        "    only_h5 = set(h5_pairs.keys()) - set(db_pairs.keys())\n",
        "    # Find pairs only in DB\n",
        "    only_db = set(db_pairs.keys()) - set(h5_pairs.keys())\n",
        "    # Find common pairs with different counts\n",
        "    common = set(h5_pairs.keys()) & set(db_pairs.keys())\n",
        "\n",
        "    print(f\"\\n   Pairs only in H5: {len(only_h5)}\")\n",
        "    print(f\"   Pairs only in DB: {len(only_db)}\")\n",
        "    print(f\"   Common pairs: {len(common)}\")\n",
        "\n",
        "    # Analyze differences in common pairs\n",
        "    differences = []\n",
        "    for pair in common:\n",
        "        h5_count = h5_pairs[pair]\n",
        "        db_count = db_pairs[pair]\n",
        "        if h5_count != db_count:\n",
        "            diff = h5_count - db_count\n",
        "            diff_pct = (diff / h5_count * 100) if h5_count > 0 else 0\n",
        "            differences.append({\n",
        "                'pair': pair,\n",
        "                'h5': h5_count,\n",
        "                'db': db_count,\n",
        "                'diff': diff,\n",
        "                'diff_pct': diff_pct,\n",
        "                'distance': abs(get_image_number(pair[0]) - get_image_number(pair[1]))\n",
        "            })\n",
        "\n",
        "    if differences:\n",
        "        print(f\"\\n   ‚ö†Ô∏è  {len(differences)} pairs have different match counts!\")\n",
        "\n",
        "        # Sort by absolute difference\n",
        "        differences.sort(key=lambda x: abs(x['diff']), reverse=True)\n",
        "\n",
        "        print(\"\\n   Top 10 largest discrepancies:\")\n",
        "        print(\"   \" + \"-\"*65)\n",
        "        print(\"   Pair                              | H5    | DB    | Diff  | %\")\n",
        "        print(\"   \" + \"-\"*65)\n",
        "        for i, d in enumerate(differences[:10], 1):\n",
        "            print(f\"   {d['pair'][0]:15s} - {d['pair'][1]:15s} | \"\n",
        "                  f\"{d['h5']:5d} | {d['db']:5d} | {d['diff']:5d} | {d['diff_pct']:+5.1f}%\")\n",
        "\n",
        "        # Statistics\n",
        "        diffs = [d['diff'] for d in differences]\n",
        "        print(f\"\\n   Difference statistics:\")\n",
        "        print(f\"   - Mean difference: {np.mean(diffs):.1f} matches\")\n",
        "        print(f\"   - Median difference: {np.median(diffs):.1f} matches\")\n",
        "        print(f\"   - Max loss: {min(diffs)} matches\")\n",
        "        print(f\"   - Max gain: {max(diffs)} matches\")\n",
        "\n",
        "        # Analyze by distance\n",
        "        print(f\"\\n4Ô∏è‚É£ Analyzing differences by distance...\")\n",
        "        distance_groups = {}\n",
        "        for d in differences:\n",
        "            dist = d['distance']\n",
        "            if dist not in distance_groups:\n",
        "                distance_groups[dist] = []\n",
        "            distance_groups[dist].append(d['diff'])\n",
        "\n",
        "        print(\"\\n   Distance | Pairs | Avg Diff | Avg Loss %\")\n",
        "        print(\"   \" + \"-\"*50)\n",
        "        for dist in sorted(distance_groups.keys())[:20]:\n",
        "            diffs = distance_groups[dist]\n",
        "            avg_diff = np.mean(diffs)\n",
        "            # Calculate average loss percentage\n",
        "            relevant_diffs = [d for d in differences if d['distance'] == dist]\n",
        "            avg_loss_pct = np.mean([d['diff_pct'] for d in relevant_diffs])\n",
        "            print(f\"   {dist:3d}      | {len(diffs):5d} | {avg_diff:+8.1f} | {avg_loss_pct:+8.1f}%\")\n",
        "    else:\n",
        "        print(\"   ‚úÖ All common pairs have identical match counts\")\n",
        "\n",
        "    # Find top pairs in DB that should be used for initialization\n",
        "    print(\"\\n5Ô∏è‚É£ Top pairs in DATABASE (what COLMAP actually sees):\")\n",
        "    print(\"   \" + \"-\"*70)\n",
        "\n",
        "    db_pairs_with_dist = []\n",
        "    for pair, count in db_pairs.items():\n",
        "        dist = abs(get_image_number(pair[0]) - get_image_number(pair[1]))\n",
        "        db_pairs_with_dist.append({\n",
        "            'pair': pair,\n",
        "            'matches': count,\n",
        "            'distance': dist\n",
        "        })\n",
        "\n",
        "    # Sort by match count\n",
        "    db_pairs_with_dist.sort(key=lambda x: x['matches'], reverse=True)\n",
        "\n",
        "    print(\"   Top 20 pairs by match count in DATABASE:\")\n",
        "    for i, p in enumerate(db_pairs_with_dist[:20], 1):\n",
        "        print(f\"   {i:2d}. {p['pair'][0]:15s} - {p['pair'][1]:15s}: \"\n",
        "              f\"{p['matches']:5d} matches, distance={p['distance']:2d}\")\n",
        "\n",
        "    # Filter for good initialization pairs (distance 8-20, high matches)\n",
        "    good_pairs = [p for p in db_pairs_with_dist\n",
        "                  if 8 <= p['distance'] <= 20 and p['matches'] >= 1000]\n",
        "\n",
        "    if good_pairs:\n",
        "        print(f\"\\n   üéØ RECOMMENDED pairs (distance 8-20, 1000+ matches in DB):\")\n",
        "        for i, p in enumerate(good_pairs[:10], 1):\n",
        "            print(f\"   {i:2d}. {p['pair'][0]:15s} - {p['pair'][1]:15s}: \"\n",
        "                  f\"{p['matches']:5d} matches, distance={p['distance']:2d}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "\n",
        "# Usage\n",
        "database_path = \"/content/output/colmap/database.db\"\n",
        "matches_h5_path = \"/content/output/features/matches.h5\"\n",
        "\n",
        "debug_database_vs_h5(database_path, matches_h5_path)"
      ],
      "metadata": {
        "id": "0XSJArJn7kOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import re\n",
        "\n",
        "matches_file = \"/content/output/features/matches.h5\"\n",
        "\n",
        "def get_image_number(filename):\n",
        "    match = re.search(r'(\\d+)', filename)\n",
        "    return int(match.group(1)) if match else 0\n",
        "\n",
        "# Ë∑ùÈõ¢Âà•„ÅÆÁµ±Ë®à\n",
        "distance_stats = {}\n",
        "\n",
        "with h5py.File(matches_file, 'r') as f:\n",
        "    for key1 in f.keys():\n",
        "        num1 = get_image_number(key1)\n",
        "        for key2 in f[key1].keys():\n",
        "            num2 = get_image_number(key2)\n",
        "            matches = f[key1][key2][()]\n",
        "            distance = abs(num2 - num1)\n",
        "\n",
        "            if distance not in distance_stats:\n",
        "                distance_stats[distance] = []\n",
        "            distance_stats[distance].append(len(matches))\n",
        "\n",
        "print(\"üìä Ë∑ùÈõ¢Âà•„Éû„ÉÉ„ÉÅÊï∞Áµ±Ë®à:\")\n",
        "print(\"Ë∑ùÈõ¢ | „Éö„Ç¢Êï∞ | Âπ≥Âùá„Éû„ÉÉ„ÉÅ | ÊúÄÂ§ß„Éû„ÉÉ„ÉÅ | 500‰ª•‰∏ä„ÅÆ„Éö„Ç¢Êï∞\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for dist in sorted(distance_stats.keys()):\n",
        "    if dist > 50:  # ÊúÄÂàù„ÅÆ50Ë∑ùÈõ¢„Å†„Åë\n",
        "        break\n",
        "\n",
        "    matches_list = distance_stats[dist]\n",
        "    avg = sum(matches_list) / len(matches_list)\n",
        "    max_m = max(matches_list)\n",
        "    count_500plus = sum(1 for m in matches_list if m >= 500)\n",
        "\n",
        "    marker = \"\"\n",
        "    if 20 <= dist <= 40 and count_500plus > 0:\n",
        "        marker = \" ‚Üê ÁêÜÊÉ≥ÁöÑ\"\n",
        "    elif 10 <= dist <= 19 and count_500plus > 0:\n",
        "        marker = \" ‚Üê ÂèØËÉΩ\"\n",
        "\n",
        "    print(f\"{dist:3d}  | {len(matches_list):4d}   | {avg:7.1f}    | {max_m:6d}    | {count_500plus:6d}{marker}\")\n",
        "\n",
        "# ÊúÄ„ÇÇÈõ¢„Çå„Åü„Éö„Ç¢„Åß500‰ª•‰∏ä„ÅÆ„Éû„ÉÉ„ÉÅ„Åå„ÅÇ„Çã„ÇÇ„ÅÆ„ÇíÊé¢„Åô\n",
        "print(\"\\nüìç Ë∑ùÈõ¢„ÅåÈÅ†„Åè„Å¶„Éû„ÉÉ„ÉÅ„ÇÇÂ§ö„ÅÑ„Éö„Ç¢ÔºàTop 10Ôºâ:\")\n",
        "good_pairs = []\n",
        "\n",
        "with h5py.File(matches_file, 'r') as f:\n",
        "    for key1 in f.keys():\n",
        "        num1 = get_image_number(key1)\n",
        "        for key2 in f[key1].keys():\n",
        "            num2 = get_image_number(key2)\n",
        "            matches = f[key1][key2][()]\n",
        "            distance = abs(num2 - num1)\n",
        "            match_count = len(matches)\n",
        "\n",
        "            if match_count >= 500:\n",
        "                good_pairs.append({\n",
        "                    'pair': (key1, key2),\n",
        "                    'distance': distance,\n",
        "                    'matches': match_count,\n",
        "                    'score': distance * (match_count / 1000)\n",
        "                })\n",
        "\n",
        "good_pairs.sort(key=lambda x: x['distance'], reverse=True)\n",
        "\n",
        "for i, p in enumerate(good_pairs[:10], 1):\n",
        "    print(f\"{i:2d}. {p['pair'][0]} - {p['pair'][1]}: \"\n",
        "          f\"distance={p['distance']:2d}, matches={p['matches']:4d}\")"
      ],
      "metadata": {
        "id": "3pI40G0ri_7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whI79VbksabQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = train_gaussian_splatting(data_dir, iterations=1000)\n",
        "\n",
        "# Step 6: Render Video\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "output_video = f\"{OUTPUT_DIR}/gaussian_splatting_video.mp4\"\n",
        "success = render_video(model_path, output_video, iteration=1000)\n"
      ],
      "metadata": {
        "id": "JKJuclrCgMcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnose_specific_pair(database_path, id1, id2):\n",
        "    \"\"\"Diagnose a specific image pair\"\"\"\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    print(f\"\\nüîç Diagnosing pair {id1}-{id2}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get match info\n",
        "    pair_id = id1 * 2147483648 + id2\n",
        "    cursor.execute(\n",
        "        \"SELECT rows, F FROM two_view_geometries WHERE pair_id=?\",\n",
        "        (pair_id,)\n",
        "    )\n",
        "    result = cursor.fetchone()\n",
        "\n",
        "    if result:\n",
        "        rows, F_blob = result\n",
        "        print(f\"  Matches: {rows}\")\n",
        "\n",
        "        if F_blob:\n",
        "            F = np.frombuffer(F_blob, dtype=np.float64).reshape(3, 3)\n",
        "            print(f\"  F matrix exists: {F.shape}\")\n",
        "            print(f\"  F matrix:\\n{F}\")\n",
        "        else:\n",
        "            print(\"  ‚ö†Ô∏è F matrix is NULL!\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è Pair not found in two_view_geometries!\")\n",
        "\n",
        "    # Get camera info\n",
        "    cursor.execute(\"SELECT c.* FROM cameras c JOIN images i ON c.camera_id = i.camera_id WHERE i.image_id IN (?, ?)\", (id1, id2))\n",
        "    print(\"\\n  Cameras:\")\n",
        "    for row in cursor.fetchall():\n",
        "        cam_id, model, w, h, params_blob, prior = row\n",
        "        params = np.frombuffer(params_blob, dtype=np.float64)\n",
        "        print(f\"    Camera {cam_id}: {w}x{h}, model={model}, params={params}\")\n",
        "\n",
        "    conn.close()\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# ÂÆüË°å\n",
        "diagnose_specific_pair('/content/output/colmap/database.db', 11, 20)"
      ],
      "metadata": {
        "id": "CtinWBxmWjFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "\n",
        "def diagnose_database(database_path):\n",
        "    \"\"\"Diagnose why COLMAP can't find initial pair\"\"\"\n",
        "    conn = sqlite3.connect(database_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    print(\"\\nüîç Database Diagnosis\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get match statistics\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT pair_id, rows, config\n",
        "        FROM two_view_geometries\n",
        "        ORDER BY rows DESC\n",
        "        LIMIT 10\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nTop 10 matches by count:\")\n",
        "    for pair_id, rows, config in cursor.fetchall():\n",
        "        image_id2 = pair_id % 2147483648\n",
        "        image_id1 = (pair_id - image_id2) // 2147483648\n",
        "        print(f\"  Images {image_id1}-{image_id2}: {rows} matches, config={config}\")\n",
        "\n",
        "    # Get image and camera info\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT i.image_id, i.name, i.camera_id, c.width, c.height\n",
        "        FROM images i\n",
        "        JOIN cameras c ON i.camera_id = c.camera_id\n",
        "        LIMIT 5\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nSample images:\")\n",
        "    for img_id, name, cam_id, w, h in cursor.fetchall():\n",
        "        print(f\"  Image {img_id}: {name}, camera {cam_id} ({w}x{h})\")\n",
        "\n",
        "    conn.close()\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# ÂÆüË°å\n",
        "diagnose_database('/content/output/colmap/database.db')"
      ],
      "metadata": {
        "id": "wUW7ZnT99nOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dq2Hln8-FKNu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}